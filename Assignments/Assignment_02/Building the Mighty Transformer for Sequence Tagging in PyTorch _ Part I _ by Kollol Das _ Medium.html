<!DOCTYPE html>
<!-- saved from url=(0112)https://medium.com/@kolloldas/building-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/branch-latest.min.js.download"></script><script async="" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/analytics.js.download"></script><script defer="" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/16180790160.js.download"></script><title>Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I | by Kollol Das | Medium</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="al:android:app_name" content="Medium"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/fit/c/152/152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/fit/c/120/120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/fit/c/76/76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/fit/c/60/60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/unbound.css"><link rel="preload" href="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/16180790160.js.download" as="script"><style type="text/css" data-fela-rehydration="548" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@-moz-keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@keyframes k1{0%{opacity:0;transform:translateY(-60px)}100%{opacity:1;transform:translateY(0px)}}@-webkit-keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@-moz-keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@keyframes k2{0%{opacity:1;transform:translateY(0px)}100%{opacity:0;transform:translateY(-60px)}}@-webkit-keyframes k3{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k3{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k3{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-webkit-keyframes k4{0%{transform:translateX(-100%)}40%{transform:translateX(0%)}60%{transform:translateX(0%)}100%{transform:translateX(100%)}}@-moz-keyframes k4{0%{transform:translateX(-100%)}40%{transform:translateX(0%)}60%{transform:translateX(0%)}100%{transform:translateX(100%)}}@keyframes k4{0%{transform:translateX(-100%)}40%{transform:translateX(0%)}60%{transform:translateX(0%)}100%{transform:translateX(100%)}}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{height:25px}.r{fill:rgba(41, 41, 41, 1)}.s{display:block}.t{margin-bottom:36px}.v{padding-top:8px}.w{width:100%}.x{box-shadow:inset 0 -1px 0 rgba(230, 230, 230, 1)}.y{min-height:115px}.ac{flex-direction:column}.ae{display:none}.ag{border-bottom:1px solid rgba(230, 230, 230, 1)}.ah{position:relative}.ai{z-index:500}.ao{max-width:1192px}.ap{min-width:0}.aq{height:62px}.ar{flex-direction:row}.as{flex:1 0 auto}.at{margin-right:16px}.au{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.av{font-size:14px}.aw{line-height:20px}.ax{color:rgba(26, 137, 23, 1)}.ay{padding:7px 16px 9px}.az{background:0}.ba{fill:rgba(26, 137, 23, 1)}.bb{border-color:rgba(26, 137, 23, 1)}.bg:disabled{cursor:inherit}.bh:disabled{opacity:0.3}.bi:disabled:hover{color:rgba(26, 137, 23, 1)}.bj:disabled:hover{fill:rgba(26, 137, 23, 1)}.bk:disabled:hover{border-color:rgba(26, 137, 23, 1)}.bl{border-radius:99em}.bm{border-width:1px}.bn{border-style:solid}.bo{box-sizing:border-box}.bp{display:inline-block}.bq{text-decoration:none}.br{margin-left:0px}.bs{color:rgba(117, 117, 117, 1)}.bt{font-size:inherit}.bu{border:inherit}.bv{font-family:inherit}.bw{letter-spacing:inherit}.bx{font-weight:inherit}.by{padding:0}.bz{margin:0}.ca:disabled{cursor:default}.cb:disabled{color:rgba(163, 208, 162, 0.5)}.cc:disabled{fill:rgba(163, 208, 162, 0.5)}.cd{justify-content:space-between}.cj{align-items:flex-start}.ck{margin-bottom:0px}.cl{margin-top:-32px}.cm{align-items:flex-end}.cn{flex-wrap:wrap}.cq{margin-top:32px}.cr{margin-right:24px}.ct{font-weight:700}.cu{font-size:27px}.cv{line-height:34px}.cw:before{margin-bottom:-14px}.cx:before{content:""}.cy:before{display:table}.cz:before{border-collapse:collapse}.da:after{margin-top:-6px}.db:after{content:""}.dc:after{display:table}.dd:after{border-collapse:collapse}.de{letter-spacing:0}.df{color:rgba(25, 25, 25, 1)}.dg{word-break:break-word}.dh{font-size:16px}.di{line-height:24px}.dj:before{margin-bottom:-10px}.dk{margin-right:12px}.dl{display:inline-flex}.dm{color:inherit}.dn{fill:inherit}.dq:disabled{color:rgba(117, 117, 117, 1)}.dr:disabled{fill:rgba(117, 117, 117, 1)}.ds{margin-left:12px}.dt{margin-left:24px}.dv{margin-bottom:-16px}.dw{margin-top:-14px}.dx{color:rgba(255, 255, 255, 1)}.dy{fill:rgba(255, 255, 255, 1)}.dz{background:rgba(26, 137, 23, 1)}.eb:disabled:hover{background:rgba(26, 137, 23, 1)}.ec{flex:0 0 auto}.ed{justify-self:flex-end}.ee{margin-bottom:-3px}.ef{margin-left:14px}.eg{margin-top:-3px}.eh{padding-top:1px}.ei{height:70px}.ej{margin-right:32px}.em{border-top:none}.en{border-bottom:none}.eo{left:0}.ep{opacity:0}.eq{position:fixed}.er{right:0}.es{top:0}.et{visibility:hidden}.ev{height:60px}.ey{margin-left:16px}.ez{padding-left:24px}.fa{padding-right:24px}.fb{margin-left:auto}.fc{margin-right:auto}.fd{max-width:728px}.fe{background:rgba(255, 255, 255, 1)}.ff{border:1px solid rgba(230, 230, 230, 1)}.fg{border-radius:4px}.fh{box-shadow:0 1px 4px rgba(230, 230, 230, 1)}.fi{max-height:100vh}.fj{overflow-y:auto}.fk{position:absolute}.fl{top:calc(100vh + 100px)}.fm{bottom:calc(100vh + 100px)}.fn{width:10px}.fo{pointer-events:none}.fp{word-wrap:break-word}.fq:after{display:block}.fr:after{clear:both}.fs{max-width:680px}.ft{line-height:1.23}.fu{font-style:normal}.gp{margin-bottom:-0.27em}.gq{color:rgba(41, 41, 41, 1)}.gu{border-radius:50%}.gv{height:28px}.gw{width:28px}.gx{margin:0 4px}.gy{margin:0 7px}.hh{padding-right:8px}.hi{margin-right:8px}.hj{fill:rgba(117, 117, 117, 1)}.hk{max-width:2560px}.hl{margin-top:33px}.hm{clear:both}.ho{cursor:zoom-in}.hp{z-index:auto}.hr{transition:opacity 100ms 400ms}.hs{height:100%}.ht{overflow:hidden}.hu{will-change:transform}.hv{transform:translateZ(0)}.hw{margin:auto}.hx{background-color:rgba(242, 242, 242, 1)}.hy{padding-bottom:56.25%}.hz{height:0}.ia{filter:blur(20px)}.ib{transform:scale(1.1)}.ic{visibility:visible}.id{line-height:1.58}.ie{letter-spacing:-0.004em}.if{font-family:charter, Georgia, Cambria, "Times New Roman", Times, serif}.ja{margin-bottom:-0.46em}.jb{text-decoration:underline}.jc{line-height:1.12}.jd{letter-spacing:-0.022em}.je{font-weight:500}.jx{margin-bottom:-0.28em}.kd{list-style-type:disc}.ke{margin-left:30px}.kf{padding-left:0px}.kg{font-style:italic}.km{max-width:583px}.ks{padding-bottom:159.00514579759863%}.kt{margin-top:10px}.ku{text-align:center}.kx{padding:2px 4px}.ky{font-size:75%}.kz> strong{font-family:inherit}.la{font-family:Menlo, Monaco, "Courier New", Courier, monospace}.lb{padding-bottom:NaN%}.lc{max-width:200px}.ld{padding-bottom:199.5%}.le{padding:20px}.lf{background:rgba(242, 242, 242, 1)}.lg{overflow-x:auto}.lh{line-height:1.18}.li{margin-top:-0.09em}.lj{margin-bottom:-0.09em}.lk{white-space:pre-wrap}.ll{max-width:297px}.lm{padding-bottom:48.821548821548824%}.ln{max-width:490px}.lo{padding-bottom:37.95918367346939%}.lp{max-width:218px}.lq{padding-bottom:101.37614678899082%}.lr{max-width:155px}.ls{padding-bottom:151.61290322580646%}.lt{max-width:504px}.lu{padding-bottom:50.79365079365079%}.lv{will-change:opacity}.lw{width:188px}.lx{left:50%}.ly{transform:translateX(406px)}.lz{top:calc(65px + 54px + 14px)}.mc{will-change:opacity, transform}.md{transform:translateY(159px)}.mf{width:131px}.mg{padding-bottom:28px}.mh{padding-bottom:5px}.mi{padding-top:2px}.mj{padding-top:14px}.mk{padding-top:28px}.ml{margin-bottom:19px}.mm{margin-left:-3px}.ms{outline:0}.mt{border:0}.mu{user-select:none}.mv{cursor:pointer}.mw> svg{pointer-events:none}.my{-webkit-user-select:none}.ni button{text-align:left}.nj{opacity:0.4}.nk{cursor:not-allowed}.nl{padding-right:9px}.nu{margin-top:40px}.nv{padding-bottom:25px}.nw{margin-top:25px}.oa{top:1px}.oo{margin-left:-1px}.op{margin-left:-4px}.ox{padding-bottom:40px}.oy{list-style-type:none}.oz{margin-bottom:8px}.pa{font-size:13px}.pb{line-height:22px}.pc{border-radius:3px}.pd{padding:5px 10px}.pe{padding-top:40px}.pf{padding-bottom:4px}.pg{padding-top:32px}.ph{background-color:rgba(250, 250, 250, 1)}.px{text-overflow:ellipsis}.py{display:-webkit-box}.pz{-webkit-line-clamp:1}.qa{-webkit-box-orient:vertical}.qc{padding-top:5px}.qd{padding-right:168px}.qe{padding-top:25px}.qk{max-width:100%}.ql{margin-bottom:40px}.qm{margin-top:24px}.qn{padding-bottom:16px}.qo{margin-bottom:24px}.sk{flex-grow:0}.sl{padding-bottom:24px}.sm{max-width:500px}.sn{flex:0 1 auto}.sr{padding-bottom:8px}.tc{padding-bottom:100%}.tn{padding:32px 0}.to{background-color:rgba(0, 0, 0, 0.9)}.ts:disabled{color:rgba(255, 255, 255, 0.7)}.tt:disabled{fill:rgba(255, 255, 255, 0.7)}.tu{height:22px}.tv{width:200px}.tx{color:rgba(255, 255, 255, 0.98)}.ua{color:rgba(255, 255, 255, 0.7)}.bc:hover{color:rgba(15, 115, 12, 1)}.bd:hover{fill:rgba(15, 115, 12, 1)}.be:hover{border-color:rgba(15, 115, 12, 1)}.bf:hover{cursor:pointer}.do:hover{color:rgba(25, 25, 25, 1)}.dp:hover{fill:rgba(25, 25, 25, 1)}.ea:hover{background:rgba(15, 115, 12, 1)}.na:hover{fill:rgba(117, 117, 117, 1)}.sz:hover{text-decoration:underline}.tq:hover{color:rgba(255, 255, 255, 0.99)}.tr:hover{fill:rgba(255, 255, 255, 0.99)}.hq:focus{transform:scale(1.01)}.mz:focus{fill:rgba(117, 117, 117, 1)}.mx:active{border-style:none}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.an{margin:0 64px}.gl{font-size:46px}.gm{margin-top:0.6em}.gn{line-height:56px}.go{letter-spacing:-0.011em}.hf{margin-left:30px}.iw{font-size:21px}.ix{margin-top:2em}.iy{line-height:32px}.iz{letter-spacing:-0.003em}.jt{font-size:30px}.ju{margin-top:1.95em}.jv{line-height:36px}.jw{letter-spacing:0}.kc{margin-top:0.86em}.kl{margin-top:1.05em}.kr{margin-top:56px}.mr{margin-right:5px}.nh{margin-top:5px}.nt{padding-left:6px}.oc{display:inline-block}.oh{margin-left:7px}.oi{margin-top:8px}.on{width:25px}.ov{padding-left:7px}.ow{top:3px}.pu{font-size:20px}.pv{line-height:24px}.pw{max-height:24px}.qj{margin:0}.qz{font-size:22px}.ra{line-height:28px}.rn{width:calc(100% + 32px)}.ro{margin-left:-16px}.rp{margin-right:-16px}.sg{padding-left:16px}.sh{padding-right:16px}.si{flex-basis:25%}.sj{max-width:25%}.sw{font-size:16px}.sx{line-height:20px}.tl{min-width:70px}.tm{min-height:70px}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.he{margin-left:30px}.kv{margin-left:auto}.kw{text-align:center}.mq{margin-right:5px}.ng{margin-top:5px}.ns{padding-left:6px}.ob{display:inline-block}.of{margin-left:7px}.og{margin-top:8px}.om{width:25px}.ot{padding-left:7px}.ou{top:3px}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.hd{margin-left:30px}.mp{margin-right:5px}.nf{margin-top:5px}.nq{padding-left:6px}.nr{top:3px}.nz{display:inline-block}.od{margin-left:7px}.oe{margin-top:8px}.ol{width:15px}.os{padding-left:3px}.sq{margin-right:16px}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.u{margin-bottom:20px}.z{box-shadow:inset 0 -1px 0 rgba(230, 230, 230, 1)}.ab{min-height:230px}.af{display:block}.ce{min-height:98px}.cf{display:flex}.cg{align-items:flex-start}.ch{flex-direction:column}.ci{justify-content:flex-end}.co{margin-bottom:28px}.cp{margin-top:0px}.cs{margin-top:28px}.du{margin-left:24px}.ek{border-top:1px solid rgba(230, 230, 230, 1)}.el{border-bottom:1px solid rgba(230, 230, 230, 1)}.ew{align-items:center}.ex{flex:1 0 auto}.gs{margin-top:32px}.gt{flex-direction:column-reverse}.hb{margin-bottom:30px}.hc{margin-left:0px}.mo{margin-left:8px}.nd{margin-top:2px}.ne{margin-right:8px}.no{padding-left:6px}.np{top:3px}.ny{display:inline-block}.ok{width:15px}.or{padding-left:3px}.qp{padding-bottom:12px}.qq{margin-top:16px}.sp{margin-right:16px}.ta{margin-left:16px}.tb{margin-right:0px}.tp{padding:32px 0}.tw{width:140px}.ty{margin-bottom:16px}.tz{margin-top:30px}.ub{width:100%}.uc{flex-direction:row}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.aj{margin:0 24px}.fv{font-size:32px}.fw{margin-top:0.64em}.fx{line-height:40px}.fy{letter-spacing:-0.016em}.gr{margin-top:32px}.gz{margin-bottom:30px}.ha{margin-left:0px}.ig{font-size:18px}.ih{margin-top:1.56em}.ii{line-height:28px}.ij{letter-spacing:-0.003em}.jf{font-size:22px}.jg{margin-top:1.2em}.jh{letter-spacing:0}.jy{margin-top:0.67em}.kh{margin-top:1.34em}.kn{margin-top:40px}.mn{margin-left:8px}.nb{margin-top:2px}.nc{margin-right:8px}.nm{padding-left:6px}.nn{top:3px}.nx{display:inline-block}.oj{width:15px}.oq{padding-left:3px}.pi{font-size:16px}.pj{line-height:20px}.pk{max-height:20px}.qf{margin:0}.qr{font-size:20px}.qs{line-height:24px}.rb{width:calc(100% + 24px)}.rc{margin-left:-12px}.rd{margin-right:-12px}.rq{padding-left:12px}.rr{padding-right:12px}.rs{flex-basis:100%}.rt{max-width:100%}.so{margin-right:16px}.sy{margin-bottom:0px}.td{min-width:48px}.te{min-height:48px}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.am{margin:0 64px}.gh{font-size:46px}.gi{margin-top:0.6em}.gj{line-height:56px}.gk{letter-spacing:-0.011em}.is{font-size:21px}.it{margin-top:2em}.iu{line-height:32px}.iv{letter-spacing:-0.003em}.jp{font-size:30px}.jq{margin-top:1.95em}.jr{line-height:36px}.js{letter-spacing:0}.kb{margin-top:0.86em}.kk{margin-top:1.05em}.kq{margin-top:56px}.pr{font-size:20px}.ps{line-height:24px}.pt{max-height:24px}.qi{margin:0}.qx{font-size:22px}.qy{line-height:28px}.rk{width:calc(100% + 32px)}.rl{margin-left:-16px}.rm{margin-right:-16px}.sc{padding-left:16px}.sd{padding-right:16px}.se{flex-basis:25%}.sf{max-width:25%}.su{font-size:16px}.sv{line-height:20px}.tj{min-width:70px}.tk{min-height:70px}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.al{margin:0 48px}.gd{font-size:46px}.ge{margin-top:0.6em}.gf{line-height:56px}.gg{letter-spacing:-0.011em}.io{font-size:21px}.ip{margin-top:2em}.iq{line-height:32px}.ir{letter-spacing:-0.003em}.jl{font-size:30px}.jm{margin-top:1.95em}.jn{line-height:36px}.jo{letter-spacing:0}.ka{margin-top:0.86em}.kj{margin-top:1.05em}.kp{margin-top:56px}.po{font-size:20px}.pp{line-height:24px}.pq{max-height:24px}.qh{margin:0}.qv{font-size:22px}.qw{line-height:28px}.rh{width:calc(100% + 28px)}.ri{margin-left:-14px}.rj{margin-right:-14px}.ry{padding-left:14px}.rz{padding-right:14px}.sa{flex-basis:50%}.sb{max-width:50%}.ss{font-size:16px}.st{line-height:20px}.th{min-width:48px}.ti{min-height:48px}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ak{margin:0 24px}.fz{font-size:32px}.ga{margin-top:0.64em}.gb{line-height:40px}.gc{letter-spacing:-0.016em}.ik{font-size:18px}.il{margin-top:1.56em}.im{line-height:28px}.in{letter-spacing:-0.003em}.ji{font-size:22px}.jj{margin-top:1.2em}.jk{letter-spacing:0}.jz{margin-top:0.67em}.ki{margin-top:1.34em}.ko{margin-top:40px}.pl{font-size:16px}.pm{line-height:20px}.pn{max-height:20px}.qg{margin:0}.qt{font-size:20px}.qu{line-height:24px}.re{width:calc(100% + 24px)}.rf{margin-left:-12px}.rg{margin-right:-12px}.ru{padding-left:12px}.rv{padding-right:12px}.rw{flex-basis:100%}.rx{max-width:100%}.tf{min-width:48px}.tg{min-height:48px}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="print">.hg{display:none}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.eu{animation:k2 .2s ease-in-out both}.hn{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.ma{transition:opacity 200ms}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (max-width: 1230px)">.mb{display:none}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="all and (max-width: 1198px)">.me{display:none}</style><style type="text/css" data-fela-rehydration="548" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.qb{max-height:none}</style><script data-rh="true">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script><style id="googleidentityservice_button_styles">.qJTHM{-webkit-user-select:none;color:#202124;direction:ltr;-webkit-touch-callout:none;font-family:'Roboto-Regular',arial,sans-serif;-webkit-font-smoothing:antialiased;font-weight:400;margin:0;overflow:hidden;-webkit-text-size-adjust:100%}.ynRLnc{left:-9999px;position:absolute;top:-9999px}.L6cTce{display:none}.bltWBb{word-break:break-all}.hSRGPd{color:#1a73e8;cursor:pointer;font-weight:500;text-decoration:none}.Bz112c-W3lGp{height:16px;width:16px}.Bz112c-E3DyYd{height:20px;width:20px}.Bz112c-r9oPif{height:24px;width:24px}.Bz112c-uaxL4e{-webkit-border-radius:10px;border-radius:10px}.LgbsSe-Bz112c{display:block}.S9gUrf-YoZ4jf,.S9gUrf-YoZ4jf *{border:none;margin:0;padding:0}.fFW7wc-ibnC6b>.aZ2wEe>div{border-color:#4285f4}.P1ekSe-ZMv3u>div:nth-child(1){background-color:#1a73e8!important}.P1ekSe-ZMv3u>div:nth-child(2),.P1ekSe-ZMv3u>div:nth-child(3){background-image:linear-gradient(to right,rgba(255,255,255,0.7),rgba(255,255,255,0.7)),linear-gradient(to right,#1a73e8,#1a73e8)!important}.haAclf{display:inline-block}.nsm7Bb-HzV7m-LgbsSe{-webkit-border-radius:4px;border-radius:4px;-webkit-box-sizing:border-box;box-sizing:border-box;-webkit-transition:background-color .218s,border-color .218s;transition:background-color .218s,border-color .218s;-webkit-user-select:none;-webkit-appearance:none;background-color:#fff;background-image:none;border:1px solid #dadce0;color:#3c4043;cursor:pointer;font-family:'Google Sans',arial,sans-serif;font-size:14px;height:40px;letter-spacing:.25px;outline:none;overflow:hidden;padding:0 12px;position:relative;text-align:center;vertical-align:middle;white-space:nowrap;width:auto}@media screen and (-ms-high-contrast:active){.nsm7Bb-HzV7m-LgbsSe{border:2px solid windowText;color:windowText}}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe{font-size:14px;height:32px;letter-spacing:.25px;padding:0 10px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe{font-size:11px;height:20px;letter-spacing:.3px;padding:0 8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe{padding:0;width:40px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe{width:32px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe{width:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK{-webkit-border-radius:20px;border-radius:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.pSzOP-SxQuSe{-webkit-border-radius:16px;border-radius:16px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.purZT-SxQuSe{-webkit-border-radius:10px;border-radius:10px}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc{border:none;color:#fff}.nsm7Bb-HzV7m-LgbsSe.MFS4be-v3pZbf-Ia7Qfc{background-color:#1a73e8}.nsm7Bb-HzV7m-LgbsSe.MFS4be-JaPV2b-Ia7Qfc{background-color:#202124;color:#e8eaed}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:18px;margin-right:8px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:14px;min-width:14px;width:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:10px;min-width:10px;width:10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin-left:8px;margin-right:-4px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:10px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:4px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:3px;border-top-left-radius:3px;-webkit-border-bottom-left-radius:3px;border-bottom-left-radius:3px;display:-webkit-box;display:-webkit-flex;display:flex;justify-content:center;-webkit-align-items:center;align-items:center;background-color:#fff;height:36px;margin-left:-10px;margin-right:12px;min-width:36px;width:36px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c,.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:28px;margin-left:-8px;margin-right:10px;min-width:28px;width:28px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:16px;margin-left:-6px;margin-right:8px;min-width:16px;width:16px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:3px;border-radius:3px;margin-left:2px;margin-right:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:14px;border-radius:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:8px;border-radius:8px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-bN97Pc-sM5MNb{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;-webkit-flex-direction:row;flex-direction:row;justify-content:space-between;-webkit-flex-wrap:nowrap;flex-wrap:nowrap;height:100%;position:relative;width:100%}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX{justify-content:center}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:1;flex-grow:1;font-family:'Google Sans',arial,sans-serif;font-weight:500;overflow:hidden;text-overflow:ellipsis;vertical-align:top}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-weight:300}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:0;flex-grow:0}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-MJoBVe{-webkit-transition:background-color .218s;transition:background-color .218s;bottom:0;left:0;position:absolute;right:0;top:0}.nsm7Bb-HzV7m-LgbsSe:hover,.nsm7Bb-HzV7m-LgbsSe:focus{-webkit-box-shadow:none;box-shadow:none;border-color:#d2e3fc;outline:none}.nsm7Bb-HzV7m-LgbsSe:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,0.04)}.nsm7Bb-HzV7m-LgbsSe:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,0.1)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,0.24)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,0.32)}.nsm7Bb-HzV7m-LgbsSe .n1UuX-DkfjY{-webkit-border-radius:50%;border-radius:50%;display:-webkit-box;display:-webkit-flex;display:flex;height:20px;margin-left:-4px;margin-right:8px;min-width:20px;width:20px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-family:'Roboto';font-size:12px;text-align:left}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .ssJRIf,.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .fmcmS{overflow:hidden;text-overflow:ellipsis}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;color:#5f6368;fill:#5f6368;font-size:11px;font-weight:400}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.MFS4be-Ia7Qfc .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{color:#e8eaed;fill:#e8eaed}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .Bz112c{height:18px;margin:-3px -3px -3px 2px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:0;border-top-left-radius:0;-webkit-border-bottom-left-radius:0;border-bottom-left-radius:0;-webkit-border-top-right-radius:3px;border-top-right-radius:3px;-webkit-border-bottom-right-radius:3px;border-bottom-right-radius:3px;margin-left:12px;margin-right:-10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.L5Fo6c-sM5MNb{border:0;display:block;left:0;position:relative;top:0}.L5Fo6c-bF1uUb{-webkit-border-radius:4px;border-radius:4px;bottom:0;cursor:pointer;left:0;position:absolute;right:0;top:0}.L5Fo6c-bF1uUb:focus{border:none;outline:none}sentinel{}
/*# sourceURL=/_/gsi/_/ss/k=gsi.gsi.n64yMIEPTMo.L.W.O/am=cg/d=1/ct=zgms/rs=AF0KOtV4Ub2H8p50TbLsIBxnE82DWYYB8g/m=gis_client_button_style */</style><link id="googleidentityservice" type="text/css" media="all" rel="stylesheet" href="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/style"><link rel="author" href="https://medium.com/@kolloldas" data-rh="true"><link rel="canonical" href="https://medium.com/@kolloldas/building-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8" data-rh="true"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/a1815655cd8" data-rh="true"><meta property="og:type" content="article" data-rh="true"><meta property="article:published_time" content="2018-06-23T12:38:22.127Z" data-rh="true"><meta name="title" content="Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I | by Kollol Das | Medium" data-rh="true"><meta property="og:title" content="Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I" data-rh="true"><meta property="twitter:title" content="Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I" data-rh="true"><meta name="twitter:site" content="@Medium" data-rh="true"><meta name="twitter:app:url:iphone" content="medium://p/a1815655cd8" data-rh="true"><meta property="al:android:url" content="medium://p/a1815655cd8" data-rh="true"><meta property="al:ios:url" content="medium://p/a1815655cd8" data-rh="true"><meta name="description" content="Attention mechanisms have taken the deep learning world by storm in the last few years. It is not uncommon nowadays to have an attention related component somewhere in your model. Last year Google…" data-rh="true"><meta property="og:description" content="Attention mechanisms have taken the deep learning world by storm in the last few years. It is not uncommon nowadays to have an attention…" data-rh="true"><meta property="twitter:description" content="Attention mechanisms have taken the deep learning world by storm in the last few years. It is not uncommon nowadays to have an attention…" data-rh="true"><meta property="og:url" content="https://medium.com/@kolloldas/building-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8" data-rh="true"><meta property="al:web:url" content="https://medium.com/@kolloldas/building-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8" data-rh="true"><meta property="og:image" content="https://miro.medium.com/max/1200/1*nIR0CnZVd7d-RRno8_F26Q.jpeg" data-rh="true"><meta name="twitter:image:src" content="https://miro.medium.com/max/1200/1*nIR0CnZVd7d-RRno8_F26Q.jpeg" data-rh="true"><meta name="twitter:card" content="summary_large_image" data-rh="true"><meta property="article:author" content="https://medium.com/@kolloldas" data-rh="true"><meta name="author" content="Kollol Das" data-rh="true"><meta name="robots" content="index,follow,max-image-preview:large" data-rh="true"><meta name="referrer" content="unsafe-url" data-rh="true"><meta name="twitter:label1" content="Reading time" data-rh="true"><meta name="twitter:data1" content="7 min read" data-rh="true"><meta name="parsely-post-id" content="a1815655cd8" data-rh="true"><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*nIR0CnZVd7d-RRno8_F26Q.jpeg"],"url":"https:\u002F\u002Fmedium.com\u002F@kolloldas\u002Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8","dateCreated":"2018-04-18T08:54:42.118Z","datePublished":"2018-04-18T08:54:42.118Z","dateModified":"2018-06-23T12:38:22.127Z","headline":"Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I","name":"Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I","description":"Attention mechanisms have taken the deep learning world by storm in the last few years. It is not uncommon nowadays to have an attention related component somewhere in your model. Last year Google…","identifier":"a1815655cd8","keywords":["Lite:true","Tag:Machine Learning","Tag:Artificial Intelligence","Tag:Neural Networks","Tag:Pytorch","Tag:NLP","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:0"],"author":{"@type":"Person","name":"Kollol Das","url":"https:\u002F\u002Fmedium.com\u002F@kolloldas"},"creator":["Kollol Das"],"publisher":{"@type":"Organization","name":"Medium","url":"https:\u002F\u002Fmedium.com\u002F","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F385\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002F@kolloldas\u002Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8"}</script></head><body data-new-gr-c-s-loaded="14.1002.0"><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><div class="s"><div class="t s u"><div class="x y s z ab"><div class="n ac"><div class="ae af"><div class="ag s ah ai"><div class="n p"><div class="aj ak al am an ao ap w"><div class="aq n o"><div class="n o ar as"><div class="ic" id="lo-meta-header-sign-up-button"><div class="at s"><span><button class="au b av aw ax ay az ba bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq">Get started</button></span></div></div><div class="ic" id="lo-ShowPostUnderUser-navbar-open-in-app-button"><div class="br ae af"><span class="au b av aw bs"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa1815655cd8&amp;~feature=LoOpenInAppButton&amp;~channel=ShowPostUnderUser&amp;~stage=mobileNavBar&amp;source=post_page-----a1815655cd8--------------------------------" class="ax ba bt bu bv bw bx by bz bf bc bd ca ud ue" rel="noopener nofollow">Open in app</a></span></div></div></div><a aria-label="Homepage" rel="noopener" href="https://medium.com/?source=post_page-----a1815655cd8--------------------------------"><svg viewBox="0 0 1043.63 592.71" class="q r"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div><div class="n p"><div class="aj ak al am an ao ap w"><div class="y n o ar cd ce cf cg ch ci"><div class="w n cj cd"><div class="v n w"><div class="ck cl w n cm ar cn co cp cf cg ch"><div class="cq cr s cs"><a aria-label="Author Homepage" rel="noopener" href="https://medium.com/@kolloldas?source=post_page-----a1815655cd8--------------------------------"><span class="au ct cu cv cw cx cy cz da db dc dd de df dg">Kollol Das</span></a></div><div class="cq s g"><span class="au b dh di dj cx cy cz da db dc dd bs"><div class="n o"><div class="dk dl ac"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener" href="https://medium.com/@kolloldas/followers?source=post_page-----a1815655cd8--------------------------------">78 Followers</a></div><div class="ds n ac"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener" href="https://medium.com/@kolloldas/about?source=post_page-----a1815655cd8--------------------------------">About</a></div><div class="dt s du"><div class="dv dw s"><div><div class="bp" aria-hidden="false"><span><button class="au b av aw dx ay dy dz bb ea be bf bg bh eb bk bl bm bn bo bp bq">Follow</button></span></div></div></div></div></div></span></div></div></div><div class="n o ec ed ai g"><div class="ic" id="lo-meta-header-sign-in-link"><p class="au b av aw bs"><span><a href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=post_page-----a1815655cd8---------------------nav_reg-----------" class="ax ba bt bu bv bw bx by bz bf bc bd ca ud ue" rel="noopener">Sign in</a></span></p></div><div class="ic" id="lo-meta-header-sign-up-button"><div class="ee ef eg cr s"><span><button class="au b av aw ax ay az ba bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq">Get started</button></span></div></div><a aria-label="Homepage" rel="noopener" href="https://medium.com/?source=post_page-----a1815655cd8--------------------------------"><svg viewBox="0 0 1043.63 592.71" class="q r"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div></div><div class="ae af"><div class="n p"><div class="aj ak al am an ao ap w"><div><div class="eh ei n o"><div class="s"><span class="au b dh di dj cx cy cz da db dc dd bs"><div class="n o"><div class="ej s"><div class="dv dw s"><div><div class="bp" aria-hidden="false"><span><button class="au b av aw dx ay dy dz bb ea be bf bg bh eb bk bl bm bn bo bp bq">Follow</button></span></div></div></div></div><div class="dk dl ac"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener" href="https://medium.com/@kolloldas/followers?source=post_page-----a1815655cd8--------------------------------">78 Followers</a></div><div class="ds n ac"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener" href="https://medium.com/@kolloldas/about?source=post_page-----a1815655cd8--------------------------------">About</a></div></div></span></div></div></div></div></div></div></div><div class="ek el em en c eo us eq er es ic ai vz"><div class="n p"><div class="aj ak al am an ao ap w"><div class="ev w ae es ai cf ew"><div class="ae cf ew ex"><div class="ic" id="lo-sticky-header-sign-up-button"><span><button class="au b av aw ax ay az ba bb bc bd be bf bg bh bi bj bk bl bm bn bo bp bq">Get started</button></span></div><div class="ic" id="lo-ShowPostUnderUser-navbar-open-in-app-button"><div class="ey ae af"><span class="au b av aw bs"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fa1815655cd8&amp;~feature=LoOpenInAppButton&amp;~channel=ShowPostUnderUser&amp;~stage=mobileNavBar&amp;source=post_page-----a1815655cd8--------------------------------" class="ax ba bt bu bv bw bx by bz bf bc bd ca ud ue" rel="noopener nofollow">Open in app</a></span></div></div></div><a aria-label="Homepage" rel="noopener" href="https://medium.com/?source=post_page-----a1815655cd8--------------------------------"><svg viewBox="0 0 1043.63 592.71" class="q r"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div></div></div></div></div><div class="s hg"><div class="ug uh w hs eq ui uj mv ep fo uk" aria-hidden="true" role="presentation"></div><div class="ul eq um un uo ug hs bo up uq ur us ut uu uv ub uw ux uy uz et" aria-hidden="true"><div class="vc vd n o ar cd"><div class="n ar"><h2 class="au je ve di de gq">Responses (1)</h2></div><div class="n ar"><div><div class="bp" role="tooltip" aria-hidden="false" aria-describedby="72" aria-labelledby="72"><a href="https://policy.medium.com/medium-rules-30e5502c4eb4?source=responses-----a1815655cd8--------------------------------" class="vf dp" target="_blank" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.99 5.04c.26-.21.64-.22.91-.01.97.72 1.77 1.21 2.6 1.54.83.32 1.72.48 2.89.5.41.01.74.35.74.76-.02 3.62-.43 6.26-1.45 8.21-1.03 1.98-2.66 3.21-4.97 4.08a.75.75 0 0 1-.53 0c-2.25-.87-3.86-2.1-4.9-4.07-1.02-1.95-1.46-4.59-1.48-8.22 0-.41.33-.75.75-.76 1.19-.02 2.1-.18 2.92-.5.82-.32 1.6-.81 2.52-1.53zm.46.9c-.9.69-1.71 1.21-2.62 1.56a8.9 8.9 0 0 1-3.02.57c.03 3.45.46 5.82 1.36 7.51.88 1.69 2.25 2.77 4.28 3.57 2.1-.8 3.47-1.89 4.34-3.57.89-1.7 1.3-4.07 1.34-7.51a8.8 8.8 0 0 1-3-.57 11.8 11.8 0 0 1-2.68-1.56zm0 9.15a2.67 2.67 0 1 0 0-5.34 2.67 2.67 0 0 0 0 5.34zm0 1a3.67 3.67 0 1 0 0-7.34 3.67 3.67 0 0 0 0 7.34zm-1.82-3.77l.53-.53.91.92 1.63-1.63.52.53-2.15 2.15-1.44-1.44z"></path></svg></a></div></div><div class="s ah vg"><div class="s ah es er"><button class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" data-testid="close-button" aria-label="close"><svg width="25" height="25" viewBox="0 0 25 25" class="hj"><path d="M18.13 6.11l-5.61 5.61-5.6-5.61-.81.8 5.61 5.61-5.61 5.61.8.8 5.61-5.6 5.61 5.6.8-.8-5.6-5.6 5.6-5.62"></path></svg></button></div></div></div></div><div><div class="au b av aw gq"><div class="di"><div class="wu vk wv s"><div class="un wn fg n ac wo wp wq"><div class="n ac"><span><a href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=responses-----a1815655cd8---------------------respond_sidebar-----------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener"><div class="ww s"><p class="au b av aw bs">What are your thoughts?</p></div></a></span><div class="cd n wr ws ep wt"><label class="n o"><div class="hi xm xn n xo ah"><input class="wx wy wz fk ep xa xb xc xd xe xf xg" type="checkbox"><span class="o fe xh bm bn xi bo dx mv n dy xj p xk xl"><svg width="11" height="11" viewBox="0 0 11 11" class="dy"><path d="M0 6.31l3.7 3.7.9.91.67-1.1 5.3-8.79L8.84 0l-5.3 8.8 1.57-.2-3.7-3.7L0 6.3z"></path></svg></span></div><p class="au b pa aw bs">Also publish to my profile</p></label><button class="au b av aw dx xp dy dz bb ea be bf bg bh eb bk bl bm bn bo bp bq" disabled="">Respond</button></div></div></div></div></div></div></div><div class="s"><div class="s"><div class="en wf s"><div><div class="w hs"><div class="qn qe s"><div class="n ar cd"><div class="n o ar"><img alt="MMG" class="s gu vn vo" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_4uVRY7OQNt-m7YKJRB2sVw.jpeg" width="32" height="32"><div class="wh s"><div class="n ar"><div><div class="bp" role="tooltip" aria-hidden="false" aria-describedby="79" aria-labelledby="79"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener" href="https://medium.com/@vgoklani?source=responses-----a1815655cd8----0----------------------------"><p class="au b av aw gq">MMG</p></a></div></div></div><a class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener nofollow" href="https://medium.com/@vgoklani/this-overview-is-excellent-im-looking-forward-to-more-posts-thank-you-3a6cfb7cbb4?source=responses-----a1815655cd8----0----------------------------"><p class="au b av aw bs">over 1 year ago</p></a></div></div><button class="mv mt vf dp wg"><svg class="overflow-dots-filled-25px_svg__svgIcon-use" width="25" height="25"><path d="M5 12.5c0 .55.2 1.02.59 1.41.39.4.86.59 1.41.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41A1.93 1.93 0 0 0 7 10.5c-.55 0-1.02.2-1.41.59-.4.39-.59.86-.59 1.41zm5.62 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.42.59.55 0 1.02-.2 1.41-.59.4-.39.59-.86.59-1.41 0-.55-.2-1.02-.59-1.41a1.93 1.93 0 0 0-1.41-.59c-.55 0-1.03.2-1.42.59-.39.39-.58.86-.58 1.41zm5.6 0c0 .55.2 1.02.58 1.41.4.4.87.59 1.43.59.56 0 1.03-.2 1.42-.59.39-.39.58-.86.58-1.41 0-.55-.2-1.02-.58-1.41a1.93 1.93 0 0 0-1.42-.59c-.56 0-1.04.2-1.43.59-.39.39-.58.86-.58 1.41z" fill-rule="evenodd"></path></svg></button></div><div class="wi s"><pre class="lk"><div class="wj s"><div class="au b av aw gq"><div class="di">This overview is excellent. I’m looking forward to more posts. Thank you!</div></div></div></pre></div><div class="wl n o ar cd"><div class="n o"><div class="n o"><div class="s ah ha hc mp mq mr"><span><a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F3a6cfb7cbb4&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=responses-----3a6cfb7cbb4----0-----------------respond_sidebar-----------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener"><div class="by ms mt mu mv mw mx uf r mz na"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div></div><div class="ds q n o"></div></div><div class="wm s"><p class="au b av aw gq"><button class="dm dn bt bu bv bw bx by bz bf sz ca dq dr">Reply</button></p></div></div></div></div></div></div></div></div></div></div><article><section class="ez fa fb fc w fd bo s"></section><span class="s"></span><div><div class="fk eo vh fm fn fo"></div><div class="fb fc fd ah"><div class="s h g f e"><aside class="uo fk es" style="width: 157.4px;"><div class="wc qk fk xx we w"><p class="au b pa aw bs"><span class="bp qk we ht px">Top highlight</span></p></div></aside></div></div><section class="dg fp fq db fr"><div class="n p"><div class="aj ak al am an fs ap w"><div class=""><h1 id="4fdb" class="ft de fu au ct fv fw fx fy fz ga gb gc gd ge gf gg gh gi gj gk gl gm gn go gp gq">Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I</h1><div class="cq"><div class="n cd gr gs gt"><div class="o n"><div><a rel="noopener" href="https://medium.com/@kolloldas?source=post_page-----a1815655cd8--------------------------------"><img alt="Kollol Das" class="s gu gv gw" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_z3gp0qUFWyfdZ7DYK6cNSw.png" width="28" height="28"></a></div><div class="ds w n cn"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div><div class="bp" role="tooltip" aria-hidden="false" aria-describedby="68" aria-labelledby="68"><a class="" rel="noopener" href="https://medium.com/@kolloldas?source=post_page-----a1815655cd8--------------------------------"><p class="au b av aw ax">Kollol Das</p></a></div></div></span></div></div><span class="au b av aw bs"><a class="" rel="noopener" href="https://medium.com/@kolloldas/building-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8?source=post_page-----a1815655cd8--------------------------------"><p class="au b av aw bs"><span class="gx"></span>Apr 18, 2018<span class="gy">·</span>7 min read</p></a></span></div></div><div class="n cm gz ha hb hc hd he hf hg"><div class="n o"><div class="hh s"><div class="bp" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bp" role="tooltip" aria-hidden="false" aria-describedby="69" aria-labelledby="69"><button class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div></div></div><div class="hi s"><div class="hj"><span><a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa1815655cd8&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=post_actions_header--------------------------bookmark_preview-----------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div><div class="s as"></div></div></div></div></div></div><figure class="hl hm fb fc paragraph-image"><div role="button" tabindex="0" class="hn ho ah hp w hq"><div class="fb fc hk"><div class="hw s ah hx"><div class="hy hz s"><div class="ep hr fk es eo hs w ht hu hv"><img alt="" class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_nIR0CnZVd7d-RRno8_F26Q.jpeg" width="2560" height="1440" role="presentation"></div><img alt="" class="us vi fk es eo hs w c" width="2560" height="1440" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_nIR0CnZVd7d-RRno8_F26Q(1).jpeg" srcset="https://miro.medium.com/max/345/1*nIR0CnZVd7d-RRno8_F26Q.jpeg 276w, https://miro.medium.com/max/690/1*nIR0CnZVd7d-RRno8_F26Q.jpeg 552w, https://miro.medium.com/max/800/1*nIR0CnZVd7d-RRno8_F26Q.jpeg 640w, https://miro.medium.com/max/875/1*nIR0CnZVd7d-RRno8_F26Q.jpeg 700w" sizes="700px"><noscript></noscript></div></div></div></div></figure><p id="01d8" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">Attention mechanisms have taken the deep learning world by storm in the last few years. It is not un<span id="rmm"><span id="rmm">c</span></span>ommon nowadays to have an attention related component somewhere in your model. Last year Google pushed attention mechanisms to the extreme when it came out with the Transformer models in its infamous <a href="https://arxiv.org/abs/1706.03762" class="dm jb" rel="noopener nofollow">“Attention is all you need”</a> paper. As the title says, Transformer models ditch recurrent layers for a combination of attention and regular feedforward networks. Not only is the model faster and scalable but it is also more interpretable because we can examine its attention weights to know what it focuses on. While this newfound approach has earned the Transformer new records in translation tasks no one seems have attempted apply this model to sequence tagging tasks yet. This is an area where RNNs still rule the roost. Would the Transformer be able to take out the venerable BiLSTM? I felt it was a great excuse to build our own implementation and that’s what this post will explain.</p><h1 id="e901" class="jc jd fu au je jf jg ii jh ji jj im jk jl jm jn jo jp jq jr js jt ju jv jw jx gq" data-selectable-paragraph="">Overview</h1><p id="0e59" class="id ie fu if b ig jy ii ij ik jz im in io ka iq ir is kb iu iv iw kc iy iz ja dg gq" data-selectable-paragraph="">In this two part series we are going to build the Transformer model from scratch and make it compete with a BiLSTM model on the chunking task. We’ll do zero math and instead look at the concepts visually.</p><ul class=""><li id="955a" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja kd ke kf gq" data-selectable-paragraph="">This first part will go through the implementation of the core components that make the Transformer — <em class="kg">Multi Head Attention</em> and <em class="kg">Position wise Feed Forward Network</em>. We’ll especially detail out the inner workings of attention mechanisms.</li><li id="243b" class="id ie fu if b ig kh ii ij ik ki im in io kj iq ir is kk iu iv iw kl iy iz ja kd ke kf gq" data-selectable-paragraph="">The second part will focus on implementing the remaining bits of the Transformer and putting all the parts together. It will conclude with a face off between the Transformer and BiLSTM.</li></ul><p id="9553" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">We’ll follow the original <a href="https://arxiv.org/abs/1706.03762" class="dm jb" rel="noopener nofollow">Transformer</a> paper to implement our model in <a href="http://pytorch.org/" class="dm jb" rel="noopener nofollow">PyTorch</a>. But we will incorporate the latest improvements from the <a href="https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py" class="dm jb" rel="noopener nofollow">TensorfFlow</a> implementation of Transformer as well. We will use the freely available <a href="https://www.clips.uantwerpen.be/conll2000/chunking/" class="dm jb" rel="noopener nofollow">CoNLL 2000 Chunking</a> dataset to run the experiments. If you just want to grab the code it’s all there on <a href="https://github.com/kolloldas/torchnlp" class="dm jb" rel="noopener nofollow">Github</a>.</p><h1 id="b6ba" class="jc jd fu au je jf jg ii jh ji jj im jk jl jm jn jo jp jq jr js jt ju jv jw jx gq" data-selectable-paragraph="">Transformer Guts</h1><p id="4b12" class="id ie fu if b ig jy ii ij ik jz im in io ka iq ir is kb iu iv iw kc iy iz ja dg gq" data-selectable-paragraph="">At the top level, the Transformer has an Encoder and Decoder just like sequence-to-sequence models. If we strip away standard neural network embellishments like <em class="kg">Dropout</em>, <em class="kg">LayerNorm </em>and residual connections, we’ll find that both blocks have two unique components — <em class="kg">Multi Head Attention</em> and <em class="kg">Position wise Feedforward</em>. They may sound complicated but are not very different from the regular attention and feed-forward layers.</p><figure class="kn ko kp kq kr hm fb fc paragraph-image"><div class="fb fc km"><div class="hw s ah hx"><div class="ks hz s"><div class="ep hr fk es eo hs w ht hu hv"><img alt="" class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_mq_H9EGUrTiwf5ZfMva4Sg.png" width="583" height="927" role="presentation"></div><img alt="" class="us vi fk es eo hs w c" width="583" height="927" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_mq_H9EGUrTiwf5ZfMva4Sg(1).png" srcset="https://miro.medium.com/max/345/1*mq_H9EGUrTiwf5ZfMva4Sg.png 276w, https://miro.medium.com/max/690/1*mq_H9EGUrTiwf5ZfMva4Sg.png 552w, https://miro.medium.com/max/729/1*mq_H9EGUrTiwf5ZfMva4Sg.png 583w" sizes="583px"><noscript></noscript></div></div></div><figcaption class="kt ku fd fb fc kv kw au b av aw bs" data-selectable-paragraph="">The Transformer in all its glory. Note some of the changed blocks from the original paper.</figcaption></figure><h1 id="7824" class="jc jd fu au je jf jg ii jh ji jj im jk jl jm jn jo jp jq jr js jt ju jv jw jx gq" data-selectable-paragraph="">Multi-Head Attention — The Beast</h1><p id="d1cc" class="id ie fu if b ig jy ii ij ik jz im in io ka iq ir is kb iu iv iw kc iy iz ja dg gq" data-selectable-paragraph=""><em class="kg">Multi head attention</em> is essentially attention repeated several times in parallel. (If you are not clear about the intuition behind attention I suggest you see this short <a href="https://www.coursera.org/learn/nlp-sequence-models/lecture/RDXpX/attention-model-intuition" class="dm jb" rel="noopener nofollow">video</a> explanation by Andrew Ng on Coursera.) Attention in general can be considered to have three inputs and one output:</p><ul class=""><li id="b04f" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja kd ke kf gq" data-selectable-paragraph=""><em class="kg">Keys</em>: A sequence of vectors also known as the memory. It is the contextual information that we want to look at. In traditional sequence-to-sequence learning they are usually the RNN encoder outputs.</li><li id="ace8" class="id ie fu if b ig kh ii ij ik ki im in io kj iq ir is kk iu iv iw kl iy iz ja kd ke kf gq" data-selectable-paragraph=""><mark class="wa wb mv"><em class="kg">Values:</em></mark><mark class="wa wb mv"> A sequence of vectors from which we aggregate the output through a weighted linear combination. Often </mark><mark class="wa wb mv"><em class="kg">Keys </em></mark><mark class="wa wb mv">serve as </mark><mark class="wa wb mv"><em class="kg">Values</em></mark><mark class="wa wb mv">.</mark></li><li id="e9ce" class="id ie fu if b ig kh ii ij ik ki im in io kj iq ir is kk iu iv iw kl iy iz ja kd ke kf gq" data-selectable-paragraph=""><em class="kg">Query:</em> A single vector that we use to probe the <em class="kg">Keys</em>. By probing we mean the <em class="kg">Query</em> is independently combined with each key<em class="kg"> </em>to arrive at a single probability. The type of attention determines how the combination is done. Usually <em class="kg">Query </em>is the decoder RNN state at a given time step in traditional sequence-to-sequence learning</li><li id="0150" class="id ie fu if b ig kh ii ij ik ki im in io kj iq ir is kk iu iv iw kl iy iz ja kd ke kf gq" data-selectable-paragraph=""><em class="kg">Output:</em> A single vector which is derived from a linear combination of the <em class="kg">Values </em>using the probabilities from the previous step as weights.</li></ul><p id="7238" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">With these definitions in place let’s look at the actual implementation in PyTorch. I will assume that you know how <code class="hx kx ky kz la b">nn.Module</code> works. (If not <a href="http://pytorch.org/tutorials/beginner/pytorch_with_examples.html" class="dm jb" rel="noopener nofollow">here</a> is an excellent introduction). Let’s jump right into the <code class="hx kx ky kz la b">forward()</code> for out <code class="hx kx ky kz la b">MultiHeadAttention</code> component:</p><figure class="kn ko kp kq kr hm"><div class="hw s ah"><div class="xs hz s"><iframe src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/a9fa222a4112d2622a3fa68e95417463.html" allowfullscreen="" frameborder="0" height="917" width="680" title="" class="fk es eo hs w" scrolling="auto"></iframe></div></div></figure><figure class="kn ko kp kq kr hm fb fc paragraph-image"><div class="fb fc lc"><div class="hw s ah hx"><div class="ld hz s"><div class="ep hr fk es eo hs w ht hu hv"><img alt="" class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_lfuT-DDgVeHrFAq7_05Dvg.png" width="200" height="399" role="presentation"></div><img alt="" class="us vi fk es eo hs w c" width="200" height="399" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_lfuT-DDgVeHrFAq7_05Dvg(1).png" srcset="" sizes="200px"><noscript></noscript></div></div></div><figcaption class="kt ku fd fb fc kv kw au b av aw bs" data-selectable-paragraph="">Flow of operations for Multi Head Attention as per the latest TensorFlow implementation</figcaption></figure><p id="2a10" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">We’ll go step by step repeating code snippets as needed:</p><p id="9867" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">1. </strong>Project each of the queries, keys and values linearly. By linear projection I mean a single neural network layer without the nonlinear activation. The learnable parameters of these linear projections are important for the attention mechanism:</p><pre class="kn ko kp kq kr le lf lg"><span id="3a31" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">queries = self.query_linear(queries)<br>keys = self.key_linear(keys)        <br>values = self.value_linear(values)</span></pre><p id="0ea0" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">This is how the Linears are defined:</p><figure class="kn ko kp kq kr hm"><div class="hw s ah"><div class="xu hz s"><iframe src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/c9f93d9289b294ec36e5ba75688c8641.html" allowfullscreen="" frameborder="0" height="169" width="680" title="" class="fk es eo hs w" scrolling="auto"></iframe></div></div></figure><p id="8378" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">Here <code class="hx kx ky kz la b">input_depth</code> <code class="hx kx ky kz la b">total_key_depth</code> <code class="hx kx ky kz la b">total_value_depth</code> and <code class="hx kx ky kz la b">output_depth</code> are hyperparameters of the model. Note that key and query size should match as we have to do a <a href="https://arxiv.org/abs/1508.04025" class="dm jb" rel="noopener nofollow">dot product</a> between them. Because Transformers don’t have recurrent layers we need not process the queries one step at a time. So the query input here is the entire sequence of queries for a particular layer.</p><p id="004f" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">2.</strong> Split the projected inputs into required number of partitions for multi head attention. Instead of working with a separate linear projections for each head or parallel attention we divide a single projection into partitoins and perform attention independently:</p><pre class="kn ko kp kq kr le lf lg"><span id="82c0" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">queries = self._split_heads(queries)        <br>keys = self._split_heads(keys)        <br>values = self._split_heads(values)</span></pre><p id="c281" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">Here’s the <code class="hx kx ky kz la b">_split_heads()</code> function:</p><figure class="kn ko kp kq kr hm"><div class="hw s ah"><div class="xv hz s"><iframe src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/0764f270f6265c0eb104c4a30b2beffc.html" allowfullscreen="" frameborder="0" height="312" width="680" title="" class="fk es eo hs w" scrolling="auto"></iframe></div></div></figure><p id="b273" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">The way we split is to reshape the inputs to have an extra <em class="kg">heads</em> dimension.</p><p id="db12" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">3. </strong>Scale the queries by a certain factor. This is supposed to prevent the outputs from growing too big which can make learning difficult:</p><pre class="kn ko kp kq kr le lf lg"><span id="8f6c" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">queries *= self.query_scale</span></pre><p id="c2f0" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">The factor is calculated as the inverse square root of the partition size after splitting:</p><pre class="kn ko kp kq kr le lf lg"><span id="dcab" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">self.query_scale = (total_key_depth//num_heads)**-0.5</span></pre><p id="c02d" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">4.</strong> Take the dot product between the queries and the keys (since we are doing multiplicative attention). We do that for every query and key pair with one single <code class="hx kx ky kz la b">matmul</code> :</p><pre class="kn ko kp kq kr le lf lg"><span id="fcf0" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">logits = torch.matmul(queries, keys.permute(0, 1, 3, 2))</span></pre><p id="e96b" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">A lot is happening in that single call so let’s break it down. For illustration we’ll use the following values: <code class="hx kx ky kz la b">sequence_length=10</code>, <code class="hx kx ky kz la b">total_key_depth=32</code>, <code class="hx kx ky kz la b">num_heads=4</code> which gives us partitions of size 8 after splitting.</p><figure class="kn ko kp kq kr hm fb fc paragraph-image"><div class="fb fc ll"><div class="hw s ah hx"><div class="lm hz s"><div class="ep hr fk es eo hs w ht hu hv"><img alt="" class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_LdgVw-tgr6twHCIG1vJp7A.png" width="297" height="145" role="presentation"></div><img alt="" class="us vi fk es eo hs w c" width="297" height="145" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_LdgVw-tgr6twHCIG1vJp7A(1).png" srcset="https://miro.medium.com/max/345/1*LdgVw-tgr6twHCIG1vJp7A.png 276w, https://miro.medium.com/max/371/1*LdgVw-tgr6twHCIG1vJp7A.png 297w" sizes="297px"><noscript></noscript></div></div></div></figure><p id="c926" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">To get the dot product we must transpose the (last two dimensions of the) key tensor before the matrix multiplication</p><figure class="kn ko kp kq kr hm fb fc paragraph-image"><div class="fb fc ln"><div class="hw s ah hx"><div class="lo hz s"><div class="ep hr fk es eo hs w ht hu hv"><img alt="" class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_C_g9gifaN8ig6StBX8Nbaw.png" width="490" height="186" role="presentation"></div><img alt="" class="us vi fk es eo hs w c" width="490" height="186" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_C_g9gifaN8ig6StBX8Nbaw(1).png" srcset="https://miro.medium.com/max/345/1*C_g9gifaN8ig6StBX8Nbaw.png 276w, https://miro.medium.com/max/613/1*C_g9gifaN8ig6StBX8Nbaw.png 490w" sizes="490px"><noscript></noscript></div></div></div></figure><p id="467d" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">The above figures only show the last two dimensions of the input. But they are actually 4D Tensors. How can <code class="hx kx ky kz la b">matmul</code> do 4D Tensors??</p><figure class="kn ko kp kq kr hm fb fc paragraph-image"><div class="fb fc lp"><div class="hw s ah hx"><div class="lq hz s"><div class="ep hr fk es eo hs w ht hu hv"><img alt="" class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_xqTChgeNxhRcGgXPBiyszw.png" width="218" height="221" role="presentation"></div><img alt="" class="us vi fk es eo hs w c" width="218" height="221" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_xqTChgeNxhRcGgXPBiyszw(1).png" srcset="" sizes="218px"><noscript></noscript></div></div></div></figure><p id="3299" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">Turns out it does a matrix multiplication for each higher dimension separately. So as long as the higher dimensions match exactly <code class="hx kx ky kz la b">matmul</code> can handle any number of them.</p><figure class="kn ko kp kq kr hm fb fc paragraph-image"><div class="fb fc lr"><div class="hw s ah hx"><div class="ls hz s"><div class="ep hr fk es eo hs w ht hu hv"><img alt="" class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_xvg7D83FnZWhDvJQ-JeOPA.png" width="155" height="235" role="presentation"></div><img alt="" class="us vi fk es eo hs w c" width="155" height="235" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_xvg7D83FnZWhDvJQ-JeOPA(1).png" srcset="" sizes="155px"><noscript></noscript></div></div></div></figure><p id="e411" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">Of course the last two dimensions should follow matrix multiplication rules.</p><p id="be78" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">5. </strong>Apply a mask on the query key dot products. This step is required mainly for the decoder to prevent future inputs from influencing attention. We’ll cover this in part II.</p><p id="ab3b" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">6.</strong> Apply <em class="kg">Softmax</em> on the dot products to convert them to probabilities:</p><pre class="kn ko kp kq kr le lf lg"><span id="2c04" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">weights = nn.functional.softmax(logits, dim=-1)</span></pre><p id="b0ad" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">7.</strong> Add <em class="kg">Dropout.</em> This is something that is not there in the original paper but added in the latest TensorFlow implementation.</p><p id="a2b3" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">8.</strong> Using the probabilities as weights do a linear combination of the <em class="kg">values</em>. Again we use a single <code class="hx kx ky kz la b">matmul</code> to do the job across all values in all partitions.</p><pre class="kn ko kp kq kr le lf lg"><span id="a274" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">contexts = torch.matmul(weights, values)</span></pre><p id="08de" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">Continuing the earlier illustration:</p><figure class="kn ko kp kq kr hm fb fc paragraph-image"><div class="fb fc lt"><div class="hw s ah hx"><div class="lu hz s"><div class="ep hr fk es eo hs w ht hu hv"><img alt="" class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_D0d-MgkSxQTz6zrZtiGqjw.png" width="504" height="256" role="presentation"></div><img alt="" class="us vi fk es eo hs w c" width="504" height="256" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_D0d-MgkSxQTz6zrZtiGqjw(1).png" srcset="https://miro.medium.com/max/345/1*D0d-MgkSxQTz6zrZtiGqjw.png 276w, https://miro.medium.com/max/630/1*D0d-MgkSxQTz6zrZtiGqjw.png 504w" sizes="504px"><noscript></noscript></div></div></div></figure><p id="343b" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">With matrix multiplication we get all the outputs in one shot. This is what makes vectorization neat!</p><p id="b297" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">9.</strong> Now merge the heads back. Or rather reshape the outputs to get the original 3D shape [batch, sequence length, output depth]:</p><pre class="kn ko kp kq kr le lf lg"><span id="9fb8" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">contexts = self._merge_heads(contexts)</span></pre><p id="16f3" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><code class="hx kx ky kz la b">_merge_heads()</code> is just the reverse of <code class="hx kx ky kz la b">split_heads()</code>:</p><figure class="kn ko kp kq kr hm"><div class="hw s ah"><div class="xw hz s"><iframe src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/b3c70df683947e2a14c981eaf7005ecf.html" allowfullscreen="" frameborder="0" height="320" width="680" title="" class="fk es eo hs w" scrolling="auto"></iframe></div></div></figure><p id="a0f9" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><strong class="if ct">10.</strong> Finally we do another linear projection to get the output:</p><pre class="kn ko kp kq kr le lf lg"><span id="e61f" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">outputs = self.output_linear(contexts)</span></pre><p id="c34b" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">So there you have it, Multi Head attention in ten steps. See the full implementation in GitHub <a href="https://github.com/kolloldas/torchnlp/blob/master/torchnlp/modules/transformer/sublayers.py" class="dm jb" rel="noopener nofollow">here</a> Now let’s go into the next core component, the <em class="kg">Positionwise Feedforward network.</em></p><h1 id="6449" class="jc jd fu au je jf jg ii jh ji jj im jk jl jm jn jo jp jq jr js jt ju jv jw jx gq" data-selectable-paragraph="">Positionwise Feedforward Network — The Sidekick</h1><p id="7dcf" class="id ie fu if b ig jy ii ij ik jz im in io ka iq ir is kb iu iv iw kc iy iz ja dg gq" data-selectable-paragraph="">Like the name indicates, this is a regular feedforward network applied to <em class="kg">each</em> time step of the Multi Head attention outputs. The network has three layers with a non-linearity like ReLU for the hidden layer. You might be wondering why do we need a feedforward network after attention; after all isn’t attention all we need 😈 ? I suspect it is needed to improve model expressiveness. As we saw earlier the multi head attention partitioned the inputs and applied attention independently. There was only a linear projection to the outputs, i.e. the partitions were combined only linearly. The <em class="kg">Positionwise Feedforward </em>network thus brings in some non-linear ‘mixing’ if we call it that. In fact for the sequence tagging task we use convolutions instead of fully connected layers. A filter of width 3 allows interactions to happen with adjacent time steps to improve performance. The implementation in PyTorch is straightforward:</p><figure class="kn ko kp kq kr hm"><div class="hw s ah"><div class="xy hz s"><iframe src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/b2f3bad617f3b2e33bd030e6e329f8e3.html" allowfullscreen="" frameborder="0" height="277" width="680" title="" class="fk es eo hs w" scrolling="auto"></iframe></div></div></figure><p id="1acf" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph=""><code class="hx kx ky kz la b">self.layers</code> is a <code class="hx kx ky kz la b">nn.ModuleList</code> which can take either linear or convolutional layers. E.g. for linear layers:</p><pre class="kn ko kp kq kr le lf lg"><span id="5450" class="gq lh jd fu la b dh li lj s lk" data-selectable-paragraph="">self.layers = nn.ModuleList([<br>  nn.Linear(input_depth, filter_size), <br>  nn.Linear(filter_size, filter_size), <br>  nn.Linear(filter_size, output_depth)<br>])</span></pre><p id="132d" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">Again <code class="hx kx ky kz la b">input_depth</code> <code class="hx kx ky kz la b">filter_size</code> and <code class="hx kx ky kz la b">output_depth</code> are all hyperparameters. (My actual implementation is slightly more complex because it allows the total number of layers and each layer type to be configured.)</p><p id="259d" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">With these two components implemented our Transformer is almost completed. All we need to do now is put everything together. The next part will cover that along with some tricks that we apply to improve the model. And of course we’ll run the actual experiments.</p><p id="d278" class="id ie fu if b ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja dg gq" data-selectable-paragraph="">Go to <a class="dm jb" rel="noopener" href="https://medium.com/@kolloldas/building-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-ii-c85bf8fd145"><em class="kg">Building the Mighty Transformer for Sequence Tagging with PyTorch: Part II</em></a></p></div></div></section></div></article><div class="us fo eq mc w vy es ma me" data-test-id="post-sidebar"><div class="n p"><div class="aj ak al am an ao ap w"><div class="mf n ac"><div class="vx"><div><div class="mg ag s"><div class="mh s"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener" href="https://medium.com/@kolloldas?source=post_sidebar--------------------------post_sidebar-----------"><h2 class="au je dh aw de gq dg">Kollol Das</h2></a></div><div class="mi s"><p class="au b av aw bs">Developer and NLP Researcher</p></div><div class="mj s"><span><button class="au b av aw dx ay dy dz bb ea be bf bg bh eb bk bl bm bn bo bp bq">Follow</button></span></div></div><div class="mk ml mm n"><div class="n o"><div class="s ah mn mo mp mq mr"><span><a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fa1815655cd8&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=post_sidebar-----a1815655cd8---------------------clap_sidebar-----------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener"><div class="by ms mt mu mv mw mx uf r mz na"><svg width="29" height="29" aria-label="clap"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nb nc nd ne nf ng nh"><div class="ni"><p class="au b av aw bs"><button class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr">326 </button></p></div></div></div></div><div class="ml s"><button class="mv mt by"><div class="nl n o ar"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg><div class="s ah nm nn no np nq nr ns nt"><p class="au b av aw bs">1 </p></div></div></button></div><div class="hj"><span><a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa1815655cd8&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=post_sidebar-----a1815655cd8---------------------bookmark_sidebar-----------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div><div class="us vx lv eq lw lx ly lz ma mb"></div><div><div class="nu hm n ac p"><div class="n p"><div class="aj ak al am an fs ap w"><div class="n cn"></div><div class="n o cn"></div><div class="nv nu s"><div class="nw n cd hg"><div class="n ar"><div class="lr s"><span class="s nx ny nz e d"><div class="n o"><div class="s ah mn mo mp mq mr"><span><a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fa1815655cd8&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=post_actions_footer-----a1815655cd8---------------------clap_footer-----------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener"><div class="by ms mt mu mv mw mx uf r mz na"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s nb nc nd ne nf ng nh"><div class="ah oa ni"><p class="au b av aw gq"><button class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr">326<span class="s h g f ob oc">&nbsp;</span></button><span class="s h g f ob oc"></span></p></div></div></div></span><span class="s h g f ob oc"><div class="n cj"><div class="s ah mn mo"><span><a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fa1815655cd8&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=post_actions_footer-----a1815655cd8---------------------clap_footer-----------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener"><div class="by ms mt mu mv mw mx uf r mz na"><svg width="33" height="33" viewBox="0 0 33 33" aria-label="clap"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></div></a></span></div><div class="s nb nc nd ne od oe of og oh oi"><div class="ah oa ni"><p class="au b av aw gq"><button class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr">326<span class="s h g f ob oc">&nbsp;</span></button><span class="s h g f ob oc"></span></p></div></div></div></span></div><div class="s oj ok ol om on"></div><button class="mv mt by"><div class="nl n o ar"><div><div class="bp" role="tooltip" aria-hidden="false" aria-describedby="70" aria-labelledby="70"><span class="oo s h g f ob oc"><svg width="33" height="33" viewBox="0 0 33 33" fill="none" class="r" aria-label="responses"><path fill-rule="evenodd" clip-rule="evenodd" d="M24.28 25.5l.32-.29c2.11-1.94 3.4-4.61 3.4-7.56C28 11.83 22.92 7 16.5 7S5 11.83 5 17.65s5.08 10.66 11.5 10.66c1.22 0 2.4-.18 3.5-.5l.5-.15.41.33a8.86 8.86 0 0 0 4.68 2.1 7.34 7.34 0 0 1-1.3-4.15v-.43zm1 .45c0 1.5.46 2.62 1.69 4.44.22.32.01.75-.38.75a9.69 9.69 0 0 1-6.31-2.37c-1.2.35-2.46.54-3.78.54C9.6 29.3 4 24.09 4 17.65 4 11.22 9.6 6 16.5 6S29 11.22 29 17.65c0 3.25-1.42 6.18-3.72 8.3z"></path></svg></span><span class="op s nx ny nz e d"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></span></div></div><div class="s ah oq nn or np os nr ot ou ov ow"><p class="au b av aw gq">1 </p></div></div></button></div><div class="n o"><div class="hh s"><div class="bp" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bp" role="tooltip" aria-hidden="false" aria-describedby="71" aria-labelledby="71"><button class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post"><svg width="25" height="25" class="r"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></button></div></div></div></div><div class="hh s ec"><div class="hj"><span><a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa1815655cd8&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40kolloldas%2Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8&amp;source=post_actions_footer--------------------------bookmark_footer-----------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div><div class="ox nw s"><ul class="by bz"><li class="bp oy hi oz"><a href="https://medium.com/tag/machine-learning" class="au b pa pb bs pc pd bq s lf">Machine Learning</a></li><li class="bp oy hi oz"><a href="https://medium.com/tag/artificial-intelligence" class="au b pa pb bs pc pd bq s lf">Artificial Intelligence</a></li><li class="bp oy hi oz"><a href="https://medium.com/tag/neural-networks" class="au b pa pb bs pc pd bq s lf">Neural Networks</a></li><li class="bp oy hi oz"><a href="https://medium.com/tag/pytorch" class="au b pa pb bs pc pd bq s lf">Pytorch</a></li><li class="bp oy hi oz"><a href="https://medium.com/tag/nlp" class="au b pa pb bs pc pd bq s lf">NLP</a></li></ul></div><div class="pe s"></div></div></div><div><div class="n p"><div class="aj ak al am an fs ap w"></div></div><div class="s hg"><div class="pf pg s ph"><div class="n p"><div class="aj ak al am an fs ap w"><div class="n o cd"><h2 class="au je pi pj pk jh pl pm pn jk po pp pq jo pr ps pt js pu pv pw jw ht px py pz qa qb gq"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr" rel="noopener" href="https://medium.com/@kolloldas?source=follow_footer-------------------------------------">More from Kollol Das</a></h2><span><button class="au b av aw dx ay dy dz bb ea be bf bg bh eb bk bl bm bn bo bp bq">Follow</button></span></div><div class="qc qd s"><p class="au b av aw bs">Developer and NLP Researcher</p></div></div></div></div></div><div class="qe s ph hg"><div class="n p"><div class="qf qg qh qi qj qk ap w"></div></div></div><div class="s fe hg"><div class="n p"><div class="aj ak al am an ao ap w"><div class="ql qm s"><div class="qn ag qo qm s qp qq"><h2 class="au je qr qs jh qt qu jk qv qw jo qx qy js qz ra jw gq">More From Medium</h2></div><div class="cj n ar cn rb rc rd re rf rg rh ri rj rk rl rm rn ro rp"><div class="rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk"><div class="sl sm s"><div class="w hs"><div class="n cd"><div class="s sn so sp sq"><div class="sr s"><h2 class="au je pi pj jh pl pm jk ss st jo su sv js sw sx jw gq"><a rel="noopener" href="https://medium.com/swlh/camera-lidar-projection-navigating-between-2d-and-3d-911c78167a94?source=post_internal_links---------0----------------------------">Camera-Lidar Projection: Navigating between 2D and 3D</a></h2></div><div class="o n"><div></div><div class="w s"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div class="ck n o sy"><span class="au b pa aw gq"><a href="https://daryl-tan.medium.com/?source=post_internal_links---------0----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Daryl Tan</a><span> in <a href="https://medium.com/swlh?source=post_internal_links---------0----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">The Startup</a></span></span></div></span></div></div></div></div></div><div class="ds hi s ta tb"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr s" rel="noopener" href="https://medium.com/swlh/camera-lidar-projection-navigating-between-2d-and-3d-911c78167a94?source=post_internal_links---------0----------------------------"><div class="hw s ah hx"><div class="tc hz s"><div class="ep hr fk es eo hs w ht hu hv"><img class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_-WFfHL24zz_mOZM7_blSOQ.png" width="70" height="70" role="presentation"></div><img class="us vi td te tf tg th ti tj tk tl tm c" width="70" height="70" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_-WFfHL24zz_mOZM7_blSOQ(1).png" srcset="https://miro.medium.com/fit/c/60/88/1*-WFfHL24zz_mOZM7_blSOQ.png 48w, https://miro.medium.com/fit/c/88/88/1*-WFfHL24zz_mOZM7_blSOQ.png 70w" sizes="70px"><noscript></noscript></div></div></a></div></div></div></div></div><div class="rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk"><div class="sl sm s"><div class="w hs"><div class="n cd"><div class="s sn so sp sq"><div class="sr s"><h2 class="au je pi pj jh pl pm jk ss st jo su sv js sw sx jw gq"><a rel="noopener" href="https://medium.com/swlh/a-3-step-guide-to-assess-any-business-use-case-of-ai-9111b2e233f6?source=post_internal_links---------1----------------------------">A 3 step guide to assess any business use-case of AI</a></h2></div><div class="o n"><div></div><div class="w s"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div class="ck n o sy"><span class="au b pa aw gq"><a class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener" href="https://medium.com/@uday.marepalli?source=post_internal_links---------1----------------------------">Uday Marepalli</a><span> in <a href="https://medium.com/swlh?source=post_internal_links---------1----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">The Startup</a></span></span></div></span></div></div></div></div></div><div class="ds hi s ta tb"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr s" rel="noopener" href="https://medium.com/swlh/a-3-step-guide-to-assess-any-business-use-case-of-ai-9111b2e233f6?source=post_internal_links---------1----------------------------"><div class="hw s ah hx"><div class="tc hz s"><div class="ep hr fk es eo hs w ht hu hv"><img class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_J9SQ1JdVMe1pSB-jePs1zg.jpeg" width="70" height="70" role="presentation"></div><img class="us vi td te tf tg th ti tj tk tl tm c" width="70" height="70" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_J9SQ1JdVMe1pSB-jePs1zg(1).jpeg" srcset="https://miro.medium.com/fit/c/60/88/1*J9SQ1JdVMe1pSB-jePs1zg.jpeg 48w, https://miro.medium.com/fit/c/88/88/1*J9SQ1JdVMe1pSB-jePs1zg.jpeg 70w" sizes="70px"><noscript></noscript></div></div></a></div></div></div></div></div><div class="rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk"><div class="sl sm s"><div class="w hs"><div class="n cd"><div class="s sn so sp sq"><div class="sr s"><h2 class="au je pi pj jh pl pm jk ss st jo su sv js sw sx jw gq"><a rel="noopener" href="https://medium.com/analytics-vidhya/different-metrics-to-evaluate-the-performance-of-a-machine-learning-model-90acec9e8726?source=post_internal_links---------2----------------------------">Different metrics to evaluate the performance of a Machine Learning model</a></h2></div><div class="o n"><div></div><div class="w s"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div class="ck n o sy"><span class="au b pa aw gq"><a href="https://swapnil-vishwakarma.medium.com/?source=post_internal_links---------2----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Swapnil Vishwakarma</a><span> in <a href="https://medium.com/analytics-vidhya?source=post_internal_links---------2----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Analytics Vidhya</a></span></span></div></span></div></div></div></div></div><div class="ds hi s ta tb"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr s" rel="noopener" href="https://medium.com/analytics-vidhya/different-metrics-to-evaluate-the-performance-of-a-machine-learning-model-90acec9e8726?source=post_internal_links---------2----------------------------"><div class="hw s ah hx"><div class="tc hz s"><div class="ep hr fk es eo hs w ht hu hv"><img class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_XO3sOjsr7wZT6TrgFAdwmw.jpeg" width="70" height="70" role="presentation"></div><img class="us vi td te tf tg th ti tj tk tl tm c" width="70" height="70" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_XO3sOjsr7wZT6TrgFAdwmw(1).jpeg" srcset="https://miro.medium.com/fit/c/60/88/1*XO3sOjsr7wZT6TrgFAdwmw.jpeg 48w, https://miro.medium.com/fit/c/88/88/1*XO3sOjsr7wZT6TrgFAdwmw.jpeg 70w" sizes="70px"><noscript></noscript></div></div></a></div></div></div></div></div><div class="rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk"><div class="sl sm s"><div class="w hs"><div class="n cd"><div class="s sn so sp sq"><div class="sr s"><h2 class="au je pi pj jh pl pm jk ss st jo su sv js sw sx jw gq"><a href="https://mark-s-cleverley.medium.com/yolov4-the-subtleties-of-high-speed-object-detection-91eced12c6a4?source=post_internal_links---------3----------------------------" rel="noopener">YOLOv4: The Subtleties of High-Speed Object Detection</a></h2></div><div class="o n"><div></div><div class="w s"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div class="ck n o sy"><span class="au b pa aw gq"><a href="https://mark-s-cleverley.medium.com/?source=post_internal_links---------3----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Mark Cleverley</a></span></div></span></div></div></div></div></div><div class="ds hi s ta tb"><a href="https://mark-s-cleverley.medium.com/yolov4-the-subtleties-of-high-speed-object-detection-91eced12c6a4?source=post_internal_links---------3----------------------------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr s" rel="noopener"><div class="hw s ah hx"><div class="tc hz s"><div class="ep hr fk es eo hs w ht hu hv"><img class="fk es eo hs w ia ib et xq" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_n5CYdeBjFGVabmacmZwDiw.jpeg" width="70" height="70" role="presentation"></div><img class="us vi td te tf tg th ti tj tk tl tm c" width="70" height="70" role="presentation" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_n5CYdeBjFGVabmacmZwDiw(1).jpeg" srcset="https://miro.medium.com/fit/c/60/88/1*n5CYdeBjFGVabmacmZwDiw.jpeg 48w, https://miro.medium.com/fit/c/88/88/1*n5CYdeBjFGVabmacmZwDiw.jpeg 70w" sizes="70px"><noscript></noscript></div></div></a></div></div></div></div></div><div class="rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk"><div class="sl sm s"><div class="w hs"><div class="n cd"><div class="s sn so sp sq"><div class="sr s"><h2 class="au je pi pj jh pl pm jk ss st jo su sv js sw sx jw gq"><a rel="noopener" href="https://medium.com/analytics-vidhya/machine-learning-how-to-handle-class-imbalance-920e48c3e970?source=post_internal_links---------4----------------------------">Machine Learning: How to Handle Class Imbalance</a></h2></div><div class="o n"><div></div><div class="w s"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div class="ck n o sy"><span class="au b pa aw gq"><a href="https://ken-hoffman.medium.com/?source=post_internal_links---------4----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Ken Hoffman</a><span> in <a href="https://medium.com/analytics-vidhya?source=post_internal_links---------4----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Analytics Vidhya</a></span></span></div></span></div></div></div></div></div><div class="ds hi s ta tb"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr s" rel="noopener" href="https://medium.com/analytics-vidhya/machine-learning-how-to-handle-class-imbalance-920e48c3e970?source=post_internal_links---------4----------------------------"><div class="hw s ah hx"><div class="tc hz s"><div class="us vi fk es eo hs w ht hu hv"><img class="fk es eo hs w ia ib ic" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_oBdmmY8h4CKbqemwjC-9kw.png" width="70" height="70" role="presentation"></div><img class="ep hr td te tf tg th ti tj tk tl tm c" width="70" height="70" role="presentation"><noscript></noscript></div></div></a></div></div></div></div></div><div class="rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk"><div class="sl sm s"><div class="w hs"><div class="n cd"><div class="s sn so sp sq"><div class="sr s"><h2 class="au je pi pj jh pl pm jk ss st jo su sv js sw sx jw gq"><a rel="noopener" href="https://medium.com/swlh/machine-learning-superfoods-healthy-and-sustainable-machine-learning-pipelines-91cd7bd9a9?source=post_internal_links---------5----------------------------">Machine Learning Superfoods — Healthy and Sustainable Machine Learning Pipelines</a></h2></div><div class="o n"><div></div><div class="w s"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div class="ck n o sy"><span class="au b pa aw gq"><a href="https://shikhasaxena7fe.medium.com/?source=post_internal_links---------5----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Shikha Saxena</a><span> in <a href="https://medium.com/swlh?source=post_internal_links---------5----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">The Startup</a></span></span></div></span></div></div></div></div></div><div class="ds hi s ta tb"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr s" rel="noopener" href="https://medium.com/swlh/machine-learning-superfoods-healthy-and-sustainable-machine-learning-pipelines-91cd7bd9a9?source=post_internal_links---------5----------------------------"><div class="hw s ah hx"><div class="tc hz s"><div class="us vi fk es eo hs w ht hu hv"><img class="fk es eo hs w ia ib ic" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/0_Sbdrw9DTJ7uwleDx" width="70" height="70" role="presentation"></div><img class="ep hr td te tf tg th ti tj tk tl tm c" width="70" height="70" role="presentation"><noscript></noscript></div></div></a></div></div></div></div></div><div class="rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk"><div class="sl sm s"><div class="w hs"><div class="n cd"><div class="s sn so sp sq"><div class="sr s"><h2 class="au je pi pj jh pl pm jk ss st jo su sv js sw sx jw gq"><a href="https://pangkh98.medium.com/multi-step-multivariate-time-series-forecasting-using-lstm-92c6d22cd9c2?source=post_internal_links---------6----------------------------" rel="noopener">Multi-Step Multivariate Time-Series Forecasting using LSTM</a></h2></div><div class="o n"><div></div><div class="w s"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div class="ck n o sy"><span class="au b pa aw gq"><a href="https://pangkh98.medium.com/?source=post_internal_links---------6----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Pang K.H.</a></span></div></span></div></div></div></div></div><div class="ds hi s ta tb"><a href="https://pangkh98.medium.com/multi-step-multivariate-time-series-forecasting-using-lstm-92c6d22cd9c2?source=post_internal_links---------6----------------------------" class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr s" rel="noopener"><div class="hw s ah hx"><div class="tc hz s"><div class="us vi fk es eo hs w ht hu hv"><img class="fk es eo hs w ia ib ic" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_3z3IKfKJHQP7ymi3lBHHgA.jpeg" width="70" height="70" role="presentation"></div><img class="ep hr td te tf tg th ti tj tk tl tm c" width="70" height="70" role="presentation"><noscript></noscript></div></div></a></div></div></div></div></div><div class="rq rr rs rt ru rv rw rx ry rz sa sb sc sd se sf sg sh si sj sk"><div class="sl sm s"><div class="w hs"><div class="n cd"><div class="s sn so sp sq"><div class="sr s"><h2 class="au je pi pj jh pl pm jk ss st jo su sv js sw sx jw gq"><a rel="noopener" href="https://medium.com/analytics-vidhya/how-to-create-a-language-dictionary-92c654d5c78f?source=post_internal_links---------7----------------------------">How To Create A Multiple Language Dictionary Using A Pipeline</a></h2></div><div class="o n"><div></div><div class="w s"><div class="n"><div style="flex: 1 1 0%;"><span class="au b av aw gq"><div class="ck n o sy"><span class="au b pa aw gq"><a class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener" href="https://medium.com/@naeemahaz?source=post_internal_links---------7----------------------------">Naeemah Small</a><span> in <a href="https://medium.com/analytics-vidhya?source=post_internal_links---------7----------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca dq dr" rel="noopener">Analytics Vidhya</a></span></span></div></span></div></div></div></div></div><div class="ds hi s ta tb"><a class="dm dn bt bu bv bw bx by bz bf do dp ca dq dr s" rel="noopener" href="https://medium.com/analytics-vidhya/how-to-create-a-language-dictionary-92c654d5c78f?source=post_internal_links---------7----------------------------"><div class="hw s ah hx"><div class="tc hz s"><div class="us vi fk es eo hs w ht hu hv"><img class="fk es eo hs w ia ib ic" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_6lSD6HSaelHLRYGtkuR6NA.jpeg" width="70" height="70" role="presentation"></div><img class="ep hr td te tf tg th ti tj tk tl tm c" width="70" height="70" role="presentation"><noscript></noscript></div></div></a></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="tn s to tp"><div class="n p"><div class="aj ak al am an ao ap w"><div class="n ac"><div class="n o cd"><a class="dm dn bt bu bv bw bx by bz bf tq tr ca ts tt" rel="noopener" href="https://medium.com/?source=post_page-----a1815655cd8--------------------------------"><svg viewBox="0 0 3940 610" class="dy tu"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><div class="v tv n cd tw cf"><p class="au b dh di tx"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----a1815655cd8--------------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca ts tt" rel="noopener">About</a></p><p class="au b dh di tx"><a href="https://help.medium.com/hc/en-us?source=post_page-----a1815655cd8--------------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca ts tt" rel="noopener">Help</a></p><p class="au b dh di tx"><a href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----a1815655cd8--------------------------------" class="dm dn bt bu bv bw bx by bz bf sz ca ts tt" rel="noopener">Legal</a></p></div></div><div class="ae ty tz cf"><p class="au b dh di ua">Get the Medium app</p></div><div class="ae ty ub cf uc"><div class="at s"><a href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----a1815655cd8--------------------------------" class="dm dn bt bu bv bw bx by bz bf tq tr ca ts tt" rel="noopener nofollow"><img alt="A button that says &#39;Download on the App Store&#39;, and if clicked it will lead you to the iOS App store" class="" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_Crl55Tm6yDNMoucPo1tvDg.png" width="135" height="41"></a></div><div class="s"><a href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----a1815655cd8--------------------------------" class="dm dn bt bu bv bw bx by bz bf tq tr ca ts tt" rel="noopener nofollow"><img alt="A button that says &#39;Get it on, Google Play&#39;, and if clicked it will lead you to the Google Play store" class="" src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1_W_RAPQ62h0em559zluJLdQ.png" width="135" height="41"></a></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__ = "main-20210402-230617-739f178f74"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"auroraPage":{"isAuroraPageEnabled":true},"bookReader":{"assets":{},"reader":{"currentAsset":null,"settingsPanelIsOpen":false,"settings":{"fontFamily":"CHARTER","fontScale":"M","publisherStyling":true,"textAlignment":"start","theme":"White","lineSpacing":0,"wordSpacing":0,"letterSpacing":0},"internalNavCounter":0,"currentSelection":null}},"cache":{"experimentGroupSet":true,"reason":"Variant is not enabled for this page","group":"control","tags":[],"serverVariantState":""},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"routingEntity":{"type":"DEFAULT","explicit":false}},"config":{"nodeEnv":"production","version":"main-20210402-230617-739f178f74","isTaggedVersion":false,"target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"main-20210402-230617-739f178f74"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","context":{"deployment":{"target":"production","tag":"main-20210402-230617-739f178f74","commit":"739f178f74dd97ee87223ad43c873041e4f682dc"}},"datacenter":"us"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e","9dc80918cc93","8a9336e5bb4","cef6983b292","54c98c43354d","193b68bd4fba","b7e45b22fec3","55760f21cdc5"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl"},"debug":{"requestId":"fba8a316-1155-46e2-a2bc-01b2251bd6dc","branchDeployConfig":null,"hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"774ffb6b0b83d278","ot-tracer-traceid":"5e77ca1b4dff1e42","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002F@kolloldas\u002Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8","host":"medium.com","hostname":"medium.com","referrer":"https:\u002F\u002Fwww.google.com\u002F","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"session":{"user":{"id":"lo_2b82e86ee221"},"xsrf":"","isSpoofed":false},"tracing":{}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","variantFlags":[{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"android_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"assign_default_topic_to_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"bane_add_user","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"bane_verify_domain","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"branch_seo_metadata","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"default_seo_post_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"deindex_from_external_search_threshold","valueType":{"__typename":"VariantFlagString","value":"1609488000000"}},{"__typename":"VariantFlag","name":"disable_android_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_resume_reading_toast","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_mobile_featured_chunk","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_post_recommended_from_friends_provider","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_local_currency","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_parse_expires_at","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_renewal_failure","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_about_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_general_admission","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_nav","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profile_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_sticky_nav","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_tag_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_autotier","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automated_mission_control_triggers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_text_me_the_app","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding_fonts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cleansweep_double_writes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_client_error_tracking","valueType":{"__typename":"VariantFlagString","value":"none"}},{"__typename":"VariantFlag","name":"enable_collaborative_filtering_rex_sourcing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_confirm_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cta_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_custom_domain_v2_settings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_dedicated_series_tab_api_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_feature_logging","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_earn_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_edit_alt_text","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_embedding_based_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_end_of_post_cleanup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_evhead_com_to_ev_medium_com_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_expanded_feature_chunk_pool","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_by_resend_rules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_expire_processor","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_global_susi_modal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook_subscription_cancelled","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_highlander_member_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_hightower_user_minimum_guarantee","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_homepage_who_to_follow_module","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_homepage_write_button","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_post_stats","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_json_logs_trained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_app_highlights","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kiln_for_digest_editors_picks","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_auto_expand_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_notifications","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pay_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_cd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pub_homepage_for_selected_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_stories","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_topics","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_unread_notification_count_mutation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_login_code_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_media_resource_try_catch","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_member_only_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_membership_remove_section_a","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_miro_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mission_control","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mps_digest_rendering","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mute","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_checkout_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_collaborative_filtering_data","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_login_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_three_dot_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_parsely","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_patronus_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_popularity_feature","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_page_nav_stickiness_removal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_settings_screen","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_tax_status_clarity","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_primary_topic_for_mobile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_design_reminder","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_page_seo_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_publish_to_email_for_publication_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_receipt_notes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_all","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_edit_and_delete","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_moderation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_follow_feed_cache","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rtr_channel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_s3_sites","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_save_to_medium","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_signup_friction","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace_ranker_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_stripegate","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipalti_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trending_posts_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_triton_predictions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trumpland_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_twitter_auth_suggestions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"entity_driven_subscription_milestone_1","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound"}},{"__typename":"VariantFlag","name":"google_sign_in_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_generic_home_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_pub_follow_email_opt_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"is_not_medium_subscriber","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_fastrak","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_stripe_express","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"make_nav_sticky","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"new_transition_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"provider_for_credit_card_form","valueType":{"__typename":"VariantFlagString","value":"BRAINTREE"}},{"__typename":"VariantFlag","name":"pub_sidebar","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefine_average_post_reading_time","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"remove_low_quality_posts_from_internal_search","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"remove_post_post_similarity","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"retrained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sign_up_with_email_button","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"suppress_apple_missing_expires_date_alert","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"tag_feed_load_test","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"use_new_admin_topic_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"viewer":null,"postResult({\"id\":\"a1815655cd8\"})":{"__ref":"Post:a1815655cd8"},"meterPost({\"postId\":\"a1815655cd8\",\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\",\"sk\":null}})":{"__ref":"MeteringInfo:{}"}},"User:a71ada66b97f":{"id":"a71ada66b97f","__typename":"User","isFollowing":null,"viewerIsUser":false,"customStyleSheet":null,"isSuspended":false,"name":"Kollol Das","hasCompletedProfile":false,"bio":"Developer and NLP Researcher","imageId":"1*z3gp0qUFWyfdZ7DYK6cNSw.png","username":"kolloldas","customDomainState":null,"isAuroraVisible":true,"createdAt":0,"mediumMemberAt":0,"lastPostCreatedAt":0,"socialStats":{"__typename":"SocialStats","followerCount":78,"followingCount":1},"hasSubdomain":false,"isAllowEdsEnabled":false,"isBlocking":null,"isMuting":null,"allowNotes":true,"newsletterV3":null,"twitterScreenName":"","followedCollections":0,"atsQualifiedAt":1612205457182},"Paragraph:6e2078896c9c_0":{"id":"6e2078896c9c_0","__typename":"Paragraph","name":"4fdb","text":"Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_1":{"id":"6e2078896c9c_1","__typename":"Paragraph","name":"736a","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*nIR0CnZVd7d-RRno8_F26Q.jpeg"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_2":{"id":"6e2078896c9c_2","__typename":"Paragraph","name":"01d8","text":"Attention mechanisms have taken the deep learning world by storm in the last few years. It is not uncommon nowadays to have an attention related component somewhere in your model. Last year Google pushed attention mechanisms to the extreme when it came out with the Transformer models in its infamous “Attention is all you need” paper. As the title says, Transformer models ditch recurrent layers for a combination of attention and regular feedforward networks. Not only is the model faster and scalable but it is also more interpretable because we can examine its attention weights to know what it focuses on. While this newfound approach has earned the Transformer new records in translation tasks no one seems have attempted apply this model to sequence tagging tasks yet. This is an area where RNNs still rule the roost. Would the Transformer be able to take out the venerable BiLSTM? I felt it was a great excuse to build our own implementation and that’s what this post will explain.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":301,"end":328,"type":"A","href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.03762","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_3":{"id":"6e2078896c9c_3","__typename":"Paragraph","name":"e901","text":"Overview","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_4":{"id":"6e2078896c9c_4","__typename":"Paragraph","name":"0e59","text":"In this two part series we are going to build the Transformer model from scratch and make it compete with a BiLSTM model on the chunking task. We’ll do zero math and instead look at the concepts visually.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_5":{"id":"6e2078896c9c_5","__typename":"Paragraph","name":"955a","text":"This first part will go through the implementation of the core components that make the Transformer — Multi Head Attention and Position wise Feed Forward Network. We’ll especially detail out the inner workings of attention mechanisms.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":102,"end":122,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":127,"end":161,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_6":{"id":"6e2078896c9c_6","__typename":"Paragraph","name":"243b","text":"The second part will focus on implementing the remaining bits of the Transformer and putting all the parts together. It will conclude with a face off between the Transformer and BiLSTM.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_7":{"id":"6e2078896c9c_7","__typename":"Paragraph","name":"9553","text":"We’ll follow the original Transformer paper to implement our model in PyTorch. But we will incorporate the latest improvements from the TensorfFlow implementation of Transformer as well. We will use the freely available CoNLL 2000 Chunking dataset to run the experiments. If you just want to grab the code it’s all there on Github.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":26,"end":37,"type":"A","href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.03762","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":70,"end":77,"type":"A","href":"http:\u002F\u002Fpytorch.org\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":136,"end":147,"type":"A","href":"https:\u002F\u002Fgithub.com\u002Ftensorflow\u002Ftensor2tensor\u002Fblob\u002Fmaster\u002Ftensor2tensor\u002Fmodels\u002Ftransformer.py","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":220,"end":239,"type":"A","href":"https:\u002F\u002Fwww.clips.uantwerpen.be\u002Fconll2000\u002Fchunking\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":324,"end":330,"type":"A","href":"https:\u002F\u002Fgithub.com\u002Fkolloldas\u002Ftorchnlp","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_8":{"id":"6e2078896c9c_8","__typename":"Paragraph","name":"b6ba","text":"Transformer Guts","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_9":{"id":"6e2078896c9c_9","__typename":"Paragraph","name":"4b12","text":"At the top level, the Transformer has an Encoder and Decoder just like sequence-to-sequence models. If we strip away standard neural network embellishments like Dropout, LayerNorm and residual connections, we’ll find that both blocks have two unique components — Multi Head Attention and Position wise Feedforward. They may sound complicated but are not very different from the regular attention and feed-forward layers.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":161,"end":168,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":170,"end":180,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":263,"end":283,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":288,"end":313,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_10":{"id":"6e2078896c9c_10","__typename":"Paragraph","name":"140a","text":"The Transformer in all its glory. Note some of the changed blocks from the original paper.","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*mq_H9EGUrTiwf5ZfMva4Sg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_11":{"id":"6e2078896c9c_11","__typename":"Paragraph","name":"7824","text":"Multi-Head Attention — The Beast","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_12":{"id":"6e2078896c9c_12","__typename":"Paragraph","name":"d1cc","text":"Multi head attention is essentially attention repeated several times in parallel. (If you are not clear about the intuition behind attention I suggest you see this short video explanation by Andrew Ng on Coursera.) Attention in general can be considered to have three inputs and one output:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":170,"end":175,"type":"A","href":"https:\u002F\u002Fwww.coursera.org\u002Flearn\u002Fnlp-sequence-models\u002Flecture\u002FRDXpX\u002Fattention-model-intuition","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":20,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_13":{"id":"6e2078896c9c_13","__typename":"Paragraph","name":"b04f","text":"Keys: A sequence of vectors also known as the memory. It is the contextual information that we want to look at. In traditional sequence-to-sequence learning they are usually the RNN encoder outputs.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":4,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_14":{"id":"6e2078896c9c_14","__typename":"Paragraph","name":"ace8","text":"Values: A sequence of vectors from which we aggregate the output through a weighted linear combination. Often Keys serve as Values.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":7,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":110,"end":115,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":124,"end":130,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_15":{"id":"6e2078896c9c_15","__typename":"Paragraph","name":"e9ce","text":"Query: A single vector that we use to probe the Keys. By probing we mean the Query is independently combined with each key to arrive at a single probability. The type of attention determines how the combination is done. Usually Query is the decoder RNN state at a given time step in traditional sequence-to-sequence learning","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":6,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":48,"end":52,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":77,"end":82,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":122,"end":123,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":228,"end":234,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_16":{"id":"6e2078896c9c_16","__typename":"Paragraph","name":"0150","text":"Output: A single vector which is derived from a linear combination of the Values using the probabilities from the previous step as weights.","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":7,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":74,"end":81,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_17":{"id":"6e2078896c9c_17","__typename":"Paragraph","name":"7238","text":"With these definitions in place let’s look at the actual implementation in PyTorch. I will assume that you know how nn.Module works. (If not here is an excellent introduction). Let’s jump right into the forward() for out MultiHeadAttention component:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":116,"end":125,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":203,"end":212,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":221,"end":239,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":141,"end":145,"type":"A","href":"http:\u002F\u002Fpytorch.org\u002Ftutorials\u002Fbeginner\u002Fpytorch_with_examples.html","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_18":{"id":"6e2078896c9c_18","__typename":"Paragraph","name":"24a5","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:a9fa222a4112d2622a3fa68e95417463"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_19":{"id":"6e2078896c9c_19","__typename":"Paragraph","name":"d9b1","text":"Flow of operations for Multi Head Attention as per the latest TensorFlow implementation","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*lfuT-DDgVeHrFAq7_05Dvg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_20":{"id":"6e2078896c9c_20","__typename":"Paragraph","name":"2a10","text":"We’ll go step by step repeating code snippets as needed:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_21":{"id":"6e2078896c9c_21","__typename":"Paragraph","name":"9867","text":"1. Project each of the queries, keys and values linearly. By linear projection I mean a single neural network layer without the nonlinear activation. The learnable parameters of these linear projections are important for the attention mechanism:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":3,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_22":{"id":"6e2078896c9c_22","__typename":"Paragraph","name":"3a31","text":"queries = self.query_linear(queries)\nkeys = self.key_linear(keys)        \nvalues = self.value_linear(values)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_23":{"id":"6e2078896c9c_23","__typename":"Paragraph","name":"0ea0","text":"This is how the Linears are defined:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_24":{"id":"6e2078896c9c_24","__typename":"Paragraph","name":"1f0a","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:c9f93d9289b294ec36e5ba75688c8641"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_25":{"id":"6e2078896c9c_25","__typename":"Paragraph","name":"8378","text":"Here input_depth total_key_depth total_value_depth and output_depth are hyperparameters of the model. Note that key and query size should match as we have to do a dot product between them. Because Transformers don’t have recurrent layers we need not process the queries one step at a time. So the query input here is the entire sequence of queries for a particular layer.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":5,"end":16,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":17,"end":32,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":33,"end":50,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":55,"end":67,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":163,"end":174,"type":"A","href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1508.04025","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_26":{"id":"6e2078896c9c_26","__typename":"Paragraph","name":"004f","text":"2. Split the projected inputs into required number of partitions for multi head attention. Instead of working with a separate linear projections for each head or parallel attention we divide a single projection into partitoins and perform attention independently:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":2,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_27":{"id":"6e2078896c9c_27","__typename":"Paragraph","name":"82c0","text":"queries = self._split_heads(queries)        \nkeys = self._split_heads(keys)        \nvalues = self._split_heads(values)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_28":{"id":"6e2078896c9c_28","__typename":"Paragraph","name":"c281","text":"Here’s the _split_heads() function:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":11,"end":25,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_29":{"id":"6e2078896c9c_29","__typename":"Paragraph","name":"d3f8","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:0764f270f6265c0eb104c4a30b2beffc"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_30":{"id":"6e2078896c9c_30","__typename":"Paragraph","name":"b273","text":"The way we split is to reshape the inputs to have an extra heads dimension.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":59,"end":64,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_31":{"id":"6e2078896c9c_31","__typename":"Paragraph","name":"db12","text":"3. Scale the queries by a certain factor. This is supposed to prevent the outputs from growing too big which can make learning difficult:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":3,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_32":{"id":"6e2078896c9c_32","__typename":"Paragraph","name":"8f6c","text":"queries *= self.query_scale","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_33":{"id":"6e2078896c9c_33","__typename":"Paragraph","name":"c2f0","text":"The factor is calculated as the inverse square root of the partition size after splitting:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_34":{"id":"6e2078896c9c_34","__typename":"Paragraph","name":"dcab","text":"self.query_scale = (total_key_depth\u002F\u002Fnum_heads)**-0.5","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_35":{"id":"6e2078896c9c_35","__typename":"Paragraph","name":"c02d","text":"4. Take the dot product between the queries and the keys (since we are doing multiplicative attention). We do that for every query and key pair with one single matmul :","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":160,"end":166,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":2,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_36":{"id":"6e2078896c9c_36","__typename":"Paragraph","name":"fcf0","text":"logits = torch.matmul(queries, keys.permute(0, 1, 3, 2))","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_37":{"id":"6e2078896c9c_37","__typename":"Paragraph","name":"e96b","text":"A lot is happening in that single call so let’s break it down. For illustration we’ll use the following values: sequence_length=10, total_key_depth=32, num_heads=4 which gives us partitions of size 8 after splitting.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":112,"end":130,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":132,"end":150,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":152,"end":163,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_38":{"id":"6e2078896c9c_38","__typename":"Paragraph","name":"a52e","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*LdgVw-tgr6twHCIG1vJp7A.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_39":{"id":"6e2078896c9c_39","__typename":"Paragraph","name":"c926","text":"To get the dot product we must transpose the (last two dimensions of the) key tensor before the matrix multiplication","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_40":{"id":"6e2078896c9c_40","__typename":"Paragraph","name":"dc22","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*C_g9gifaN8ig6StBX8Nbaw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_41":{"id":"6e2078896c9c_41","__typename":"Paragraph","name":"467d","text":"The above figures only show the last two dimensions of the input. But they are actually 4D Tensors. How can matmul do 4D Tensors??","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":108,"end":114,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_42":{"id":"6e2078896c9c_42","__typename":"Paragraph","name":"e40f","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*xqTChgeNxhRcGgXPBiyszw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_43":{"id":"6e2078896c9c_43","__typename":"Paragraph","name":"3299","text":"Turns out it does a matrix multiplication for each higher dimension separately. So as long as the higher dimensions match exactly matmul can handle any number of them.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":130,"end":136,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_44":{"id":"6e2078896c9c_44","__typename":"Paragraph","name":"f59f","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*xvg7D83FnZWhDvJQ-JeOPA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_45":{"id":"6e2078896c9c_45","__typename":"Paragraph","name":"e411","text":"Of course the last two dimensions should follow matrix multiplication rules.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_46":{"id":"6e2078896c9c_46","__typename":"Paragraph","name":"be78","text":"5. Apply a mask on the query key dot products. This step is required mainly for the decoder to prevent future inputs from influencing attention. We’ll cover this in part II.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":3,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_47":{"id":"6e2078896c9c_47","__typename":"Paragraph","name":"ab3b","text":"6. Apply Softmax on the dot products to convert them to probabilities:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":2,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":9,"end":16,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_48":{"id":"6e2078896c9c_48","__typename":"Paragraph","name":"2c04","text":"weights = nn.functional.softmax(logits, dim=-1)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_49":{"id":"6e2078896c9c_49","__typename":"Paragraph","name":"b0ad","text":"7. Add Dropout. This is something that is not there in the original paper but added in the latest TensorFlow implementation.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":2,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":7,"end":15,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_50":{"id":"6e2078896c9c_50","__typename":"Paragraph","name":"a2b3","text":"8. Using the probabilities as weights do a linear combination of the values. Again we use a single matmul to do the job across all values in all partitions.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":99,"end":105,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":2,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":69,"end":75,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_51":{"id":"6e2078896c9c_51","__typename":"Paragraph","name":"a274","text":"contexts = torch.matmul(weights, values)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_52":{"id":"6e2078896c9c_52","__typename":"Paragraph","name":"08de","text":"Continuing the earlier illustration:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_53":{"id":"6e2078896c9c_53","__typename":"Paragraph","name":"9dfc","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*D0d-MgkSxQTz6zrZtiGqjw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_54":{"id":"6e2078896c9c_54","__typename":"Paragraph","name":"343b","text":"With matrix multiplication we get all the outputs in one shot. This is what makes vectorization neat!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_55":{"id":"6e2078896c9c_55","__typename":"Paragraph","name":"b297","text":"9. Now merge the heads back. Or rather reshape the outputs to get the original 3D shape [batch, sequence length, output depth]:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":2,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_56":{"id":"6e2078896c9c_56","__typename":"Paragraph","name":"9fb8","text":"contexts = self._merge_heads(contexts)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_57":{"id":"6e2078896c9c_57","__typename":"Paragraph","name":"16f3","text":"_merge_heads() is just the reverse of split_heads():","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":14,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":38,"end":51,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_58":{"id":"6e2078896c9c_58","__typename":"Paragraph","name":"c4f0","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:b3c70df683947e2a14c981eaf7005ecf"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_59":{"id":"6e2078896c9c_59","__typename":"Paragraph","name":"a0f9","text":"10. Finally we do another linear projection to get the output:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":3,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_60":{"id":"6e2078896c9c_60","__typename":"Paragraph","name":"e61f","text":"outputs = self.output_linear(contexts)","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_61":{"id":"6e2078896c9c_61","__typename":"Paragraph","name":"c34b","text":"So there you have it, Multi Head attention in ten steps. See the full implementation in GitHub here Now let’s go into the next core component, the Positionwise Feedforward network.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":95,"end":99,"type":"A","href":"https:\u002F\u002Fgithub.com\u002Fkolloldas\u002Ftorchnlp\u002Fblob\u002Fmaster\u002Ftorchnlp\u002Fmodules\u002Ftransformer\u002Fsublayers.py","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":147,"end":180,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_62":{"id":"6e2078896c9c_62","__typename":"Paragraph","name":"6449","text":"Positionwise Feedforward Network — The Sidekick","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_63":{"id":"6e2078896c9c_63","__typename":"Paragraph","name":"7dcf","text":"Like the name indicates, this is a regular feedforward network applied to each time step of the Multi Head attention outputs. The network has three layers with a non-linearity like ReLU for the hidden layer. You might be wondering why do we need a feedforward network after attention; after all isn’t attention all we need 😈 ? I suspect it is needed to improve model expressiveness. As we saw earlier the multi head attention partitioned the inputs and applied attention independently. There was only a linear projection to the outputs, i.e. the partitions were combined only linearly. The Positionwise Feedforward network thus brings in some non-linear ‘mixing’ if we call it that. In fact for the sequence tagging task we use convolutions instead of fully connected layers. A filter of width 3 allows interactions to happen with adjacent time steps to improve performance. The implementation in PyTorch is straightforward:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":74,"end":78,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":591,"end":616,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_64":{"id":"6e2078896c9c_64","__typename":"Paragraph","name":"9815","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:b2f3bad617f3b2e33bd030e6e329f8e3"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_65":{"id":"6e2078896c9c_65","__typename":"Paragraph","name":"1acf","text":"self.layers is a nn.ModuleList which can take either linear or convolutional layers. E.g. for linear layers:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":11,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":17,"end":30,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_66":{"id":"6e2078896c9c_66","__typename":"Paragraph","name":"5450","text":"self.layers = nn.ModuleList([\n  nn.Linear(input_depth, filter_size), \n  nn.Linear(filter_size, filter_size), \n  nn.Linear(filter_size, output_depth)\n])","type":"PRE","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_67":{"id":"6e2078896c9c_67","__typename":"Paragraph","name":"132d","text":"Again input_depth filter_size and output_depth are all hyperparameters. (My actual implementation is slightly more complex because it allows the total number of layers and each layer type to be configured.)","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":6,"end":17,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":18,"end":29,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":34,"end":46,"type":"CODE","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:6e2078896c9c_68":{"id":"6e2078896c9c_68","__typename":"Paragraph","name":"259d","text":"With these two components implemented our Transformer is almost completed. All we need to do now is put everything together. The next part will cover that along with some tricks that we apply to improve the model. And of course we’ll run the actual experiments.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:6e2078896c9c_69":{"id":"6e2078896c9c_69","__typename":"Paragraph","name":"d278","text":"Go to Building the Mighty Transformer for Sequence Tagging with PyTorch: Part II","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":6,"end":80,"type":"A","href":"https:\u002F\u002Fmedium.com\u002F@kolloldas\u002Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-ii-c85bf8fd145","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":6,"end":80,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"ImageMetadata:1*nIR0CnZVd7d-RRno8_F26Q.jpeg":{"id":"1*nIR0CnZVd7d-RRno8_F26Q.jpeg","__typename":"ImageMetadata","originalHeight":1440,"originalWidth":2560,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*mq_H9EGUrTiwf5ZfMva4Sg.png":{"id":"1*mq_H9EGUrTiwf5ZfMva4Sg.png","__typename":"ImageMetadata","originalHeight":927,"originalWidth":583,"focusPercentX":null,"focusPercentY":null,"alt":null},"MediaResource:a9fa222a4112d2622a3fa68e95417463":{"id":"a9fa222a4112d2622a3fa68e95417463","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"ImageMetadata:1*lfuT-DDgVeHrFAq7_05Dvg.png":{"id":"1*lfuT-DDgVeHrFAq7_05Dvg.png","__typename":"ImageMetadata","originalHeight":399,"originalWidth":200,"focusPercentX":null,"focusPercentY":null,"alt":null},"MediaResource:c9f93d9289b294ec36e5ba75688c8641":{"id":"c9f93d9289b294ec36e5ba75688c8641","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"MediaResource:0764f270f6265c0eb104c4a30b2beffc":{"id":"0764f270f6265c0eb104c4a30b2beffc","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"ImageMetadata:1*LdgVw-tgr6twHCIG1vJp7A.png":{"id":"1*LdgVw-tgr6twHCIG1vJp7A.png","__typename":"ImageMetadata","originalHeight":145,"originalWidth":297,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*C_g9gifaN8ig6StBX8Nbaw.png":{"id":"1*C_g9gifaN8ig6StBX8Nbaw.png","__typename":"ImageMetadata","originalHeight":186,"originalWidth":490,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*xqTChgeNxhRcGgXPBiyszw.png":{"id":"1*xqTChgeNxhRcGgXPBiyszw.png","__typename":"ImageMetadata","originalHeight":221,"originalWidth":218,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*xvg7D83FnZWhDvJQ-JeOPA.png":{"id":"1*xvg7D83FnZWhDvJQ-JeOPA.png","__typename":"ImageMetadata","originalHeight":235,"originalWidth":155,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*D0d-MgkSxQTz6zrZtiGqjw.png":{"id":"1*D0d-MgkSxQTz6zrZtiGqjw.png","__typename":"ImageMetadata","originalHeight":256,"originalWidth":504,"focusPercentX":null,"focusPercentY":null,"alt":null},"MediaResource:b3c70df683947e2a14c981eaf7005ecf":{"id":"b3c70df683947e2a14c981eaf7005ecf","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"MediaResource:b2f3bad617f3b2e33bd030e6e329f8e3":{"id":"b2f3bad617f3b2e33bd030e6e329f8e3","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"Tag:machine-learning":{"id":"machine-learning","__typename":"Tag","displayTitle":"Machine Learning","normalizedTagSlug":""},"Tag:artificial-intelligence":{"id":"artificial-intelligence","__typename":"Tag","displayTitle":"Artificial Intelligence","normalizedTagSlug":""},"Tag:neural-networks":{"id":"neural-networks","__typename":"Tag","displayTitle":"Neural Networks","normalizedTagSlug":""},"Tag:pytorch":{"id":"pytorch","__typename":"Tag","displayTitle":"Pytorch","normalizedTagSlug":""},"Tag:nlp":{"id":"nlp","__typename":"Tag","displayTitle":"NLP","normalizedTagSlug":""},"ImageMetadata:1*-WFfHL24zz_mOZM7_blSOQ.png":{"id":"1*-WFfHL24zz_mOZM7_blSOQ.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"Collection:f5af2b715248":{"id":"f5af2b715248","__typename":"Collection","name":"The Startup","domain":null,"slug":"swlh"},"User:d5d47d10c0e9":{"id":"d5d47d10c0e9","__typename":"User","name":"Daryl Tan","username":"daryl-tan","bio":"AV Machine Learning Engineer","imageId":"2*HNVsBoEb2aYvPS_Mitihog.png","mediumMemberAt":1574603122000,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"daryl-tan.medium.com"}},"hasSubdomain":true,"isFollowing":null},"Post:911c78167a94":{"id":"911c78167a94","__typename":"Post","title":"Camera-Lidar Projection: Navigating between 2D and 3D","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fcamera-lidar-projection-navigating-between-2d-and-3d-911c78167a94","previewImage":{"__ref":"ImageMetadata:1*-WFfHL24zz_mOZM7_blSOQ.png"},"isPublished":true,"firstPublishedAt":1580401909422,"readingTime":7.528301886792453,"statusForCollection":"APPROVED","isLocked":true,"visibility":"LOCKED","collection":{"__ref":"Collection:f5af2b715248"},"creator":{"__ref":"User:d5d47d10c0e9"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*J9SQ1JdVMe1pSB-jePs1zg.jpeg":{"id":"1*J9SQ1JdVMe1pSB-jePs1zg.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:51879ac498f2":{"id":"51879ac498f2","__typename":"User","name":"Uday Marepalli","username":"uday.marepalli","bio":"At the intersection of technology, startups and business.","imageId":"1*2Os7tI5ZmJzI6h_7tTZ0sw.jpeg","mediumMemberAt":0,"customDomainState":null,"hasSubdomain":false,"isFollowing":null},"Post:9111b2e233f6":{"id":"9111b2e233f6","__typename":"Post","title":"A 3 step guide to assess any business use-case of AI","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fa-3-step-guide-to-assess-any-business-use-case-of-ai-9111b2e233f6","previewImage":{"__ref":"ImageMetadata:1*J9SQ1JdVMe1pSB-jePs1zg.jpeg"},"isPublished":true,"firstPublishedAt":1546517542989,"readingTime":8.973584905660378,"statusForCollection":"APPROVED","isLocked":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:f5af2b715248"},"creator":{"__ref":"User:51879ac498f2"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*XO3sOjsr7wZT6TrgFAdwmw.jpeg":{"id":"1*XO3sOjsr7wZT6TrgFAdwmw.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"Collection:7219b4dc6c4c":{"id":"7219b4dc6c4c","__typename":"Collection","name":"Analytics Vidhya","domain":null,"slug":"analytics-vidhya"},"User:9dce31355a2e":{"id":"9dce31355a2e","__typename":"User","name":"Swapnil Vishwakarma","username":"swapnil-vishwakarma","bio":"Data Science Intern @Data Glacier | LinkedIn: https:\u002F\u002Fbit.ly\u002F3ltBarT | Github: https:\u002F\u002Fbit.ly\u002F3rQAYoH","imageId":"0*e3Ka4XpQ8lPUhGRG.jpg","mediumMemberAt":0,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"swapnil-vishwakarma.medium.com"}},"hasSubdomain":true,"isFollowing":null},"Post:90acec9e8726":{"id":"90acec9e8726","__typename":"Post","title":"Different metrics to evaluate the performance of a Machine Learning model","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fanalytics-vidhya\u002Fdifferent-metrics-to-evaluate-the-performance-of-a-machine-learning-model-90acec9e8726","previewImage":{"__ref":"ImageMetadata:1*XO3sOjsr7wZT6TrgFAdwmw.jpeg"},"isPublished":true,"firstPublishedAt":1615702745414,"readingTime":12.922641509433962,"statusForCollection":"APPROVED","isLocked":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7219b4dc6c4c"},"creator":{"__ref":"User:9dce31355a2e"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*n5CYdeBjFGVabmacmZwDiw.jpeg":{"id":"1*n5CYdeBjFGVabmacmZwDiw.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:82a316983f2c":{"id":"82a316983f2c","__typename":"User","name":"Mark Cleverley","username":"mark-s-cleverley","bio":"data scientist, machine learning engineer. passionate about ecology, biotech and AI. https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fmark-s-cleverley\u002F","imageId":"0*ksFyTOj6Q4XjE3TL.jpg","mediumMemberAt":0,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"mark-s-cleverley.medium.com"}},"hasSubdomain":true,"isFollowing":null},"Post:91eced12c6a4":{"id":"91eced12c6a4","__typename":"Post","title":"YOLOv4: The Subtleties of High-Speed Object Detection","mediumUrl":"https:\u002F\u002Fmark-s-cleverley.medium.com\u002Fyolov4-the-subtleties-of-high-speed-object-detection-91eced12c6a4","previewImage":{"__ref":"ImageMetadata:1*n5CYdeBjFGVabmacmZwDiw.jpeg"},"isPublished":true,"firstPublishedAt":1595198582537,"readingTime":7.686792452830189,"statusForCollection":null,"isLocked":true,"visibility":"LOCKED","collection":null,"creator":{"__ref":"User:82a316983f2c"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*oBdmmY8h4CKbqemwjC-9kw.png":{"id":"1*oBdmmY8h4CKbqemwjC-9kw.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:1a74c7f727fa":{"id":"1a74c7f727fa","__typename":"User","name":"Ken Hoffman","username":"ken-hoffman","bio":"","imageId":"1*587LKT55pOBBEOqSmdSZTA.jpeg","mediumMemberAt":0,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"ken-hoffman.medium.com"}},"hasSubdomain":true,"isFollowing":null},"Post:920e48c3e970":{"id":"920e48c3e970","__typename":"Post","title":"Machine Learning: How to Handle Class Imbalance","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fanalytics-vidhya\u002Fmachine-learning-how-to-handle-class-imbalance-920e48c3e970","previewImage":{"__ref":"ImageMetadata:1*oBdmmY8h4CKbqemwjC-9kw.png"},"isPublished":true,"firstPublishedAt":1613253990532,"readingTime":3.2292452830188676,"statusForCollection":"APPROVED","isLocked":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7219b4dc6c4c"},"creator":{"__ref":"User:1a74c7f727fa"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*Sbdrw9DTJ7uwleDx":{"id":"0*Sbdrw9DTJ7uwleDx","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:b2ead3fbe8a7":{"id":"b2ead3fbe8a7","__typename":"User","name":"Shikha Saxena","username":"shikhasaxena7fe","bio":"Working on end to end Machine Learning https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fshikhasaxena97\u002F","imageId":"1*gKr26YkIbAVFiosDNnd_4A.png","mediumMemberAt":0,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"shikhasaxena7fe.medium.com"}},"hasSubdomain":true,"isFollowing":null},"Post:91cd7bd9a9":{"id":"91cd7bd9a9","__typename":"Post","title":"Machine Learning Superfoods — Healthy and Sustainable Machine Learning Pipelines","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fswlh\u002Fmachine-learning-superfoods-healthy-and-sustainable-machine-learning-pipelines-91cd7bd9a9","previewImage":{"__ref":"ImageMetadata:0*Sbdrw9DTJ7uwleDx"},"isPublished":true,"firstPublishedAt":1595626268909,"readingTime":4.281132075471698,"statusForCollection":"APPROVED","isLocked":true,"visibility":"LOCKED","collection":{"__ref":"Collection:f5af2b715248"},"creator":{"__ref":"User:b2ead3fbe8a7"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*3z3IKfKJHQP7ymi3lBHHgA.jpeg":{"id":"1*3z3IKfKJHQP7ymi3lBHHgA.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:c6e25dbb9e63":{"id":"c6e25dbb9e63","__typename":"User","name":"Pang K.H.","username":"pangkh98","bio":"Degree in Electrical & Electronics, ML enthusiast","imageId":"0*hyoTEYCo5fEqRAju.jpg","mediumMemberAt":0,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"pangkh98.medium.com"}},"hasSubdomain":true,"isFollowing":null},"Post:92c6d22cd9c2":{"id":"92c6d22cd9c2","__typename":"Post","title":"Multi-Step Multivariate Time-Series Forecasting using LSTM","mediumUrl":"https:\u002F\u002Fpangkh98.medium.com\u002Fmulti-step-multivariate-time-series-forecasting-using-lstm-92c6d22cd9c2","previewImage":{"__ref":"ImageMetadata:1*3z3IKfKJHQP7ymi3lBHHgA.jpeg"},"isPublished":true,"firstPublishedAt":1607076056302,"readingTime":8.582075471698113,"statusForCollection":null,"isLocked":false,"visibility":"PUBLIC","collection":null,"creator":{"__ref":"User:c6e25dbb9e63"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*6lSD6HSaelHLRYGtkuR6NA.jpeg":{"id":"1*6lSD6HSaelHLRYGtkuR6NA.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:e449fc8bdc50":{"id":"e449fc8bdc50","__typename":"User","name":"Naeemah Small","username":"naeemahaz","bio":"Expert ability to analyze and interpret complex data models to identify key operational impacts to drive positive results. Work with Python and R.","imageId":"1*g--2I19FI-69oHEp_lpziQ.jpeg","mediumMemberAt":0,"customDomainState":null,"hasSubdomain":false,"isFollowing":null},"Post:92c654d5c78f":{"id":"92c654d5c78f","__typename":"Post","title":"How To Create A Multiple Language Dictionary Using A Pipeline","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fanalytics-vidhya\u002Fhow-to-create-a-language-dictionary-92c654d5c78f","previewImage":{"__ref":"ImageMetadata:1*6lSD6HSaelHLRYGtkuR6NA.jpeg"},"isPublished":true,"firstPublishedAt":1602910898652,"readingTime":4.373584905660378,"statusForCollection":"APPROVED","isLocked":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7219b4dc6c4c"},"creator":{"__ref":"User:e449fc8bdc50"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"Post:a1815655cd8":{"id":"a1815655cd8","__typename":"Post","canonicalUrl":"","collection":null,"content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\",\"sk\":null}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","isCacheableContent":false,"bodyModel":{"__typename":"RichText","paragraphs":[{"__ref":"Paragraph:6e2078896c9c_0"},{"__ref":"Paragraph:6e2078896c9c_1"},{"__ref":"Paragraph:6e2078896c9c_2"},{"__ref":"Paragraph:6e2078896c9c_3"},{"__ref":"Paragraph:6e2078896c9c_4"},{"__ref":"Paragraph:6e2078896c9c_5"},{"__ref":"Paragraph:6e2078896c9c_6"},{"__ref":"Paragraph:6e2078896c9c_7"},{"__ref":"Paragraph:6e2078896c9c_8"},{"__ref":"Paragraph:6e2078896c9c_9"},{"__ref":"Paragraph:6e2078896c9c_10"},{"__ref":"Paragraph:6e2078896c9c_11"},{"__ref":"Paragraph:6e2078896c9c_12"},{"__ref":"Paragraph:6e2078896c9c_13"},{"__ref":"Paragraph:6e2078896c9c_14"},{"__ref":"Paragraph:6e2078896c9c_15"},{"__ref":"Paragraph:6e2078896c9c_16"},{"__ref":"Paragraph:6e2078896c9c_17"},{"__ref":"Paragraph:6e2078896c9c_18"},{"__ref":"Paragraph:6e2078896c9c_19"},{"__ref":"Paragraph:6e2078896c9c_20"},{"__ref":"Paragraph:6e2078896c9c_21"},{"__ref":"Paragraph:6e2078896c9c_22"},{"__ref":"Paragraph:6e2078896c9c_23"},{"__ref":"Paragraph:6e2078896c9c_24"},{"__ref":"Paragraph:6e2078896c9c_25"},{"__ref":"Paragraph:6e2078896c9c_26"},{"__ref":"Paragraph:6e2078896c9c_27"},{"__ref":"Paragraph:6e2078896c9c_28"},{"__ref":"Paragraph:6e2078896c9c_29"},{"__ref":"Paragraph:6e2078896c9c_30"},{"__ref":"Paragraph:6e2078896c9c_31"},{"__ref":"Paragraph:6e2078896c9c_32"},{"__ref":"Paragraph:6e2078896c9c_33"},{"__ref":"Paragraph:6e2078896c9c_34"},{"__ref":"Paragraph:6e2078896c9c_35"},{"__ref":"Paragraph:6e2078896c9c_36"},{"__ref":"Paragraph:6e2078896c9c_37"},{"__ref":"Paragraph:6e2078896c9c_38"},{"__ref":"Paragraph:6e2078896c9c_39"},{"__ref":"Paragraph:6e2078896c9c_40"},{"__ref":"Paragraph:6e2078896c9c_41"},{"__ref":"Paragraph:6e2078896c9c_42"},{"__ref":"Paragraph:6e2078896c9c_43"},{"__ref":"Paragraph:6e2078896c9c_44"},{"__ref":"Paragraph:6e2078896c9c_45"},{"__ref":"Paragraph:6e2078896c9c_46"},{"__ref":"Paragraph:6e2078896c9c_47"},{"__ref":"Paragraph:6e2078896c9c_48"},{"__ref":"Paragraph:6e2078896c9c_49"},{"__ref":"Paragraph:6e2078896c9c_50"},{"__ref":"Paragraph:6e2078896c9c_51"},{"__ref":"Paragraph:6e2078896c9c_52"},{"__ref":"Paragraph:6e2078896c9c_53"},{"__ref":"Paragraph:6e2078896c9c_54"},{"__ref":"Paragraph:6e2078896c9c_55"},{"__ref":"Paragraph:6e2078896c9c_56"},{"__ref":"Paragraph:6e2078896c9c_57"},{"__ref":"Paragraph:6e2078896c9c_58"},{"__ref":"Paragraph:6e2078896c9c_59"},{"__ref":"Paragraph:6e2078896c9c_60"},{"__ref":"Paragraph:6e2078896c9c_61"},{"__ref":"Paragraph:6e2078896c9c_62"},{"__ref":"Paragraph:6e2078896c9c_63"},{"__ref":"Paragraph:6e2078896c9c_64"},{"__ref":"Paragraph:6e2078896c9c_65"},{"__ref":"Paragraph:6e2078896c9c_66"},{"__ref":"Paragraph:6e2078896c9c_67"},{"__ref":"Paragraph:6e2078896c9c_68"},{"__ref":"Paragraph:6e2078896c9c_69"}],"sections":[{"__typename":"Section","name":"ff9d","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}]}},"creator":{"__ref":"User:a71ada66b97f"},"customStyleSheet":null,"firstPublishedAt":1524041682118,"isLocked":false,"isPublished":true,"isShortform":false,"layerCake":0,"primaryTopic":null,"title":"Building the Mighty Transformer for Sequence Tagging in PyTorch : Part I","isMarkedPaywallOnly":false,"readCreatorPostsCount":0,"mediumUrl":"https:\u002F\u002Fmedium.com\u002F@kolloldas\u002Fbuilding-the-mighty-transformer-for-sequence-tagging-in-pytorch-part-i-a1815655cd8","isLimitedState":false,"visibility":"PUBLIC","license":"ALL_RIGHTS_RESERVED","allowResponses":true,"newsletterId":"","sequence":null,"tags":[{"__ref":"Tag:machine-learning"},{"__ref":"Tag:artificial-intelligence"},{"__ref":"Tag:neural-networks"},{"__ref":"Tag:pytorch"},{"__ref":"Tag:nlp"}],"topics":[{"__typename":"Topic","topicId":"1eca0103fff3","name":"Machine Learning"}],"viewerClapCount":0,"showSubscribeToProfilePromo":false,"showSubscribeToCollectionNewsletterV3Promo":false,"inResponseToPostResult":null,"isNewsletter":false,"socialTitle":"","socialDek":"","noIndex":null,"curationStatus":null,"metaDescription":"","latestPublishedAt":1529757502127,"readingTime":6.767295597484276,"previewContent":{"__typename":"PreviewContent","subtitle":"Attention mechanisms have taken the deep learning world by storm in the last few years. It is not uncommon nowadays to have an attention…"},"previewImage":{"__ref":"ImageMetadata:1*nIR0CnZVd7d-RRno8_F26Q.jpeg"},"creatorPartnerProgramEnrollmentStatus":"PERMISSION_DENIED","clapCount":326,"lockedSource":"LOCKED_POST_SOURCE_NONE","isSuspended":false,"pendingCollection":null,"statusForCollection":null,"pinnedAt":0,"pinnedByCreatorAt":0,"curationEligibleAt":0,"responseDistribution":"NOT_DISTRIBUTED","shareKey":null,"internalLinks({\"paging\":{\"limit\":8}})":{"__typename":"InternalLinksConnection","items":[{"__ref":"Post:911c78167a94"},{"__ref":"Post:9111b2e233f6"},{"__ref":"Post:90acec9e8726"},{"__ref":"Post:91eced12c6a4"},{"__ref":"Post:920e48c3e970"},{"__ref":"Post:91cd7bd9a9"},{"__ref":"Post:92c6d22cd9c2"},{"__ref":"Post:92c654d5c78f"}]},"collaborators":[],"translationSourcePost":null,"inResponseToMediaResource":null,"audioVersionUrl":"","seoTitle":"","updatedAt":1529757502127,"shortformType":"SHORTFORM_TYPE_LINK","structuredData":"","seoDescription":"","postResponses":{"__typename":"PostResponses","count":1},"latestPublishedVersion":"6e2078896c9c","isPublishToEmail":false,"readingList":"READING_LIST_NONE","voterCount":76,"recommenders":[]},"MeteringInfo:{}":{"__typename":"MeteringInfo","postIds":[],"maxUnlockCount":3,"unlocksRemaining":0}}</script><script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/manifest.a8800a5b.js.download"></script><script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/870.7d7441d0.js.download"></script><script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/main.ece9e02a.js.download"></script><script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/5573.159bf40f.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/instrumentation.372969f8.chunk.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/reporting.b852991c.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1752.a348f767.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1491.c08ce3ca.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/4964.fb36722e.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/8342.6aa0b45e.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/9692.90fec906.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/4586.5d6d44cc.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/5064.e0fb94df.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/9046.f95d4b20.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/2846.a0cdf4b3.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/7012.40260101.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/6230.b03cfb97.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/9972.0609b472.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/5127.fe128101.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/8580.59306eb8.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/8751.218c9a13.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/2955.b4efc833.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/7131.d651bf17.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/9546.6595c8a2.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/8127.1c99358b.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/2514.eb9a5ab7.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/6371.142e3c8c.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/8995.26570164.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/1725.3775ddee.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/3874.7f6fdc49.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/8953.db5f047a.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/8286.d433fa28.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/5801.a44fbe07.chunk.js.download"></script>
<script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/Post.8f64be45.chunk.js.download"></script><script>window.main();</script><script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/p.js.download" async="" id="parsely-cf"></script><script src="./Building the Mighty Transformer for Sequence Tagging in PyTorch _ Part I _ by Kollol Das _ Medium_files/client" async=""></script></body></html>