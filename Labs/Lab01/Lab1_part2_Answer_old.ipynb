{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S02d9PimAZKJ"
   },
   "source": [
    "In this lab we will review some basics of pytorch. Save your answers for this lab as they will be used for part of Lab 2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIDPxv5l2qpI"
   },
   "source": [
    "(1) Create a dataloader for the MNIST training data using torchvision package. Have your dataloader iterate over the training set outputing mini-batches of size 256 image samples. Note you do not need to use the image labels in this lab. You may follow the example in the official pytorch examples: \n",
    "\n",
    "https://github.com/pytorch/examples/blob/master/mnist/main.py#L112-L120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x87b1cdecf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 256\n",
    "batch_size_test = 256\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels =dataiter.next()\n",
    "print(images.shape)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "#   print(len(torch.flatten(example_data[i+10][0])))\n",
    "  plt.imshow(example_data[i+10][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i+10]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14MBuiusdZmA"
   },
   "source": [
    "(2) Using only torch primitives (e.g. torch.matmul, torch._relu, etc) implement a simple feedforward neural network with 2 hidden layers that takes as input MNIST digits and outputs a single scalar value. You may select the hidden layer width (greater than 20) and activations (tanh, relu, sigmoid, others) as desired.  Initialize the weights and biases with uniform random values in the range -1 to 1. Avoid using any functions from torch.nn class. Using the loop from (1) Forward pass through the dataset in mini-batches of 256 and record the time this takes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bhZ0I_q7dnb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9250e-07])\n",
      "tensor([6.5842e-09])\n",
      "tensor([0.0002])\n",
      "tensor([8.8074e-13])\n",
      "tensor([1.6191e-08])\n",
      "tensor([6.9406e-13])\n",
      "tensor([2.5992e-11])\n",
      "tensor([2.3353e-11])\n",
      "tensor([7.8137e-11])\n",
      "tensor([1.1934e-15])\n",
      "tensor([8.9004e-14])\n",
      "tensor([2.2219e-09])\n",
      "tensor([2.2988e-08])\n",
      "tensor([1.1119e-17])\n",
      "tensor([1.])\n",
      "tensor([0.9875])\n",
      "tensor([3.4141e-15])\n",
      "tensor([7.8295e-15])\n",
      "tensor([2.9420e-07])\n",
      "tensor([0.8383])\n",
      "tensor([0.4904])\n",
      "tensor([8.2852e-12])\n",
      "tensor([0.0007])\n",
      "tensor([5.7557e-07])\n",
      "tensor([0.1838])\n",
      "tensor([2.9703e-18])\n",
      "tensor([2.7820e-13])\n",
      "tensor([1.3344e-19])\n",
      "tensor([2.3103e-11])\n",
      "tensor([1.7211e-06])\n",
      "tensor([2.2085e-12])\n",
      "tensor([5.9497e-18])\n",
      "tensor([1.5195e-08])\n",
      "tensor([1.9690e-24])\n",
      "tensor([2.9478e-21])\n",
      "tensor([9.1001e-23])\n",
      "tensor([0.0407])\n",
      "tensor([2.9788e-06])\n",
      "tensor([5.6683e-10])\n",
      "tensor([0.0365])\n",
      "tensor([1.4901e-16])\n",
      "tensor([1.9873e-12])\n",
      "tensor([1.4318e-22])\n",
      "tensor([2.8170e-08])\n",
      "tensor([1.5672e-10])\n",
      "tensor([6.6215e-09])\n",
      "tensor([0.7757])\n",
      "tensor([0.9368])\n",
      "tensor([2.0810e-15])\n",
      "tensor([1.6246e-12])\n",
      "tensor([1.2899e-22])\n",
      "tensor([2.7150e-20])\n",
      "tensor([1.3750e-17])\n",
      "tensor([8.9441e-13])\n",
      "tensor([1.8315e-17])\n",
      "tensor([1.3475e-13])\n",
      "tensor([0.7046])\n",
      "tensor([1.0822e-08])\n",
      "tensor([1.5744e-08])\n",
      "tensor([2.2521e-06])\n",
      "tensor([0.2090])\n",
      "tensor([3.6980e-07])\n",
      "tensor([1.5946e-10])\n",
      "tensor([0.9999])\n",
      "tensor([2.7906e-09])\n",
      "tensor([3.5076e-07])\n",
      "tensor([1.8727e-06])\n",
      "tensor([1.0000])\n",
      "tensor([5.0663e-13])\n",
      "tensor([1.5873e-21])\n",
      "tensor([3.6331e-12])\n",
      "tensor([0.0015])\n",
      "tensor([1.0000])\n",
      "tensor([1.7577e-12])\n",
      "tensor([5.5835e-12])\n",
      "tensor([5.3557e-09])\n",
      "tensor([3.4308e-14])\n",
      "tensor([3.0447e-32])\n",
      "tensor([2.8180e-06])\n",
      "tensor([0.0346])\n",
      "tensor([0.0018])\n",
      "tensor([0.0002])\n",
      "tensor([8.4914e-23])\n",
      "tensor([0.9976])\n",
      "tensor([3.4551e-09])\n",
      "tensor([0.0097])\n",
      "tensor([1.9832e-20])\n",
      "tensor([1.8840e-13])\n",
      "tensor([8.2570e-20])\n",
      "tensor([0.0885])\n",
      "tensor([1.5306e-11])\n",
      "tensor([8.5041e-12])\n",
      "tensor([4.1553e-10])\n",
      "tensor([5.6470e-17])\n",
      "tensor([0.3357])\n",
      "tensor([8.8431e-09])\n",
      "tensor([8.9660e-05])\n",
      "tensor([0.8063])\n",
      "tensor([1.3644e-05])\n",
      "tensor([1.7283e-05])\n",
      "tensor([0.0026])\n",
      "tensor([6.8620e-08])\n",
      "tensor([0.0089])\n",
      "tensor([7.6485e-09])\n",
      "tensor([0.9979])\n",
      "tensor([3.7990e-13])\n",
      "tensor([4.0714e-09])\n",
      "tensor([8.7928e-15])\n",
      "tensor([1.4710e-11])\n",
      "tensor([0.0463])\n",
      "tensor([2.2459e-20])\n",
      "tensor([8.6842e-14])\n",
      "tensor([3.7742e-21])\n",
      "tensor([5.5138e-07])\n",
      "tensor([8.6810e-18])\n",
      "tensor([1.3169e-16])\n",
      "tensor([9.1933e-15])\n",
      "tensor([0.0771])\n",
      "tensor([7.7023e-13])\n",
      "tensor([3.8582e-08])\n",
      "tensor([0.0005])\n",
      "tensor([3.2147e-08])\n",
      "tensor([5.8528e-15])\n",
      "tensor([3.6579e-08])\n",
      "tensor([6.7617e-08])\n",
      "tensor([8.0367e-13])\n",
      "tensor([4.6483e-30])\n",
      "tensor([5.1563e-09])\n",
      "tensor([3.4284e-23])\n",
      "tensor([0.0015])\n",
      "tensor([5.7622e-08])\n",
      "tensor([1.7035e-08])\n",
      "tensor([3.3508e-19])\n",
      "tensor([8.9816e-22])\n",
      "tensor([1.2966e-19])\n",
      "tensor([4.8353e-14])\n",
      "tensor([1.0200e-14])\n",
      "tensor([8.3944e-07])\n",
      "tensor([3.6256e-06])\n",
      "tensor([2.3102e-11])\n",
      "tensor([0.0002])\n",
      "tensor([4.6523e-10])\n",
      "tensor([0.9998])\n",
      "tensor([0.9991])\n",
      "tensor([4.5729e-20])\n",
      "tensor([5.7764e-11])\n",
      "tensor([3.3815e-14])\n",
      "tensor([6.3918e-23])\n",
      "tensor([3.8539e-10])\n",
      "tensor([7.2348e-11])\n",
      "tensor([2.9015e-08])\n",
      "tensor([1.8290e-14])\n",
      "tensor([1.2158e-13])\n",
      "tensor([0.5845])\n",
      "tensor([5.6111e-20])\n",
      "tensor([2.7124e-14])\n",
      "tensor([0.0781])\n",
      "tensor([3.4085e-11])\n",
      "tensor([2.2454e-12])\n",
      "tensor([2.1698e-12])\n",
      "tensor([5.1290e-24])\n",
      "tensor([4.9791e-13])\n",
      "tensor([1.0671e-07])\n",
      "tensor([7.5093e-06])\n",
      "tensor([0.9925])\n",
      "tensor([9.1284e-15])\n",
      "tensor([2.5938e-10])\n",
      "tensor([2.2954e-10])\n",
      "tensor([2.8590e-12])\n",
      "tensor([0.0044])\n",
      "tensor([1.9747e-06])\n",
      "tensor([4.7627e-25])\n",
      "tensor([1.6567e-12])\n",
      "tensor([6.5832e-11])\n",
      "tensor([6.5356e-21])\n",
      "tensor([0.9581])\n",
      "tensor([3.8013e-19])\n",
      "tensor([4.1726e-08])\n",
      "tensor([0.0368])\n",
      "tensor([5.1540e-11])\n",
      "tensor([0.0007])\n",
      "tensor([0.0326])\n",
      "tensor([6.8031e-07])\n",
      "tensor([9.4728e-14])\n",
      "tensor([9.7319e-20])\n",
      "tensor([1.0561e-06])\n",
      "tensor([9.6325e-11])\n",
      "tensor([0.0008])\n",
      "tensor([5.2400e-20])\n",
      "tensor([1.6947e-15])\n",
      "tensor([0.0002])\n",
      "tensor([8.9110e-20])\n",
      "tensor([2.3150e-09])\n",
      "tensor([4.7318e-19])\n",
      "tensor([2.0961e-20])\n",
      "tensor([2.0709e-21])\n",
      "tensor([4.8508e-07])\n",
      "tensor([1.2159e-08])\n",
      "tensor([1.5627e-07])\n",
      "tensor([2.7746e-07])\n",
      "tensor([6.1847e-06])\n",
      "tensor([8.9065e-10])\n",
      "tensor([4.5765e-22])\n",
      "tensor([0.2482])\n",
      "tensor([5.6750e-08])\n",
      "tensor([0.1164])\n",
      "tensor([1.5138e-19])\n",
      "tensor([0.9994])\n",
      "tensor([1.0000])\n",
      "tensor([0.0107])\n",
      "tensor([0.9976])\n",
      "tensor([7.0164e-23])\n",
      "tensor([6.1147e-09])\n",
      "tensor([1.4085e-29])\n",
      "tensor([0.0102])\n",
      "tensor([8.8598e-07])\n",
      "tensor([6.3002e-12])\n",
      "tensor([1.7774e-05])\n",
      "tensor([3.4790e-17])\n",
      "tensor([4.0170e-10])\n",
      "tensor([1.2284e-05])\n",
      "tensor([2.2302e-05])\n",
      "tensor([5.8370e-14])\n",
      "tensor([1.0187e-14])\n",
      "tensor([5.7800e-22])\n",
      "tensor([2.3641e-09])\n",
      "tensor([1.4497e-05])\n",
      "tensor([1.8477e-07])\n",
      "tensor([0.0107])\n",
      "tensor([0.9680])\n",
      "tensor([4.7265e-06])\n",
      "tensor([8.5579e-17])\n",
      "tensor([6.9019e-21])\n",
      "tensor([2.6672e-16])\n",
      "tensor([6.3516e-14])\n",
      "tensor([3.6825e-10])\n",
      "tensor([0.3786])\n",
      "tensor([6.4336e-05])\n",
      "tensor([0.2719])\n",
      "tensor([0.0006])\n",
      "tensor([3.0227e-13])\n",
      "tensor([8.5773e-18])\n",
      "tensor([4.5562e-15])\n",
      "tensor([0.0007])\n",
      "tensor([1.9634e-22])\n",
      "tensor([7.2400e-20])\n",
      "tensor([1.5439e-11])\n",
      "tensor([7.9956e-15])\n",
      "tensor([0.9920])\n",
      "tensor([1.8075e-18])\n",
      "tensor([7.3166e-08])\n",
      "tensor([4.0345e-05])\n",
      "tensor([1.3266e-10])\n",
      "tensor([1.6525e-12])\n",
      "tensor([5.7461e-07])\n",
      "tensor([1.5246e-07])\n",
      "FF 256 images Time= : 0.7747126659960486\n"
     ]
    }
   ],
   "source": [
    "# generating some random features\n",
    "#     print(features)\n",
    "#     print(features.shape)\n",
    "# define the weights\n",
    "# W1 = torch.randn((784, 12), requires_grad=True)\n",
    "import timeit\n",
    "params={\"W1\":torch.FloatTensor(784, 12).uniform_(-1, 1),\n",
    "    # print(W1)\n",
    "    \"W2\": torch.FloatTensor(12, 10).uniform_(-1, 1), #torch.randn((12, 10), requires_grad=True)\n",
    "    \"W3\": torch.FloatTensor(10, 1).uniform_(-1, 1), #torch.randn((10, 1), requires_grad=True)\n",
    "    # define the bias terms\n",
    "    \"B1\": torch.FloatTensor(12).uniform_(-1, 1), #torch.randn((12), requires_grad=True)\n",
    "    \"B2\": torch.FloatTensor(10).uniform_(-1, 1), #torch.randn((10), requires_grad=True)\n",
    "    \"B3\": torch.FloatTensor(1).uniform_(-1, 1), #torch.randn((1), requires_grad=True)]\n",
    "       }\n",
    "def my_simple_ff_nn(img,nn_params):      \n",
    "    W1=nn_params[\"W1\"]\n",
    "    W2=nn_params[\"W2\"]\n",
    "    W3=nn_params[\"W3\"]\n",
    "    B1=nn_params[\"B1\"]\n",
    "    B2=nn_params[\"B2\"]\n",
    "    B3=nn_params[\"B3\"]\n",
    "    features = torch.flatten(img).reshape(-1)\n",
    "        # calculate hidden and output layers\n",
    "    h1 = F.relu((features @ W1) + B1)\n",
    "    h2 = F.relu((h1 @ W2) + B2)\n",
    "    output = torch.sigmoid((h2 @ W3) + B3)\n",
    "    print(output)\n",
    "\n",
    "start = timeit.default_timer()   \n",
    "for idx in range(len(example_data)):\n",
    "     my_simple_ff_nn(example_data[idx][0],params)\n",
    "stop = timeit.default_timer()\n",
    "print('FF 256 images Time= :',stop - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndXpk3C5bwQ8"
   },
   "source": [
    "(3) Implement a new torch.nn.module that performs the equivalent of the network in (2). Initialize it with the same weights and validate the outputs of this network is the same as the one in (2) on MNIST training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_uniform(m):\n",
    "        classname = m.__class__.__name__\n",
    "        # for every Linear layer in a model..\n",
    "        if classname.find('Linear') != -1:\n",
    "            # apply a uniform distribution to the weights and a bias=0\n",
    "            m.weight.data.uniform_(-1, 1.0)\n",
    "            m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Nbgzjuqtlhvx"
   },
   "outputs": [],
   "source": [
    "class my_torch_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_torch_nn, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = my_torch_nn()\n",
    "network.apply(weights_init_uniform)\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    print('output=',output)\n",
    "    print('target=',target)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "        torch.save(network.state_dict(), 'model.pth')\n",
    "        torch.save(optimizer.state_dict(), 'optimizer.pth')\n",
    "\n",
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "c:\\program files\\python37\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 18.9188, Accuracy: 1021/10000 (10%)\n",
      "\n",
      "output= tensor([[-2.6852e+01, -5.6851e+00, -4.7861e+01,  ..., -3.4020e-03,\n",
      "         -3.4253e+01, -2.8846e+01],\n",
      "        [-7.9550e+01, -5.0365e+01, -7.1319e+01,  ..., -4.8861e+01,\n",
      "         -4.2195e+01,  0.0000e+00],\n",
      "        [-3.1429e+01, -3.7946e+01, -3.8392e+01,  ..., -4.0257e+01,\n",
      "         -5.2649e+01, -3.7183e+01],\n",
      "        ...,\n",
      "        [-1.0389e+02, -4.3325e+01, -4.4091e+01,  ..., -3.3553e+01,\n",
      "         -5.2609e+01,  0.0000e+00],\n",
      "        [-4.2844e+01, -3.6682e+01, -2.3120e+01,  ..., -1.8671e+01,\n",
      "         -1.9739e+01, -2.2014e+01],\n",
      "        [-2.9988e+01, -1.2900e+01, -3.5721e+01,  ..., -1.1131e+01,\n",
      "         -7.5267e+00, -6.1919e-02]], grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([6, 1, 1, 0, 7, 5, 7, 5, 2, 1, 3, 7, 1, 7, 6, 0, 5, 8, 4, 4, 9, 5, 3, 0,\n",
      "        6, 7, 0, 9, 4, 3, 1, 3, 4, 7, 2, 4, 8, 5, 8, 5, 4, 2, 8, 4, 8, 8, 3, 9,\n",
      "        1, 4, 6, 9, 5, 2, 6, 9, 4, 5, 4, 2, 2, 7, 0, 7, 2, 9, 1, 3, 0, 9, 8, 6,\n",
      "        4, 8, 8, 0, 1, 0, 5, 7, 2, 4, 0, 2, 3, 3, 7, 0, 6, 6, 2, 2, 8, 0, 7, 6,\n",
      "        7, 1, 1, 3, 6, 9, 9, 3, 5, 9, 3, 8, 1, 4, 6, 7, 3, 7, 8, 1, 2, 7, 4, 4,\n",
      "        8, 6, 5, 6, 9, 3, 4, 3, 6, 5, 0, 2, 7, 5, 8, 7, 0, 3, 7, 1, 6, 9, 5, 9,\n",
      "        9, 0, 1, 4, 9, 6, 5, 1, 9, 7, 5, 4, 5, 6, 9, 0, 4, 3, 6, 7, 1, 1, 1, 2,\n",
      "        2, 3, 4, 7, 5, 7, 2, 8, 6, 1, 0, 7, 6, 3, 2, 0, 2, 0, 9, 7, 4, 7, 3, 6,\n",
      "        1, 1, 7, 5, 9, 1, 4, 7, 2, 1, 1, 8, 3, 1, 6, 8, 3, 6, 5, 6, 9, 2, 4, 0,\n",
      "        2, 7, 2, 8, 8, 1, 9, 9, 4, 9, 5, 2, 2, 9, 0, 0, 0, 8, 7, 9, 9, 0, 2, 6,\n",
      "        9, 2, 1, 4, 4, 6, 1, 2, 7, 4, 8, 9, 6, 9, 9, 1])\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 32.528088\n",
      "output= tensor([[-2.9414e+01, -1.9939e+01, -1.5496e-04,  ..., -2.9512e+01,\n",
      "         -1.8958e+01, -1.1002e+01],\n",
      "        [-1.5179e+01, -2.0272e-03, -7.3153e+00,  ..., -1.7311e+01,\n",
      "         -9.8780e+00, -2.7310e+01],\n",
      "        [-5.1721e+01, -9.6785e+00, -2.6848e+01,  ..., -2.7564e+01,\n",
      "         -1.3821e+01, -2.8728e+00],\n",
      "        ...,\n",
      "        [-2.3855e+01, -2.2157e-01, -2.8931e+00,  ..., -2.0912e+01,\n",
      "         -1.5969e+01, -1.5022e+01],\n",
      "        [-9.8287e+00, -2.2155e+00, -7.1821e+00,  ..., -3.9043e+00,\n",
      "         -6.2515e+00, -5.3968e-01],\n",
      "        [-2.2353e+01, -2.0686e-02, -3.9957e+00,  ..., -1.5704e+01,\n",
      "         -2.5426e+01, -2.5987e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([3, 5, 5, 0, 4, 6, 4, 9, 4, 3, 2, 5, 6, 1, 8, 4, 2, 2, 3, 2, 5, 0, 2, 4,\n",
      "        9, 9, 9, 1, 7, 5, 8, 9, 3, 3, 6, 7, 3, 0, 9, 4, 2, 0, 3, 8, 5, 9, 1, 3,\n",
      "        4, 2, 6, 3, 7, 5, 6, 4, 8, 6, 5, 9, 4, 0, 6, 5, 9, 2, 7, 9, 7, 6, 3, 2,\n",
      "        5, 1, 6, 3, 3, 0, 2, 7, 2, 3, 5, 4, 6, 4, 8, 2, 9, 2, 3, 9, 1, 5, 3, 0,\n",
      "        2, 7, 3, 3, 3, 0, 3, 6, 5, 4, 3, 6, 2, 6, 6, 7, 7, 3, 8, 5, 5, 3, 9, 8,\n",
      "        4, 3, 4, 4, 7, 7, 7, 0, 0, 7, 5, 6, 9, 6, 6, 5, 3, 8, 2, 9, 4, 1, 1, 1,\n",
      "        8, 1, 9, 4, 1, 9, 4, 8, 5, 8, 1, 0, 9, 0, 1, 6, 2, 5, 8, 6, 4, 7, 5, 6,\n",
      "        1, 3, 4, 1, 7, 5, 4, 4, 8, 9, 1, 6, 0, 9, 8, 2, 6, 8, 8, 9, 8, 7, 0, 5,\n",
      "        5, 2, 4, 7, 7, 6, 1, 5, 0, 7, 6, 3, 9, 2, 1, 6, 2, 7, 1, 0, 4, 9, 4, 7,\n",
      "        8, 2, 4, 1, 1, 3, 1, 6, 6, 0, 7, 3, 0, 9, 9, 0, 4, 7, 0, 8, 2, 0, 4, 1,\n",
      "        5, 1, 5, 2, 5, 2, 1, 0, 2, 0, 1, 7, 1, 4, 7, 1])\n",
      "output= tensor([[ -2.3068,  -5.0759,  -4.7468,  ...,  -1.1448,  -9.1992,  -3.5835],\n",
      "        [ -2.2363,  -2.3681,  -2.4886,  ...,  -1.0557,  -3.6182,  -2.6486],\n",
      "        [ -3.7917,  -2.0360,  -2.7444,  ...,  -2.3739,  -5.0087,  -1.4642],\n",
      "        ...,\n",
      "        [ -3.3515,  -3.8211,  -3.2355,  ...,  -2.1474,  -2.7812,  -2.3944],\n",
      "        [ -3.1499,  -2.3930,  -2.3543,  ...,  -2.6014,  -1.4326,  -2.3019],\n",
      "        [-13.6317,  -7.9695,  -4.7128,  ...,  -4.2027,  -8.8354,  -5.6414]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 4, 2, 7, 0, 4, 4, 6, 5, 7, 8, 2, 8, 0, 4, 7, 7, 6, 2, 2, 8, 8, 4, 8,\n",
      "        1, 0, 6, 9, 2, 2, 0, 2, 2, 2, 5, 8, 0, 5, 8, 9, 5, 3, 6, 3, 2, 2, 6, 2,\n",
      "        3, 2, 3, 8, 4, 2, 4, 0, 0, 5, 8, 0, 6, 0, 9, 7, 7, 3, 6, 6, 4, 3, 9, 1,\n",
      "        2, 6, 2, 7, 7, 3, 1, 2, 7, 0, 9, 4, 0, 4, 5, 7, 9, 1, 3, 8, 2, 0, 3, 2,\n",
      "        6, 9, 9, 5, 1, 1, 1, 9, 4, 7, 7, 1, 0, 0, 6, 8, 2, 7, 9, 2, 5, 1, 7, 8,\n",
      "        5, 5, 1, 6, 1, 2, 5, 9, 4, 9, 3, 2, 1, 2, 9, 3, 0, 3, 5, 3, 4, 9, 3, 6,\n",
      "        7, 6, 3, 8, 7, 7, 7, 1, 2, 0, 9, 0, 2, 4, 0, 4, 5, 4, 7, 9, 4, 5, 3, 2,\n",
      "        1, 2, 5, 1, 1, 2, 6, 1, 8, 1, 0, 5, 9, 3, 8, 8, 3, 1, 2, 9, 6, 2, 9, 8,\n",
      "        2, 4, 7, 2, 9, 7, 2, 6, 4, 0, 9, 6, 9, 9, 8, 2, 3, 0, 3, 7, 8, 0, 8, 5,\n",
      "        0, 2, 9, 8, 4, 9, 7, 7, 8, 8, 1, 2, 6, 0, 5, 3, 0, 6, 8, 5, 4, 3, 2, 9,\n",
      "        2, 7, 2, 5, 7, 2, 5, 2, 8, 5, 4, 3, 1, 9, 0, 8])\n",
      "output= tensor([[-2.2993, -2.3083, -2.3013,  ..., -2.3030, -2.3013, -2.3076],\n",
      "        [-2.2975, -2.3102, -2.3003,  ..., -2.3018, -2.2997, -2.3110],\n",
      "        [-2.2978, -2.3098, -2.3000,  ..., -2.3015, -2.3001, -2.3108],\n",
      "        ...,\n",
      "        [-2.2967, -2.3141, -2.3012,  ..., -2.3054, -2.2971, -2.3113],\n",
      "        [-2.2989, -2.2511, -2.2663,  ..., -2.3674, -2.3091, -2.4155],\n",
      "        [-2.2978, -2.3098, -2.3000,  ..., -2.3015, -2.3001, -2.3108]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 3, 4, 4, 5, 8, 0, 4, 4, 2, 7, 6, 8, 5, 5, 7, 4, 0, 2, 9, 4, 8, 9, 0,\n",
      "        5, 6, 1, 3, 0, 4, 2, 4, 5, 1, 9, 2, 0, 4, 0, 8, 1, 6, 7, 2, 7, 0, 1, 0,\n",
      "        7, 4, 6, 1, 4, 2, 0, 2, 2, 7, 2, 9, 7, 3, 0, 7, 7, 2, 5, 8, 8, 0, 6, 8,\n",
      "        0, 6, 5, 6, 7, 5, 2, 7, 5, 7, 3, 6, 6, 5, 5, 7, 7, 9, 2, 6, 1, 4, 4, 9,\n",
      "        1, 9, 9, 3, 5, 0, 1, 3, 1, 6, 0, 3, 0, 3, 6, 9, 3, 0, 7, 4, 3, 7, 6, 1,\n",
      "        5, 9, 6, 2, 5, 1, 0, 7, 2, 4, 4, 0, 4, 6, 7, 5, 8, 2, 4, 0, 6, 0, 2, 4,\n",
      "        5, 2, 9, 8, 1, 7, 7, 6, 0, 4, 0, 9, 4, 9, 0, 9, 0, 3, 7, 7, 4, 5, 1, 9,\n",
      "        5, 1, 7, 5, 0, 9, 3, 2, 0, 4, 2, 2, 5, 3, 4, 2, 0, 1, 0, 5, 2, 5, 5, 6,\n",
      "        6, 4, 3, 4, 2, 9, 3, 5, 1, 4, 0, 7, 7, 8, 4, 5, 0, 3, 9, 0, 0, 7, 1, 4,\n",
      "        5, 5, 2, 7, 1, 2, 3, 6, 0, 1, 3, 5, 9, 5, 6, 4, 8, 5, 2, 0, 3, 3, 3, 7,\n",
      "        6, 6, 7, 2, 1, 0, 7, 0, 8, 7, 9, 4, 8, 6, 7, 2])\n",
      "output= tensor([[-2.2955, -2.3150, -2.3008,  ..., -2.3055, -2.2973, -2.3120],\n",
      "        [-2.2983, -2.3095, -2.3010,  ..., -2.3031, -2.3015, -2.3082],\n",
      "        [-2.2963, -2.3139, -2.3016,  ..., -2.3059, -2.3006, -2.3094],\n",
      "        ...,\n",
      "        [-2.3228, -2.3633, -2.3001,  ..., -2.3282, -2.3051, -2.2262],\n",
      "        [-2.2955, -2.3150, -2.3008,  ..., -2.3055, -2.2973, -2.3120],\n",
      "        [-2.2988, -2.3101, -2.3005,  ..., -2.3025, -2.3020, -2.3080]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([0, 4, 1, 5, 2, 3, 2, 6, 7, 4, 0, 8, 8, 7, 6, 6, 4, 1, 8, 7, 1, 5, 6, 8,\n",
      "        5, 8, 2, 8, 2, 4, 3, 9, 3, 1, 6, 6, 0, 2, 9, 7, 8, 2, 5, 6, 3, 3, 2, 1,\n",
      "        3, 0, 7, 0, 9, 4, 3, 8, 5, 3, 7, 1, 5, 1, 1, 3, 8, 4, 7, 8, 7, 9, 3, 7,\n",
      "        7, 6, 1, 4, 6, 5, 9, 3, 9, 9, 5, 2, 3, 0, 4, 2, 2, 7, 1, 1, 4, 5, 1, 3,\n",
      "        7, 1, 1, 7, 1, 6, 7, 7, 7, 9, 2, 5, 7, 2, 3, 0, 0, 2, 4, 1, 6, 8, 1, 3,\n",
      "        8, 2, 9, 0, 3, 3, 5, 0, 9, 7, 1, 3, 6, 9, 1, 9, 6, 2, 3, 6, 8, 3, 3, 9,\n",
      "        4, 4, 0, 2, 6, 5, 1, 5, 2, 9, 2, 5, 2, 3, 9, 3, 0, 9, 7, 2, 8, 1, 3, 0,\n",
      "        9, 5, 5, 8, 5, 9, 6, 1, 9, 4, 2, 5, 4, 4, 5, 2, 1, 6, 9, 2, 9, 0, 6, 4,\n",
      "        1, 0, 9, 0, 6, 8, 8, 9, 2, 1, 5, 5, 3, 6, 3, 0, 5, 0, 5, 7, 8, 2, 8, 8,\n",
      "        3, 5, 9, 2, 1, 1, 4, 9, 3, 0, 9, 2, 8, 1, 6, 8, 6, 8, 3, 0, 1, 4, 9, 2,\n",
      "        7, 7, 6, 0, 3, 7, 6, 7, 8, 9, 3, 0, 8, 4, 1, 4])\n",
      "output= tensor([[-2.2958, -2.3160, -2.2998,  ..., -2.3046, -2.2976, -2.3123],\n",
      "        [-2.2970, -2.3112, -2.2997,  ..., -2.3028, -2.2979, -2.3115],\n",
      "        [-2.2970, -2.3112, -2.2997,  ..., -2.3028, -2.2979, -2.3115],\n",
      "        ...,\n",
      "        [-2.3829, -2.2684, -2.2439,  ..., -2.4222, -2.1184, -2.3049],\n",
      "        [-2.2985, -2.3108, -2.3001,  ..., -2.3024, -2.3022, -2.3083],\n",
      "        [-2.2931, -2.3157, -2.2999,  ..., -2.3036, -2.3003, -2.3142]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([0, 7, 7, 5, 9, 9, 5, 4, 9, 0, 9, 6, 1, 1, 4, 9, 1, 8, 3, 0, 6, 9, 4, 3,\n",
      "        6, 4, 5, 1, 8, 6, 3, 7, 1, 8, 6, 2, 3, 6, 0, 2, 2, 5, 4, 6, 0, 0, 7, 8,\n",
      "        6, 5, 6, 5, 9, 8, 8, 0, 3, 6, 2, 7, 1, 1, 9, 1, 2, 6, 2, 9, 3, 0, 9, 0,\n",
      "        6, 6, 2, 1, 0, 7, 7, 7, 7, 3, 4, 1, 7, 1, 7, 9, 7, 5, 0, 1, 0, 1, 2, 8,\n",
      "        1, 1, 3, 6, 8, 1, 8, 8, 7, 6, 9, 5, 6, 2, 6, 3, 1, 8, 8, 5, 9, 2, 1, 1,\n",
      "        7, 9, 9, 4, 0, 5, 2, 1, 4, 1, 1, 7, 3, 5, 2, 4, 1, 9, 8, 2, 9, 7, 0, 0,\n",
      "        6, 4, 2, 9, 7, 0, 2, 6, 3, 3, 1, 0, 4, 0, 4, 7, 9, 1, 6, 1, 2, 4, 1, 0,\n",
      "        8, 6, 0, 5, 1, 6, 2, 5, 7, 0, 9, 6, 4, 7, 8, 9, 5, 4, 7, 0, 9, 0, 4, 6,\n",
      "        3, 4, 2, 2, 1, 5, 8, 4, 4, 6, 3, 7, 3, 0, 8, 2, 2, 9, 8, 9, 2, 3, 7, 2,\n",
      "        4, 4, 7, 6, 2, 7, 1, 0, 8, 8, 0, 3, 4, 6, 4, 8, 6, 5, 2, 1, 5, 1, 7, 3,\n",
      "        8, 2, 0, 2, 7, 8, 1, 6, 4, 6, 8, 0, 3, 8, 7, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-2.7230, -1.7543, -2.0314,  ..., -1.8687, -1.9660, -2.5725],\n",
      "        [-2.2970, -2.3151, -2.2987,  ..., -2.3025, -2.2990, -2.3117],\n",
      "        [-2.2956, -2.3133, -2.2999,  ..., -2.3042, -2.2976, -2.3122],\n",
      "        ...,\n",
      "        [-2.2933, -2.3139, -2.2994,  ..., -2.3021, -2.3013, -2.3141],\n",
      "        [-2.2980, -2.3129, -2.2983,  ..., -2.3011, -2.2994, -2.3111],\n",
      "        [-2.2979, -2.3139, -2.2996,  ..., -2.3029, -2.3025, -2.3088]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([5, 1, 3, 5, 1, 2, 0, 7, 0, 5, 5, 3, 3, 2, 5, 1, 0, 8, 6, 4, 3, 5, 7, 3,\n",
      "        3, 6, 4, 3, 4, 3, 6, 4, 2, 9, 3, 0, 7, 6, 7, 7, 9, 2, 6, 7, 6, 8, 5, 3,\n",
      "        1, 6, 0, 1, 6, 0, 0, 1, 9, 8, 8, 3, 6, 6, 3, 3, 1, 7, 8, 2, 8, 0, 8, 4,\n",
      "        9, 3, 9, 9, 3, 1, 4, 9, 4, 3, 8, 2, 8, 3, 3, 1, 3, 5, 2, 2, 7, 8, 6, 0,\n",
      "        1, 8, 6, 7, 1, 3, 9, 8, 6, 2, 7, 9, 4, 5, 3, 9, 4, 0, 3, 2, 6, 8, 9, 2,\n",
      "        8, 5, 3, 5, 4, 6, 8, 4, 7, 9, 0, 8, 1, 8, 2, 0, 5, 7, 0, 0, 9, 2, 8, 1,\n",
      "        7, 6, 9, 9, 7, 3, 6, 4, 7, 2, 3, 2, 4, 1, 6, 6, 5, 0, 5, 8, 3, 7, 4, 4,\n",
      "        6, 4, 6, 7, 9, 0, 5, 2, 1, 7, 5, 4, 7, 3, 0, 9, 8, 9, 6, 5, 8, 1, 7, 8,\n",
      "        3, 4, 1, 4, 7, 6, 0, 5, 2, 1, 4, 2, 1, 2, 9, 3, 9, 6, 3, 0, 5, 0, 4, 1,\n",
      "        7, 3, 1, 0, 7, 6, 7, 7, 8, 9, 9, 0, 6, 5, 2, 2, 7, 2, 1, 8, 5, 1, 2, 9,\n",
      "        1, 3, 5, 4, 7, 7, 5, 1, 7, 9, 6, 6, 5, 7, 4, 3])\n",
      "output= tensor([[-2.2966, -2.3134, -2.2979,  ..., -2.2977, -2.3086, -2.3106],\n",
      "        [-2.2966, -2.3134, -2.2979,  ..., -2.2977, -2.3086, -2.3106],\n",
      "        [-2.2958, -2.3145, -2.2969,  ..., -2.2973, -2.3051, -2.3133],\n",
      "        ...,\n",
      "        [-2.2962, -2.3120, -2.2998,  ..., -2.3032, -2.2981, -2.3120],\n",
      "        [-2.8649, -1.9510, -2.3821,  ..., -2.1052, -2.1449, -2.1955],\n",
      "        [-2.2966, -2.3134, -2.2979,  ..., -2.2977, -2.3086, -2.3106]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([3, 7, 7, 0, 9, 0, 6, 2, 3, 4, 5, 2, 7, 2, 6, 9, 8, 8, 1, 4, 5, 4, 8, 3,\n",
      "        1, 4, 5, 2, 9, 5, 1, 1, 1, 1, 6, 7, 8, 4, 0, 5, 4, 0, 9, 9, 0, 2, 9, 9,\n",
      "        8, 6, 1, 9, 4, 9, 8, 5, 2, 1, 9, 3, 6, 5, 8, 1, 1, 5, 0, 7, 4, 2, 2, 5,\n",
      "        3, 6, 1, 2, 5, 3, 0, 1, 5, 4, 7, 5, 4, 6, 7, 3, 1, 4, 6, 7, 0, 2, 6, 2,\n",
      "        1, 9, 2, 8, 2, 0, 7, 4, 6, 0, 6, 2, 7, 2, 9, 2, 2, 7, 9, 6, 6, 8, 1, 8,\n",
      "        1, 3, 6, 2, 4, 4, 7, 7, 0, 1, 6, 3, 1, 1, 9, 0, 1, 4, 6, 8, 4, 8, 8, 5,\n",
      "        5, 4, 2, 3, 9, 5, 8, 9, 9, 1, 1, 4, 3, 8, 0, 1, 4, 8, 1, 8, 3, 4, 0, 5,\n",
      "        1, 4, 4, 0, 1, 9, 8, 1, 4, 6, 1, 5, 9, 7, 3, 0, 2, 5, 0, 3, 0, 3, 3, 7,\n",
      "        4, 4, 1, 5, 7, 2, 2, 4, 3, 9, 7, 0, 7, 4, 0, 2, 1, 4, 4, 1, 9, 2, 9, 3,\n",
      "        1, 4, 2, 2, 7, 4, 1, 4, 6, 2, 1, 8, 3, 6, 0, 0, 7, 9, 0, 7, 5, 1, 4, 1,\n",
      "        1, 3, 3, 9, 1, 7, 6, 7, 3, 2, 0, 2, 2, 7, 9, 5])\n",
      "output= tensor([[-2.2970, -2.3101, -2.2999,  ..., -2.3027, -2.3002, -2.3106],\n",
      "        [-2.3005, -2.3245, -2.2955,  ..., -2.3038, -2.2836, -2.3041],\n",
      "        [-2.3002, -2.3128, -2.2979,  ..., -2.2997, -2.3047, -2.3081],\n",
      "        ...,\n",
      "        [-2.2940, -2.3103, -2.2996,  ..., -2.3000, -2.3075, -2.3119],\n",
      "        [-2.2940, -2.3103, -2.2996,  ..., -2.3000, -2.3075, -2.3119],\n",
      "        [-2.2711, -2.2213, -2.2843,  ..., -2.3710, -2.1958, -2.4484]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([5, 6, 3, 8, 3, 1, 4, 7, 7, 8, 8, 1, 9, 2, 7, 6, 1, 2, 4, 6, 8, 5, 2, 0,\n",
      "        6, 0, 6, 5, 9, 9, 3, 8, 0, 6, 5, 3, 4, 8, 6, 2, 8, 4, 3, 6, 0, 6, 7, 0,\n",
      "        9, 2, 2, 7, 6, 0, 5, 4, 2, 7, 0, 7, 5, 0, 5, 6, 6, 6, 9, 1, 2, 7, 3, 6,\n",
      "        6, 6, 6, 3, 2, 2, 4, 7, 9, 9, 6, 7, 8, 0, 7, 2, 2, 7, 9, 4, 9, 7, 1, 0,\n",
      "        8, 6, 7, 8, 7, 0, 9, 6, 3, 5, 0, 6, 6, 5, 5, 8, 0, 5, 0, 6, 3, 7, 3, 5,\n",
      "        9, 2, 8, 9, 9, 4, 8, 3, 2, 7, 7, 9, 2, 8, 6, 6, 1, 2, 7, 6, 3, 0, 3, 8,\n",
      "        8, 8, 6, 2, 8, 7, 4, 7, 6, 2, 6, 2, 2, 7, 6, 6, 7, 0, 5, 6, 0, 1, 1, 9,\n",
      "        8, 3, 1, 2, 8, 2, 1, 9, 6, 7, 4, 4, 7, 0, 2, 3, 0, 7, 6, 3, 9, 8, 7, 8,\n",
      "        6, 1, 9, 9, 4, 5, 5, 9, 8, 3, 9, 0, 3, 5, 2, 6, 7, 1, 4, 8, 4, 5, 7, 4,\n",
      "        3, 4, 0, 0, 9, 4, 4, 5, 2, 4, 3, 4, 6, 8, 5, 2, 4, 1, 1, 5, 8, 7, 7, 3,\n",
      "        8, 1, 8, 2, 8, 7, 8, 7, 2, 2, 9, 3, 0, 7, 9, 9])\n",
      "output= tensor([[-2.2975, -2.3097, -2.3002,  ..., -2.3026, -2.3020, -2.3092],\n",
      "        [-2.2963, -2.3152, -2.2959,  ..., -2.2942, -2.3131, -2.3117],\n",
      "        [-2.2920, -2.3117, -2.2983,  ..., -2.2981, -2.3067, -2.3154],\n",
      "        ...,\n",
      "        [-2.2920, -2.3117, -2.2983,  ..., -2.2981, -2.3067, -2.3154],\n",
      "        [-2.3088, -2.2842, -2.3042,  ..., -2.3368, -2.3383, -2.2833],\n",
      "        [-2.2968, -2.3106, -2.2994,  ..., -2.3023, -2.2991, -2.3115]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([0, 9, 2, 4, 1, 7, 4, 1, 1, 1, 9, 5, 4, 7, 4, 5, 9, 0, 6, 2, 3, 1, 0, 1,\n",
      "        1, 1, 4, 9, 5, 3, 6, 4, 9, 1, 7, 6, 5, 1, 8, 1, 7, 6, 7, 3, 9, 6, 9, 6,\n",
      "        9, 8, 8, 7, 7, 9, 7, 1, 7, 9, 2, 3, 0, 0, 2, 0, 5, 0, 3, 7, 6, 0, 0, 2,\n",
      "        8, 8, 7, 7, 5, 3, 0, 8, 4, 5, 5, 7, 4, 1, 8, 8, 2, 6, 3, 0, 8, 6, 5, 1,\n",
      "        4, 2, 9, 6, 7, 8, 4, 0, 5, 4, 2, 3, 9, 8, 4, 2, 1, 1, 1, 7, 0, 4, 9, 9,\n",
      "        7, 4, 7, 4, 1, 4, 7, 8, 4, 2, 1, 0, 2, 9, 9, 2, 4, 5, 3, 8, 5, 5, 9, 8,\n",
      "        7, 9, 0, 1, 1, 8, 6, 9, 4, 2, 5, 1, 6, 1, 4, 9, 1, 4, 3, 1, 5, 6, 2, 4,\n",
      "        3, 2, 0, 9, 3, 5, 4, 4, 3, 0, 0, 2, 7, 1, 4, 7, 7, 3, 1, 3, 3, 0, 0, 5,\n",
      "        3, 6, 8, 9, 5, 5, 5, 7, 9, 8, 2, 0, 1, 3, 5, 2, 2, 1, 8, 2, 3, 7, 9, 2,\n",
      "        6, 0, 6, 4, 2, 4, 7, 1, 9, 7, 9, 2, 1, 0, 0, 9, 5, 8, 0, 8, 8, 7, 8, 4,\n",
      "        6, 9, 8, 3, 0, 7, 4, 1, 3, 7, 4, 2, 3, 7, 3, 9])\n",
      "output= tensor([[-2.2921, -2.3107, -2.2989,  ..., -2.2976, -2.3106, -2.3134],\n",
      "        [-2.2958, -2.3166, -2.2946,  ..., -2.2924, -2.3123, -2.3137],\n",
      "        [-2.2958, -2.3166, -2.2946,  ..., -2.2924, -2.3123, -2.3137],\n",
      "        ...,\n",
      "        [-2.2916, -2.3115, -2.2983,  ..., -2.2973, -2.3083, -2.3153],\n",
      "        [-2.3262, -2.3291, -2.2954,  ..., -2.2909, -2.3230, -2.2910],\n",
      "        [-2.2921, -2.3107, -2.2989,  ..., -2.2976, -2.3106, -2.3134]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 9, 4, 1, 1, 0, 9, 5, 1, 2, 7, 0, 7, 5, 6, 8, 2, 0, 6, 3, 7, 2, 3, 9,\n",
      "        2, 5, 8, 2, 0, 5, 2, 7, 5, 1, 8, 4, 0, 4, 9, 7, 3, 8, 4, 5, 6, 1, 3, 6,\n",
      "        7, 6, 8, 6, 0, 9, 2, 4, 4, 3, 7, 9, 1, 7, 2, 4, 1, 1, 2, 7, 5, 7, 7, 2,\n",
      "        9, 4, 0, 4, 6, 1, 4, 5, 6, 7, 5, 3, 5, 4, 2, 9, 9, 5, 0, 1, 5, 5, 8, 7,\n",
      "        0, 4, 7, 1, 6, 7, 8, 7, 5, 1, 2, 6, 7, 4, 2, 7, 8, 5, 3, 8, 9, 6, 5, 3,\n",
      "        2, 8, 3, 9, 5, 8, 2, 9, 2, 9, 5, 4, 0, 9, 8, 9, 1, 6, 8, 6, 5, 4, 7, 6,\n",
      "        7, 2, 3, 6, 5, 8, 8, 1, 1, 2, 1, 2, 6, 6, 1, 1, 6, 0, 6, 1, 8, 4, 4, 6,\n",
      "        1, 4, 0, 7, 8, 3, 0, 5, 6, 5, 9, 6, 2, 3, 0, 4, 4, 6, 8, 9, 7, 1, 5, 9,\n",
      "        4, 1, 3, 7, 4, 6, 3, 5, 4, 4, 9, 3, 4, 1, 6, 6, 4, 7, 6, 0, 6, 8, 0, 5,\n",
      "        2, 6, 9, 6, 6, 0, 8, 9, 0, 8, 5, 5, 3, 9, 6, 9, 4, 3, 1, 4, 6, 0, 9, 1,\n",
      "        6, 7, 6, 6, 6, 1, 9, 9, 4, 5, 2, 1, 2, 3, 4, 3])\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.301686\n",
      "output= tensor([[-2.2978, -2.3093, -2.3002,  ..., -2.3021, -2.3024, -2.3091],\n",
      "        [-2.3019, -2.3162, -2.2952,  ..., -2.2961, -2.3039, -2.3097],\n",
      "        [-2.3019, -2.3162, -2.2952,  ..., -2.2961, -2.3039, -2.3097],\n",
      "        ...,\n",
      "        [-2.3033, -2.3162, -2.2953,  ..., -2.2956, -2.3077, -2.3070],\n",
      "        [-2.2978, -2.3093, -2.3002,  ..., -2.3021, -2.3024, -2.3091],\n",
      "        [-2.3026, -2.3152, -2.2960,  ..., -2.2965, -2.3070, -2.3073]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 3, 6, 8, 9, 4, 2, 9, 8, 5, 5, 6, 0, 8, 3, 6, 0, 4, 5, 8, 0, 0, 7, 7,\n",
      "        1, 1, 0, 9, 1, 6, 4, 7, 0, 2, 3, 8, 4, 7, 0, 1, 0, 3, 0, 6, 4, 7, 2, 6,\n",
      "        2, 7, 6, 3, 6, 0, 1, 7, 3, 0, 0, 5, 3, 7, 7, 4, 6, 1, 2, 9, 5, 0, 7, 1,\n",
      "        7, 8, 2, 1, 0, 5, 1, 6, 5, 5, 1, 5, 8, 5, 7, 3, 3, 2, 9, 9, 1, 6, 8, 9,\n",
      "        5, 7, 0, 0, 0, 1, 9, 2, 1, 0, 6, 1, 9, 4, 8, 9, 9, 7, 6, 9, 1, 0, 3, 5,\n",
      "        5, 4, 4, 1, 9, 1, 6, 9, 9, 1, 0, 8, 2, 5, 6, 6, 4, 0, 9, 6, 6, 2, 4, 2,\n",
      "        4, 6, 7, 4, 4, 2, 2, 5, 5, 3, 7, 1, 4, 5, 9, 8, 4, 3, 0, 7, 2, 7, 5, 8,\n",
      "        1, 2, 3, 8, 7, 7, 2, 9, 3, 7, 7, 1, 8, 4, 5, 8, 7, 9, 1, 9, 9, 1, 4, 4,\n",
      "        6, 6, 9, 4, 8, 3, 0, 2, 0, 2, 3, 9, 3, 3, 5, 8, 3, 6, 7, 5, 2, 2, 8, 3,\n",
      "        5, 2, 7, 2, 7, 0, 3, 7, 1, 2, 7, 7, 8, 6, 2, 4, 8, 3, 4, 2, 1, 3, 8, 1,\n",
      "        6, 0, 8, 6, 7, 8, 3, 4, 9, 5, 6, 0, 4, 9, 3, 5])\n",
      "output= tensor([[-2.2941, -2.3185, -2.2931,  ..., -2.2890, -2.3149, -2.3168],\n",
      "        [-2.2951, -2.3170, -2.2943,  ..., -2.2895, -2.3193, -2.3134],\n",
      "        [-2.3017, -2.3167, -2.2948,  ..., -2.2956, -2.3029, -2.3107],\n",
      "        ...,\n",
      "        [-2.4303, -2.4216, -2.3908,  ..., -2.3644, -2.2136, -2.0528],\n",
      "        [-2.2902, -2.3110, -2.2986,  ..., -2.2952, -2.3146, -2.3152],\n",
      "        [-2.2892, -2.3124, -2.2975,  ..., -2.2947, -2.3103, -2.3186]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([3, 7, 1, 3, 1, 4, 4, 8, 6, 6, 2, 1, 0, 0, 8, 5, 9, 7, 0, 1, 0, 7, 4, 9,\n",
      "        8, 1, 3, 3, 6, 2, 4, 8, 4, 2, 8, 6, 3, 5, 3, 7, 2, 3, 2, 3, 0, 0, 8, 2,\n",
      "        0, 1, 5, 4, 8, 3, 1, 5, 0, 7, 2, 7, 8, 9, 9, 9, 7, 3, 6, 1, 1, 9, 6, 2,\n",
      "        7, 8, 4, 6, 3, 7, 4, 8, 5, 5, 5, 8, 5, 1, 4, 1, 6, 3, 0, 7, 4, 4, 7, 8,\n",
      "        9, 3, 0, 0, 0, 5, 9, 6, 0, 5, 0, 5, 7, 3, 0, 5, 7, 8, 2, 3, 4, 1, 4, 7,\n",
      "        0, 6, 1, 4, 2, 5, 3, 1, 7, 9, 0, 0, 9, 8, 0, 1, 4, 7, 7, 1, 0, 1, 5, 1,\n",
      "        8, 0, 1, 3, 9, 8, 9, 4, 5, 6, 9, 6, 2, 7, 1, 7, 2, 0, 1, 4, 3, 0, 8, 8,\n",
      "        1, 4, 0, 5, 7, 2, 9, 7, 0, 9, 3, 3, 4, 5, 6, 3, 2, 1, 8, 7, 5, 7, 5, 0,\n",
      "        7, 7, 3, 1, 7, 3, 1, 0, 4, 9, 8, 4, 8, 4, 0, 4, 1, 0, 0, 1, 0, 8, 1, 4,\n",
      "        5, 3, 7, 9, 4, 3, 7, 3, 6, 1, 1, 9, 7, 7, 3, 9, 7, 0, 0, 5, 6, 0, 4, 0,\n",
      "        6, 1, 6, 0, 2, 5, 5, 7, 6, 8, 3, 6, 2, 6, 9, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-2.3024, -2.3150, -2.2963,  ..., -2.2957, -2.3075, -2.3075],\n",
      "        [-2.2929, -2.3186, -2.2931,  ..., -2.2879, -2.3158, -2.3180],\n",
      "        [-2.3072, -2.3344, -2.2958,  ..., -2.2810, -2.3212, -2.2896],\n",
      "        ...,\n",
      "        [-2.3024, -2.3150, -2.2963,  ..., -2.2957, -2.3075, -2.3074],\n",
      "        [-2.2929, -2.3186, -2.2931,  ..., -2.2879, -2.3158, -2.3180],\n",
      "        [-2.2891, -2.3109, -2.2988,  ..., -2.2942, -2.3160, -2.3160]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([5, 6, 4, 6, 3, 3, 6, 5, 3, 8, 1, 2, 7, 5, 2, 2, 9, 0, 0, 0, 1, 9, 1, 7,\n",
      "        0, 8, 7, 2, 1, 5, 8, 6, 4, 9, 4, 9, 5, 4, 1, 4, 8, 3, 3, 9, 9, 1, 7, 3,\n",
      "        8, 3, 6, 3, 3, 4, 7, 4, 1, 7, 6, 8, 2, 8, 9, 1, 4, 2, 5, 3, 8, 5, 8, 2,\n",
      "        8, 5, 0, 8, 0, 4, 0, 2, 0, 5, 6, 5, 3, 1, 1, 4, 1, 2, 8, 9, 1, 8, 5, 8,\n",
      "        6, 0, 9, 3, 6, 2, 5, 1, 5, 8, 6, 8, 2, 9, 7, 2, 3, 0, 2, 0, 3, 8, 3, 2,\n",
      "        8, 0, 7, 9, 2, 8, 5, 5, 3, 3, 9, 0, 6, 1, 6, 0, 2, 7, 3, 4, 3, 0, 0, 3,\n",
      "        4, 3, 7, 4, 8, 1, 3, 0, 0, 8, 6, 5, 3, 5, 6, 4, 5, 9, 9, 6, 2, 7, 5, 7,\n",
      "        0, 9, 0, 9, 0, 8, 2, 5, 0, 3, 3, 6, 4, 2, 2, 4, 8, 5, 9, 7, 9, 8, 7, 1,\n",
      "        7, 1, 8, 8, 9, 4, 7, 2, 0, 0, 1, 5, 1, 3, 6, 6, 9, 5, 1, 9, 9, 9, 7, 7,\n",
      "        7, 0, 1, 7, 7, 3, 8, 4, 8, 0, 5, 2, 7, 3, 1, 1, 1, 0, 7, 1, 4, 7, 0, 3,\n",
      "        8, 0, 2, 2, 4, 3, 7, 7, 6, 7, 5, 0, 0, 6, 1, 3])\n",
      "output= tensor([[-2.2867, -2.3128, -2.2974,  ..., -2.2928, -2.3110, -2.3214],\n",
      "        [-2.2915, -2.3187, -2.2931,  ..., -2.2871, -2.3156, -2.3196],\n",
      "        [-2.3779, -2.2877, -2.2584,  ..., -2.2586, -2.3111, -2.3031],\n",
      "        ...,\n",
      "        [-2.3021, -2.4703, -2.4303,  ..., -2.5018, -2.3498, -2.0284],\n",
      "        [-2.2957, -2.3107, -2.2994,  ..., -2.3005, -2.2969, -2.3142],\n",
      "        [-2.3018, -2.3147, -2.2967,  ..., -2.2956, -2.3074, -2.3077]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 8, 3, 8, 0, 4, 9, 5, 7, 9, 9, 5, 6, 3, 5, 0, 8, 2, 4, 9, 5, 0, 7, 8,\n",
      "        5, 4, 1, 8, 6, 2, 7, 7, 3, 1, 4, 0, 1, 7, 1, 8, 4, 3, 0, 0, 6, 2, 0, 6,\n",
      "        6, 5, 2, 2, 7, 5, 8, 2, 7, 3, 4, 0, 7, 7, 6, 8, 6, 1, 1, 1, 0, 9, 9, 7,\n",
      "        5, 9, 7, 9, 6, 0, 2, 8, 9, 7, 3, 5, 7, 0, 7, 6, 1, 6, 4, 3, 0, 8, 2, 0,\n",
      "        6, 2, 1, 8, 9, 3, 6, 3, 0, 2, 2, 6, 3, 5, 9, 8, 1, 8, 0, 5, 7, 2, 0, 6,\n",
      "        4, 7, 7, 2, 0, 1, 0, 1, 9, 4, 3, 3, 7, 6, 9, 8, 7, 2, 8, 3, 4, 3, 3, 1,\n",
      "        7, 3, 8, 4, 4, 5, 6, 1, 7, 8, 4, 3, 9, 8, 9, 7, 1, 1, 0, 9, 2, 0, 9, 9,\n",
      "        5, 7, 4, 1, 5, 8, 5, 7, 4, 1, 5, 9, 8, 7, 9, 9, 1, 3, 0, 3, 1, 5, 3, 6,\n",
      "        0, 8, 2, 9, 9, 1, 6, 8, 3, 5, 3, 1, 7, 4, 0, 0, 9, 9, 1, 0, 7, 3, 3, 2,\n",
      "        6, 3, 1, 0, 6, 8, 1, 2, 9, 9, 8, 2, 2, 8, 6, 3, 1, 6, 2, 3, 7, 8, 5, 5,\n",
      "        1, 2, 9, 1, 3, 0, 0, 2, 5, 7, 7, 0, 9, 2, 6, 7])\n",
      "output= tensor([[-2.2905, -2.3170, -2.2957,  ..., -2.2882, -2.3213, -2.3163],\n",
      "        [-2.2960, -2.3094, -2.3016,  ..., -2.3016, -2.3019, -2.3101],\n",
      "        [-2.2891, -2.3193, -2.2938,  ..., -2.2874, -2.3146, -2.3212],\n",
      "        ...,\n",
      "        [-2.2869, -2.3109, -2.2989,  ..., -2.2924, -2.3181, -2.3174],\n",
      "        [-2.2864, -2.3119, -2.2992,  ..., -2.2931, -2.3170, -2.3177],\n",
      "        [-3.1133, -2.3466, -2.4395,  ..., -2.3650, -1.9944, -2.0737]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 3, 1, 3, 1, 8, 3, 4, 7, 0, 2, 3, 1, 1, 5, 8, 6, 2, 0, 2, 6, 8, 5, 7,\n",
      "        4, 2, 2, 6, 0, 3, 0, 1, 7, 7, 1, 2, 7, 6, 6, 1, 3, 9, 5, 1, 8, 4, 6, 7,\n",
      "        5, 9, 5, 7, 2, 7, 3, 7, 0, 2, 1, 5, 9, 2, 8, 4, 4, 7, 6, 5, 7, 5, 5, 2,\n",
      "        9, 9, 9, 7, 4, 4, 2, 1, 3, 2, 9, 7, 2, 9, 6, 8, 5, 2, 4, 7, 1, 5, 9, 2,\n",
      "        8, 7, 8, 8, 5, 3, 7, 5, 6, 1, 3, 6, 7, 9, 9, 9, 8, 6, 8, 1, 5, 7, 9, 2,\n",
      "        6, 5, 5, 1, 0, 0, 5, 2, 9, 9, 2, 0, 3, 3, 7, 0, 9, 7, 3, 7, 3, 4, 1, 5,\n",
      "        2, 3, 8, 4, 7, 0, 6, 8, 1, 1, 9, 4, 3, 7, 1, 7, 6, 6, 0, 8, 8, 1, 8, 2,\n",
      "        7, 4, 6, 5, 6, 6, 4, 2, 0, 4, 9, 4, 6, 4, 0, 1, 7, 6, 9, 0, 6, 4, 8, 3,\n",
      "        6, 6, 1, 7, 1, 9, 8, 3, 6, 3, 6, 4, 3, 1, 8, 4, 2, 3, 5, 3, 0, 1, 1, 3,\n",
      "        3, 9, 6, 6, 7, 1, 3, 0, 1, 0, 4, 2, 2, 0, 5, 7, 6, 8, 7, 6, 7, 2, 6, 9,\n",
      "        3, 9, 2, 8, 0, 1, 6, 1, 2, 1, 3, 9, 5, 5, 1, 3])\n",
      "output= tensor([[-2.2891, -2.3178, -2.2936,  ..., -2.2862, -2.3161, -2.3215],\n",
      "        [-2.2901, -2.3163, -2.2957,  ..., -2.2875, -2.3221, -2.3166],\n",
      "        [-2.2863, -2.3116, -2.2990,  ..., -2.2922, -2.3179, -2.3179],\n",
      "        ...,\n",
      "        [-2.3813, -2.4095, -2.1922,  ..., -2.3019, -2.2620, -2.3446],\n",
      "        [-2.2949, -2.3113, -2.2995,  ..., -2.3002, -2.2954, -2.3149],\n",
      "        [-2.2846, -2.3135, -2.2975,  ..., -2.2915, -2.3116, -2.3234]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 9, 1, 1, 0, 8, 7, 6, 6, 5, 1, 9, 0, 9, 4, 5, 4, 7, 0, 7, 0, 3, 1, 3,\n",
      "        8, 4, 8, 1, 1, 3, 9, 7, 1, 3, 8, 3, 0, 6, 4, 8, 4, 5, 1, 7, 2, 2, 8, 1,\n",
      "        8, 3, 1, 1, 7, 4, 8, 6, 6, 2, 5, 3, 9, 2, 0, 1, 0, 4, 3, 4, 9, 4, 6, 2,\n",
      "        3, 1, 4, 8, 1, 3, 4, 7, 8, 7, 7, 5, 7, 1, 8, 3, 9, 6, 9, 2, 7, 5, 2, 3,\n",
      "        9, 3, 7, 4, 4, 3, 5, 3, 6, 3, 5, 9, 3, 9, 5, 4, 7, 5, 7, 3, 4, 6, 3, 8,\n",
      "        5, 4, 2, 3, 6, 9, 5, 4, 3, 6, 9, 2, 0, 6, 6, 1, 5, 6, 1, 8, 4, 2, 5, 0,\n",
      "        8, 5, 5, 7, 2, 3, 5, 3, 3, 0, 4, 3, 9, 8, 7, 0, 1, 0, 4, 0, 2, 1, 1, 9,\n",
      "        0, 3, 9, 6, 6, 8, 7, 0, 2, 8, 6, 0, 4, 9, 7, 6, 4, 5, 3, 7, 9, 6, 7, 6,\n",
      "        8, 8, 6, 8, 8, 3, 6, 9, 1, 7, 9, 8, 2, 8, 0, 8, 1, 1, 9, 8, 9, 2, 7, 6,\n",
      "        5, 1, 8, 9, 2, 0, 3, 8, 5, 2, 3, 5, 3, 8, 9, 6, 0, 4, 0, 3, 8, 5, 3, 2,\n",
      "        0, 8, 3, 2, 7, 7, 0, 4, 7, 6, 5, 6, 3, 3, 4, 7])\n",
      "output= tensor([[-2.2947, -2.3114, -2.3002,  ..., -2.3004, -2.2954, -2.3152],\n",
      "        [-2.3008, -2.3131, -2.2978,  ..., -2.2957, -2.3064, -2.3081],\n",
      "        [-2.2644, -2.3308, -2.2901,  ..., -2.2752, -2.3300, -2.3017],\n",
      "        ...,\n",
      "        [-2.2954, -2.3104, -2.2996,  ..., -2.2995, -2.2964, -2.3146],\n",
      "        [-2.2969, -2.3083, -2.3013,  ..., -2.3002, -2.3027, -2.3096],\n",
      "        [-2.2993, -2.3151, -2.2963,  ..., -2.2950, -2.3003, -2.3132]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([4, 6, 3, 2, 3, 1, 7, 7, 9, 1, 2, 6, 9, 9, 3, 9, 0, 1, 6, 9, 6, 5, 0, 1,\n",
      "        6, 6, 7, 1, 1, 6, 3, 0, 1, 0, 7, 9, 8, 8, 3, 6, 4, 3, 4, 6, 4, 1, 5, 4,\n",
      "        8, 0, 0, 7, 9, 3, 0, 0, 6, 4, 2, 2, 9, 8, 1, 6, 1, 8, 3, 5, 6, 3, 2, 3,\n",
      "        5, 8, 5, 1, 7, 1, 0, 4, 3, 8, 6, 4, 1, 1, 6, 5, 5, 8, 2, 4, 4, 4, 2, 8,\n",
      "        2, 8, 9, 3, 4, 4, 9, 0, 2, 2, 5, 9, 3, 2, 0, 7, 5, 8, 3, 2, 8, 4, 6, 3,\n",
      "        0, 3, 0, 1, 1, 1, 4, 5, 8, 0, 6, 9, 5, 2, 9, 2, 1, 0, 3, 6, 4, 2, 3, 6,\n",
      "        6, 6, 6, 6, 6, 7, 6, 3, 0, 8, 4, 4, 8, 0, 6, 9, 6, 1, 8, 4, 6, 6, 1, 0,\n",
      "        8, 9, 0, 4, 9, 5, 9, 4, 0, 7, 1, 1, 7, 1, 7, 2, 6, 2, 3, 5, 3, 9, 3, 1,\n",
      "        3, 0, 3, 0, 7, 1, 1, 3, 4, 5, 1, 0, 6, 5, 5, 4, 2, 6, 1, 3, 1, 9, 4, 7,\n",
      "        9, 4, 6, 5, 4, 8, 9, 4, 7, 9, 9, 1, 2, 1, 7, 3, 1, 8, 7, 7, 0, 0, 6, 9,\n",
      "        0, 3, 9, 5, 2, 2, 1, 1, 0, 0, 8, 7, 7, 6, 7, 1])\n",
      "output= tensor([[-2.2876, -2.3169, -2.2944,  ..., -2.2855, -2.3195, -2.3221],\n",
      "        [-2.3377, -2.2554, -2.2347,  ..., -2.2172, -2.2998, -2.4271],\n",
      "        [-2.8394, -2.1589, -2.2646,  ..., -1.7907, -2.2626, -2.2539],\n",
      "        ...,\n",
      "        [-2.2837, -2.3129, -2.2979,  ..., -2.2901, -2.3156, -2.3238],\n",
      "        [-2.5831, -2.2971, -2.6397,  ..., -2.5079, -1.8825, -2.3435],\n",
      "        [-2.3914, -2.3236, -2.3339,  ..., -2.3459, -2.2197, -2.3107]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([0, 8, 2, 7, 4, 7, 4, 6, 8, 7, 8, 3, 0, 9, 5, 7, 0, 2, 6, 3, 4, 9, 7, 6,\n",
      "        3, 6, 1, 1, 3, 2, 6, 8, 9, 5, 8, 5, 9, 4, 5, 5, 0, 4, 3, 1, 9, 6, 8, 1,\n",
      "        7, 2, 5, 5, 9, 6, 0, 5, 8, 2, 2, 2, 8, 2, 4, 6, 4, 0, 3, 2, 7, 7, 7, 8,\n",
      "        2, 4, 9, 3, 6, 7, 2, 5, 6, 0, 7, 7, 0, 7, 2, 1, 2, 1, 5, 2, 9, 2, 7, 8,\n",
      "        7, 5, 0, 3, 0, 8, 2, 8, 3, 2, 1, 2, 3, 2, 9, 5, 6, 0, 1, 9, 1, 6, 9, 5,\n",
      "        6, 3, 3, 0, 7, 6, 9, 2, 9, 9, 1, 6, 8, 4, 4, 5, 0, 5, 6, 2, 8, 0, 9, 4,\n",
      "        4, 4, 8, 1, 2, 6, 1, 6, 4, 4, 8, 6, 4, 9, 4, 3, 9, 0, 3, 4, 3, 9, 2, 8,\n",
      "        0, 9, 4, 4, 3, 9, 4, 4, 0, 6, 1, 8, 5, 6, 2, 6, 6, 8, 1, 2, 9, 3, 0, 6,\n",
      "        8, 1, 9, 8, 0, 7, 7, 5, 0, 7, 3, 8, 4, 3, 5, 6, 6, 3, 4, 6, 2, 4, 4, 7,\n",
      "        0, 9, 1, 4, 6, 7, 7, 1, 2, 6, 3, 4, 4, 8, 5, 5, 5, 9, 4, 8, 1, 6, 4, 3,\n",
      "        5, 4, 9, 4, 0, 3, 0, 1, 0, 3, 4, 5, 7, 8, 9, 3])\n",
      "output= tensor([[-2.2823, -2.3127, -2.2975,  ..., -2.2885, -2.3193, -2.3245],\n",
      "        [-2.4734, -2.3324, -2.3278,  ..., -2.2952, -2.2886, -2.2098],\n",
      "        [-2.2932, -2.3274, -2.2809,  ..., -2.2894, -2.3057, -2.3134],\n",
      "        ...,\n",
      "        [-2.2998, -2.3147, -2.2968,  ..., -2.2951, -2.3022, -2.3122],\n",
      "        [-2.2876, -2.3162, -2.2951,  ..., -2.2841, -2.3282, -2.3191],\n",
      "        [-2.2967, -2.3079, -2.3018,  ..., -2.3006, -2.3031, -2.3098]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([5, 3, 8, 4, 5, 9, 1, 3, 5, 1, 1, 9, 2, 0, 8, 5, 6, 6, 4, 4, 0, 4, 4, 1,\n",
      "        3, 0, 1, 1, 1, 1, 6, 2, 1, 8, 2, 1, 2, 2, 3, 6, 1, 4, 1, 9, 5, 3, 3, 2,\n",
      "        1, 6, 9, 6, 2, 9, 3, 0, 7, 3, 4, 6, 6, 2, 6, 0, 9, 3, 7, 2, 6, 1, 6, 4,\n",
      "        2, 4, 6, 7, 0, 1, 8, 0, 8, 1, 5, 8, 6, 6, 5, 5, 7, 3, 0, 8, 6, 8, 8, 8,\n",
      "        2, 3, 1, 7, 5, 4, 6, 6, 7, 7, 2, 1, 6, 2, 7, 5, 8, 1, 5, 9, 5, 0, 9, 1,\n",
      "        0, 7, 2, 6, 3, 6, 2, 7, 6, 0, 7, 4, 5, 1, 3, 6, 7, 8, 9, 4, 8, 3, 8, 2,\n",
      "        2, 1, 5, 6, 7, 5, 5, 9, 3, 2, 1, 0, 0, 5, 2, 7, 3, 5, 6, 2, 3, 6, 5, 7,\n",
      "        1, 8, 2, 7, 5, 0, 6, 9, 7, 4, 9, 1, 5, 6, 5, 4, 2, 3, 3, 8, 9, 9, 9, 6,\n",
      "        1, 1, 0, 6, 7, 6, 7, 7, 5, 0, 0, 1, 3, 1, 5, 1, 3, 1, 1, 2, 5, 6, 9, 2,\n",
      "        2, 5, 4, 0, 2, 1, 9, 2, 3, 2, 3, 8, 2, 1, 2, 8, 7, 7, 4, 2, 6, 8, 6, 8,\n",
      "        0, 8, 0, 0, 3, 3, 1, 2, 8, 4, 2, 1, 7, 6, 7, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-2.3002, -2.3150, -2.2961,  ..., -2.2948, -2.3020, -2.3130],\n",
      "        [-2.2852, -2.3185, -2.2927,  ..., -2.2819, -2.3257, -2.3251],\n",
      "        [-2.2820, -2.3111, -2.2983,  ..., -2.2878, -2.3269, -2.3223],\n",
      "        ...,\n",
      "        [-2.3065, -2.2741, -2.2853,  ..., -2.3230, -2.3433, -2.3414],\n",
      "        [-2.2953, -2.3099, -2.3002,  ..., -2.3005, -2.2975, -2.3149],\n",
      "        [-2.2852, -2.3185, -2.2927,  ..., -2.2819, -2.3257, -2.3251]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([6, 3, 9, 5, 3, 5, 2, 9, 2, 0, 1, 4, 2, 9, 1, 6, 1, 2, 6, 8, 1, 8, 0, 7,\n",
      "        6, 4, 5, 2, 0, 2, 4, 7, 8, 2, 0, 6, 9, 0, 1, 9, 6, 9, 1, 1, 1, 9, 6, 3,\n",
      "        2, 5, 3, 9, 9, 2, 5, 6, 7, 4, 2, 5, 0, 9, 3, 4, 2, 2, 4, 0, 1, 9, 0, 3,\n",
      "        3, 1, 4, 5, 7, 1, 8, 8, 9, 8, 8, 3, 5, 0, 8, 8, 6, 4, 1, 8, 1, 0, 2, 2,\n",
      "        3, 5, 8, 4, 4, 8, 1, 8, 0, 4, 2, 8, 2, 6, 3, 5, 5, 0, 1, 3, 7, 6, 3, 0,\n",
      "        4, 7, 0, 9, 2, 2, 9, 1, 7, 1, 6, 9, 1, 1, 7, 7, 7, 0, 2, 1, 0, 3, 3, 3,\n",
      "        2, 0, 3, 8, 2, 9, 2, 4, 3, 8, 0, 7, 3, 0, 7, 7, 5, 1, 3, 4, 7, 8, 2, 1,\n",
      "        6, 2, 9, 1, 6, 8, 2, 9, 9, 9, 8, 6, 2, 5, 2, 1, 6, 0, 4, 4, 9, 2, 3, 6,\n",
      "        6, 4, 3, 2, 6, 0, 3, 3, 6, 9, 5, 2, 8, 1, 6, 8, 8, 3, 6, 5, 9, 7, 9, 2,\n",
      "        4, 4, 8, 6, 9, 4, 2, 3, 0, 3, 4, 4, 4, 1, 3, 0, 0, 5, 1, 0, 8, 8, 4, 3,\n",
      "        8, 3, 0, 4, 7, 4, 3, 2, 7, 8, 7, 4, 6, 0, 0, 9])\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.298387\n",
      "output= tensor([[-2.9050, -2.0257, -1.8721,  ..., -2.4047, -3.0188, -1.9607],\n",
      "        [-2.2817, -2.3109, -2.2978,  ..., -2.2881, -2.3273, -2.3227],\n",
      "        [-2.2857, -2.3187, -2.2921,  ..., -2.2816, -2.3274, -2.3245],\n",
      "        ...,\n",
      "        [-2.2958, -2.3088, -2.2999,  ..., -2.3006, -2.2985, -2.3142],\n",
      "        [-2.2868, -2.3171, -2.2933,  ..., -2.2821, -2.3321, -2.3208],\n",
      "        [-2.3020, -2.3135, -2.2967,  ..., -2.2952, -2.3081, -2.3085]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([5, 8, 4, 6, 2, 0, 6, 8, 8, 7, 0, 9, 4, 0, 7, 8, 1, 3, 4, 4, 6, 9, 1, 2,\n",
      "        1, 5, 4, 7, 0, 8, 7, 1, 0, 8, 6, 0, 0, 7, 9, 0, 8, 6, 2, 8, 0, 8, 8, 4,\n",
      "        1, 3, 6, 6, 8, 1, 6, 0, 3, 1, 4, 3, 0, 6, 8, 2, 4, 8, 6, 0, 0, 4, 0, 7,\n",
      "        8, 5, 9, 3, 8, 6, 3, 7, 2, 4, 9, 9, 1, 0, 9, 8, 7, 3, 9, 6, 2, 7, 1, 5,\n",
      "        0, 6, 5, 3, 3, 3, 6, 4, 7, 8, 9, 1, 7, 8, 0, 2, 2, 1, 2, 2, 6, 4, 1, 2,\n",
      "        3, 3, 9, 1, 8, 7, 0, 4, 8, 9, 9, 2, 2, 1, 0, 9, 2, 6, 0, 1, 0, 1, 3, 1,\n",
      "        9, 3, 2, 1, 8, 1, 9, 7, 2, 1, 3, 9, 3, 8, 8, 5, 7, 2, 5, 6, 8, 4, 8, 6,\n",
      "        1, 3, 8, 6, 3, 4, 0, 9, 2, 7, 8, 1, 4, 3, 5, 0, 3, 1, 9, 5, 7, 9, 3, 1,\n",
      "        8, 0, 7, 2, 1, 0, 6, 5, 0, 7, 2, 8, 6, 0, 4, 0, 5, 3, 1, 1, 5, 0, 2, 3,\n",
      "        1, 5, 7, 1, 6, 8, 8, 3, 7, 5, 3, 9, 7, 3, 3, 5, 3, 5, 3, 8, 5, 9, 5, 7,\n",
      "        8, 9, 8, 3, 1, 1, 9, 8, 3, 3, 5, 0, 4, 9, 7, 0])\n",
      "output= tensor([[-2.3009, -2.3157, -2.2956,  ..., -2.2961, -2.3027, -2.3123],\n",
      "        [-2.4530, -2.2893, -2.3483,  ..., -2.2560, -2.3416, -2.1265],\n",
      "        [-2.2955, -2.3085, -2.2999,  ..., -2.3009, -2.2981, -2.3143],\n",
      "        ...,\n",
      "        [-2.2866, -2.3185, -2.2923,  ..., -2.2830, -2.3259, -2.3240],\n",
      "        [-2.2853, -2.3191, -2.2925,  ..., -2.2832, -2.3256, -2.3247],\n",
      "        [-2.2863, -2.3192, -2.2923,  ..., -2.2834, -2.3259, -2.3242]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([5, 8, 5, 3, 8, 2, 4, 5, 0, 5, 7, 4, 3, 2, 8, 6, 1, 5, 4, 5, 4, 4, 5, 5,\n",
      "        9, 4, 6, 6, 7, 9, 3, 0, 0, 2, 0, 2, 6, 5, 0, 4, 5, 4, 3, 5, 9, 9, 0, 9,\n",
      "        8, 3, 5, 2, 1, 7, 3, 9, 5, 2, 0, 0, 0, 3, 7, 9, 1, 2, 3, 1, 8, 8, 4, 2,\n",
      "        5, 0, 4, 7, 1, 1, 1, 5, 7, 3, 3, 4, 4, 7, 6, 9, 6, 3, 3, 3, 7, 4, 4, 6,\n",
      "        4, 0, 6, 0, 0, 1, 1, 6, 4, 8, 8, 0, 5, 1, 7, 2, 2, 8, 4, 6, 3, 6, 4, 1,\n",
      "        9, 2, 0, 9, 0, 2, 8, 1, 6, 8, 8, 7, 1, 1, 0, 1, 4, 3, 5, 6, 7, 3, 7, 5,\n",
      "        1, 1, 3, 4, 0, 9, 9, 2, 7, 1, 2, 7, 0, 0, 2, 9, 6, 4, 0, 7, 1, 5, 2, 1,\n",
      "        5, 4, 8, 1, 8, 0, 6, 8, 2, 1, 1, 0, 8, 1, 2, 9, 1, 9, 0, 1, 6, 1, 0, 3,\n",
      "        9, 5, 4, 4, 7, 1, 9, 4, 3, 1, 4, 7, 3, 8, 3, 0, 2, 0, 2, 4, 6, 3, 3, 4,\n",
      "        1, 5, 9, 3, 3, 4, 7, 6, 0, 8, 7, 1, 9, 7, 8, 8, 8, 5, 7, 6, 8, 6, 1, 1,\n",
      "        1, 7, 0, 0, 6, 9, 2, 3, 2, 9, 8, 3, 5, 3, 1, 5])\n",
      "output= tensor([[-2.2811, -2.3115, -2.2970,  ..., -2.2883, -2.3208, -2.3263],\n",
      "        [-2.2824, -2.3102, -2.2982,  ..., -2.2890, -2.3256, -2.3224],\n",
      "        [-2.7318, -1.9905, -2.3255,  ..., -1.8396, -2.2391, -2.0894],\n",
      "        ...,\n",
      "        [-2.2955, -2.3082, -2.3001,  ..., -2.3015, -2.2981, -2.3144],\n",
      "        [-2.2871, -2.3160, -2.2940,  ..., -2.2836, -2.3300, -2.3207],\n",
      "        [-2.2820, -2.3101, -2.2981,  ..., -2.2894, -2.3258, -2.3225]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 7, 7, 4, 7, 1, 6, 8, 9, 4, 3, 4, 9, 3, 5, 9, 4, 4, 9, 1, 3, 7, 6, 0,\n",
      "        3, 0, 9, 1, 9, 5, 3, 3, 3, 2, 0, 1, 4, 0, 9, 3, 9, 4, 5, 3, 6, 4, 8, 7,\n",
      "        7, 9, 7, 7, 0, 2, 6, 1, 6, 6, 6, 6, 8, 6, 5, 7, 6, 2, 5, 5, 5, 5, 5, 0,\n",
      "        6, 8, 4, 9, 2, 8, 0, 3, 2, 0, 3, 2, 3, 4, 6, 7, 0, 5, 9, 0, 4, 1, 0, 8,\n",
      "        2, 5, 3, 9, 2, 1, 6, 1, 7, 2, 5, 0, 1, 6, 8, 0, 7, 7, 0, 2, 0, 2, 2, 2,\n",
      "        3, 6, 0, 6, 2, 2, 5, 1, 3, 7, 5, 3, 2, 2, 0, 7, 0, 8, 3, 3, 9, 8, 8, 0,\n",
      "        8, 7, 9, 2, 9, 2, 3, 2, 8, 0, 8, 4, 0, 7, 7, 0, 6, 6, 7, 5, 5, 6, 0, 2,\n",
      "        7, 3, 1, 9, 0, 3, 4, 3, 6, 5, 2, 3, 5, 7, 0, 9, 0, 2, 0, 1, 1, 4, 3, 8,\n",
      "        5, 7, 3, 9, 2, 0, 8, 1, 3, 1, 5, 2, 0, 9, 0, 0, 0, 9, 8, 4, 4, 1, 5, 8,\n",
      "        7, 5, 7, 7, 0, 8, 1, 1, 7, 0, 7, 1, 8, 0, 6, 3, 1, 3, 2, 9, 4, 6, 1, 8,\n",
      "        7, 2, 8, 7, 9, 7, 3, 3, 1, 5, 1, 3, 1, 1, 1, 2])\n",
      "output= tensor([[-2.2957, -2.3073, -2.3009,  ..., -2.3017, -2.3015, -2.3110],\n",
      "        [-2.2994, -2.3137, -2.2956,  ..., -2.2957, -2.3020, -2.3130],\n",
      "        [-2.2798, -2.3128, -2.2963,  ..., -2.2876, -2.3201, -2.3272],\n",
      "        ...,\n",
      "        [-2.2996, -2.3148, -2.2956,  ..., -2.2954, -2.3005, -2.3132],\n",
      "        [-2.3328, -2.3337, -2.2944,  ..., -2.2657, -2.3062, -2.2842],\n",
      "        [-2.3293, -2.3626, -2.5287,  ..., -2.5646, -2.1389, -2.3346]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([4, 0, 1, 5, 5, 3, 4, 5, 3, 4, 3, 1, 6, 2, 1, 1, 3, 3, 9, 9, 2, 9, 2, 2,\n",
      "        3, 7, 2, 1, 2, 0, 1, 6, 1, 2, 0, 7, 0, 4, 4, 4, 4, 2, 1, 9, 8, 8, 9, 3,\n",
      "        8, 7, 4, 9, 8, 7, 4, 7, 7, 1, 7, 4, 3, 8, 4, 5, 0, 1, 6, 7, 5, 9, 7, 7,\n",
      "        3, 9, 8, 5, 7, 1, 7, 3, 3, 4, 8, 1, 1, 8, 0, 2, 9, 3, 0, 0, 8, 7, 5, 4,\n",
      "        8, 3, 2, 3, 9, 5, 7, 1, 3, 7, 8, 2, 6, 8, 4, 3, 2, 6, 7, 4, 6, 3, 0, 1,\n",
      "        4, 8, 9, 4, 6, 4, 2, 7, 1, 3, 7, 3, 1, 8, 7, 7, 6, 2, 1, 8, 1, 3, 1, 2,\n",
      "        6, 0, 3, 2, 2, 7, 7, 0, 7, 0, 4, 6, 7, 8, 8, 2, 8, 1, 1, 0, 1, 6, 8, 2,\n",
      "        5, 0, 0, 3, 9, 9, 1, 1, 9, 8, 3, 1, 8, 8, 0, 0, 9, 9, 6, 4, 0, 3, 6, 6,\n",
      "        7, 0, 1, 2, 4, 7, 8, 2, 1, 6, 5, 1, 8, 1, 4, 3, 2, 6, 0, 5, 7, 6, 8, 9,\n",
      "        6, 2, 0, 7, 2, 3, 1, 1, 0, 2, 0, 7, 8, 8, 0, 9, 1, 2, 1, 7, 0, 3, 4, 1,\n",
      "        0, 3, 9, 4, 1, 4, 9, 1, 3, 3, 2, 3, 1, 0, 8, 3])\n",
      "output= tensor([[-2.2951, -2.3058, -2.3015,  ..., -2.3019, -2.3026, -2.3117],\n",
      "        [-2.2959, -2.3061, -2.3017,  ..., -2.3012, -2.3020, -2.3116],\n",
      "        [-2.2855, -2.3149, -2.2937,  ..., -2.2831, -2.3309, -2.3216],\n",
      "        ...,\n",
      "        [-2.3243, -2.4115, -2.2999,  ..., -2.2435, -2.2684, -2.3325],\n",
      "        [-2.3003, -2.3115, -2.2969,  ..., -2.2959, -2.3075, -2.3096],\n",
      "        [-2.2994, -2.3136, -2.2969,  ..., -2.2962, -2.3051, -2.3103]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 7, 4, 4, 7, 4, 3, 1, 0, 2, 5, 0, 2, 1, 1, 4, 8, 8, 7, 6, 5, 0, 6, 8,\n",
      "        0, 1, 8, 3, 9, 5, 2, 2, 8, 4, 6, 6, 4, 0, 6, 3, 4, 6, 9, 7, 4, 8, 0, 0,\n",
      "        8, 9, 5, 8, 4, 6, 5, 7, 7, 8, 1, 6, 5, 8, 8, 3, 0, 9, 7, 3, 6, 8, 5, 4,\n",
      "        8, 6, 9, 4, 1, 1, 3, 5, 1, 4, 3, 3, 6, 3, 0, 1, 6, 2, 7, 6, 8, 0, 1, 1,\n",
      "        9, 7, 6, 2, 2, 8, 1, 3, 1, 1, 7, 2, 7, 4, 2, 9, 9, 2, 1, 0, 5, 2, 6, 5,\n",
      "        8, 3, 2, 6, 4, 0, 0, 0, 5, 2, 2, 9, 3, 7, 4, 3, 8, 3, 0, 5, 1, 8, 1, 9,\n",
      "        4, 8, 5, 1, 4, 3, 1, 1, 5, 2, 4, 6, 3, 9, 5, 8, 9, 1, 3, 9, 7, 9, 1, 6,\n",
      "        2, 4, 8, 2, 8, 3, 9, 8, 7, 7, 6, 6, 2, 8, 3, 9, 3, 7, 2, 3, 2, 9, 7, 4,\n",
      "        9, 2, 5, 9, 6, 5, 1, 1, 2, 4, 4, 9, 5, 3, 8, 3, 3, 3, 1, 7, 9, 8, 3, 9,\n",
      "        8, 8, 4, 7, 0, 6, 1, 7, 2, 5, 7, 9, 0, 7, 2, 0, 7, 8, 4, 7, 2, 2, 6, 0,\n",
      "        4, 4, 2, 6, 3, 6, 5, 1, 7, 4, 3, 3, 8, 5, 5, 7])\n",
      "output= tensor([[-2.2954, -2.3067, -2.3004,  ..., -2.3002, -2.2982, -2.3148],\n",
      "        [-2.2876, -2.3069, -2.2985,  ..., -2.2943, -2.3246, -2.3202],\n",
      "        [-2.2866, -2.3167, -2.2924,  ..., -2.2816, -2.3259, -2.3243],\n",
      "        ...,\n",
      "        [-2.2943, -2.3067, -2.3003,  ..., -2.3012, -2.2985, -2.3151],\n",
      "        [-2.2946, -2.3064, -2.3001,  ..., -2.3010, -2.2988, -2.3149],\n",
      "        [-2.3001, -2.3137, -2.2963,  ..., -2.2954, -2.3056, -2.3103]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 8, 2, 3, 1, 5, 5, 5, 2, 6, 3, 7, 9, 6, 9, 0, 1, 8, 2, 9, 1, 8, 2, 5,\n",
      "        8, 2, 3, 3, 2, 7, 4, 0, 3, 8, 7, 8, 5, 2, 1, 3, 2, 0, 2, 8, 4, 1, 7, 3,\n",
      "        0, 0, 9, 1, 6, 2, 3, 3, 1, 1, 1, 6, 1, 3, 5, 6, 5, 4, 6, 0, 9, 7, 3, 2,\n",
      "        2, 2, 0, 0, 3, 9, 2, 3, 0, 9, 7, 1, 4, 5, 7, 5, 6, 8, 9, 3, 0, 8, 9, 6,\n",
      "        1, 9, 6, 8, 9, 8, 1, 1, 6, 5, 5, 5, 1, 3, 0, 4, 7, 2, 8, 5, 0, 7, 1, 9,\n",
      "        5, 4, 6, 9, 5, 4, 7, 1, 2, 3, 4, 3, 7, 7, 2, 8, 1, 1, 4, 5, 5, 7, 6, 8,\n",
      "        0, 9, 7, 7, 3, 3, 1, 4, 9, 9, 1, 8, 6, 2, 6, 3, 5, 5, 9, 4, 4, 4, 0, 5,\n",
      "        8, 1, 5, 1, 7, 1, 1, 1, 9, 1, 4, 6, 8, 6, 2, 6, 6, 6, 9, 7, 9, 4, 7, 8,\n",
      "        5, 3, 2, 5, 4, 9, 7, 3, 7, 7, 2, 1, 7, 9, 8, 4, 0, 4, 5, 7, 0, 6, 3, 6,\n",
      "        5, 0, 9, 6, 3, 6, 3, 2, 2, 1, 8, 7, 8, 5, 5, 9, 3, 1, 9, 9, 5, 3, 4, 9,\n",
      "        1, 3, 0, 6, 0, 5, 9, 0, 8, 5, 1, 7, 7, 1, 7, 5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-2.2817, -2.3096, -2.2982,  ..., -2.2883, -2.3231, -2.3231],\n",
      "        [-2.3005, -2.3119, -2.2960,  ..., -2.2949, -2.3055, -2.3117],\n",
      "        [-2.2956, -2.3066, -2.3016,  ..., -2.3012, -2.3003, -2.3124],\n",
      "        ...,\n",
      "        [-2.2864, -2.3156, -2.2932,  ..., -2.2829, -2.3289, -2.3216],\n",
      "        [-2.2951, -2.3056, -2.3008,  ..., -2.3009, -2.3002, -2.3133],\n",
      "        [-2.2812, -2.3096, -2.2980,  ..., -2.2886, -2.3218, -2.3255]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([4, 0, 1, 1, 3, 2, 6, 2, 9, 5, 4, 8, 4, 1, 3, 1, 2, 6, 2, 3, 8, 8, 5, 3,\n",
      "        3, 9, 4, 0, 7, 9, 8, 8, 0, 0, 6, 7, 6, 9, 4, 1, 4, 8, 5, 9, 5, 8, 0, 9,\n",
      "        9, 6, 8, 9, 4, 4, 0, 8, 5, 5, 0, 1, 9, 7, 3, 2, 6, 8, 0, 2, 1, 2, 6, 8,\n",
      "        9, 4, 1, 6, 1, 1, 5, 2, 8, 4, 9, 0, 7, 6, 5, 5, 2, 1, 5, 5, 1, 5, 0, 0,\n",
      "        7, 9, 2, 2, 0, 8, 2, 6, 4, 3, 2, 9, 5, 6, 7, 5, 4, 1, 1, 3, 6, 2, 9, 2,\n",
      "        8, 3, 5, 9, 2, 1, 3, 7, 6, 6, 5, 7, 3, 6, 0, 1, 6, 6, 6, 5, 5, 0, 0, 5,\n",
      "        9, 8, 9, 0, 2, 1, 0, 9, 2, 4, 0, 4, 4, 7, 0, 2, 8, 2, 9, 6, 7, 0, 3, 2,\n",
      "        0, 1, 8, 1, 8, 9, 7, 9, 6, 3, 1, 0, 4, 3, 2, 5, 2, 1, 4, 3, 1, 2, 8, 0,\n",
      "        2, 9, 5, 0, 1, 7, 1, 2, 6, 4, 7, 2, 9, 6, 0, 5, 5, 2, 3, 4, 1, 5, 2, 3,\n",
      "        0, 4, 7, 0, 9, 5, 2, 9, 1, 6, 7, 2, 9, 4, 6, 2, 7, 6, 1, 1, 6, 9, 7, 0,\n",
      "        0, 8, 2, 1, 0, 7, 6, 1, 9, 4, 7, 1, 2, 1, 0, 0])\n",
      "output= tensor([[-2.2841, -2.3154, -2.2935,  ..., -2.2821, -2.3287, -2.3234],\n",
      "        [-2.5158, -2.3720, -2.2642,  ..., -2.2351, -2.3391, -2.0573],\n",
      "        [-2.2996, -2.3117, -2.2969,  ..., -2.2955, -2.3043, -2.3110],\n",
      "        ...,\n",
      "        [-2.2949, -2.3054, -2.3008,  ..., -2.3009, -2.3003, -2.3125],\n",
      "        [-2.3258, -2.2976, -2.2742,  ..., -2.1979, -2.4331, -2.2822],\n",
      "        [-2.2946, -2.3058, -2.3010,  ..., -2.3012, -2.2999, -2.3128]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 3, 6, 3, 8, 0, 5, 4, 1, 3, 8, 3, 3, 1, 9, 4, 5, 0, 3, 1, 4, 4, 1, 6,\n",
      "        2, 9, 4, 4, 7, 6, 9, 2, 5, 4, 9, 4, 9, 6, 1, 1, 2, 5, 1, 7, 4, 7, 3, 2,\n",
      "        5, 0, 2, 9, 8, 5, 3, 8, 0, 2, 7, 2, 3, 5, 1, 4, 1, 9, 1, 0, 3, 4, 5, 0,\n",
      "        5, 2, 5, 2, 9, 3, 0, 2, 3, 7, 0, 2, 6, 7, 2, 6, 1, 3, 0, 7, 6, 3, 5, 0,\n",
      "        9, 0, 8, 4, 0, 7, 9, 4, 2, 0, 2, 8, 5, 5, 1, 9, 6, 3, 7, 6, 5, 0, 1, 8,\n",
      "        6, 6, 0, 7, 2, 0, 7, 1, 1, 5, 8, 2, 4, 8, 4, 0, 3, 3, 7, 8, 9, 1, 8, 6,\n",
      "        6, 1, 6, 1, 8, 7, 0, 8, 7, 2, 7, 0, 6, 7, 9, 8, 7, 8, 2, 1, 1, 0, 6, 0,\n",
      "        2, 9, 1, 8, 0, 6, 9, 1, 1, 8, 3, 1, 5, 0, 6, 6, 1, 1, 8, 5, 1, 4, 9, 3,\n",
      "        2, 3, 3, 3, 4, 7, 5, 9, 3, 4, 5, 9, 1, 2, 9, 5, 7, 9, 9, 2, 7, 4, 1, 7,\n",
      "        4, 3, 4, 9, 7, 5, 4, 2, 0, 7, 1, 9, 6, 8, 8, 0, 2, 3, 2, 6, 2, 8, 1, 6,\n",
      "        0, 4, 1, 1, 3, 3, 6, 7, 7, 4, 3, 3, 4, 7, 8, 7])\n",
      "output= tensor([[-2.2800, -2.3073, -2.2973,  ..., -2.2880, -2.3278, -2.3244],\n",
      "        [-2.2796, -2.3080, -2.2976,  ..., -2.2885, -2.3271, -2.3247],\n",
      "        [-2.7309, -2.6391, -2.4431,  ..., -2.2189, -2.2483, -2.0685],\n",
      "        ...,\n",
      "        [-2.3004, -2.3096, -2.2965,  ..., -2.2958, -2.3079, -2.3100],\n",
      "        [-2.2796, -2.3080, -2.2967,  ..., -2.2878, -2.3257, -2.3259],\n",
      "        [-2.2950, -2.3043, -2.3013,  ..., -2.3019, -2.3025, -2.3119]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 0, 9, 9, 5, 6, 6, 8, 1, 0, 5, 7, 2, 3, 1, 7, 8, 2, 4, 9, 7, 7, 0, 8,\n",
      "        6, 2, 1, 8, 8, 0, 4, 4, 7, 0, 8, 4, 4, 7, 7, 2, 9, 8, 6, 2, 0, 4, 0, 9,\n",
      "        6, 8, 1, 7, 4, 5, 7, 9, 3, 9, 8, 3, 2, 8, 7, 9, 7, 6, 1, 3, 3, 9, 9, 7,\n",
      "        1, 6, 2, 2, 6, 1, 6, 6, 6, 5, 8, 9, 7, 8, 7, 3, 9, 3, 9, 4, 5, 8, 2, 5,\n",
      "        8, 3, 4, 1, 6, 6, 1, 8, 1, 6, 9, 0, 3, 1, 5, 4, 1, 9, 0, 7, 9, 2, 3, 6,\n",
      "        2, 8, 6, 8, 4, 4, 5, 3, 0, 1, 0, 6, 6, 2, 2, 0, 0, 5, 9, 9, 3, 9, 0, 1,\n",
      "        0, 1, 9, 7, 3, 7, 9, 6, 0, 0, 1, 8, 0, 9, 9, 3, 7, 5, 0, 2, 7, 1, 6, 3,\n",
      "        2, 1, 5, 4, 7, 5, 8, 5, 7, 0, 7, 1, 7, 8, 0, 6, 7, 4, 1, 0, 1, 2, 6, 9,\n",
      "        5, 1, 1, 5, 9, 5, 6, 4, 6, 5, 3, 9, 9, 8, 9, 2, 5, 7, 0, 6, 3, 2, 2, 0,\n",
      "        6, 7, 8, 4, 9, 6, 1, 3, 1, 0, 4, 0, 8, 8, 1, 8, 4, 7, 0, 1, 9, 8, 7, 4,\n",
      "        7, 0, 0, 5, 1, 4, 9, 8, 6, 2, 8, 3, 6, 1, 1, 8])\n",
      "output= tensor([[-2.3361, -2.2984, -2.2914,  ..., -2.3386, -2.3212, -2.1329],\n",
      "        [-2.2792, -2.3080, -2.2982,  ..., -2.2870, -2.3271, -2.3227],\n",
      "        [-2.2847, -2.3132, -2.2929,  ..., -2.2817, -2.3331, -2.3225],\n",
      "        ...,\n",
      "        [-2.2831, -2.3154, -2.2929,  ..., -2.2824, -2.3289, -2.3256],\n",
      "        [-2.1301, -2.7554, -2.2758,  ..., -2.8987, -1.5862, -2.4088],\n",
      "        [-2.6252, -2.4508, -2.2535,  ..., -2.2585, -2.4249, -2.1417]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([8, 6, 5, 6, 8, 5, 7, 7, 1, 8, 4, 9, 3, 6, 2, 7, 8, 9, 0, 0, 0, 7, 9, 6,\n",
      "        4, 8, 1, 1, 6, 4, 1, 7, 1, 2, 8, 6, 7, 6, 6, 9, 4, 0, 5, 1, 7, 5, 2, 0,\n",
      "        3, 4, 0, 5, 0, 1, 2, 6, 4, 8, 5, 0, 0, 9, 4, 6, 5, 2, 8, 4, 2, 6, 2, 1,\n",
      "        0, 4, 1, 1, 8, 2, 5, 1, 9, 7, 1, 6, 2, 3, 8, 2, 8, 5, 3, 1, 6, 5, 4, 5,\n",
      "        0, 3, 2, 3, 2, 2, 8, 4, 6, 8, 1, 8, 9, 6, 9, 1, 8, 6, 5, 5, 7, 9, 3, 9,\n",
      "        3, 3, 9, 2, 1, 5, 0, 5, 1, 2, 6, 2, 4, 1, 8, 0, 8, 2, 1, 7, 2, 9, 0, 7,\n",
      "        2, 6, 7, 7, 3, 6, 4, 2, 1, 6, 6, 4, 3, 6, 3, 0, 1, 1, 8, 7, 4, 6, 1, 3,\n",
      "        1, 2, 7, 9, 5, 1, 9, 6, 6, 4, 0, 4, 0, 3, 4, 0, 8, 3, 6, 2, 0, 7, 6, 3,\n",
      "        2, 3, 8, 1, 6, 0, 7, 1, 5, 1, 2, 0, 4, 0, 4, 8, 8, 4, 7, 0, 4, 5, 2, 7,\n",
      "        0, 3, 7, 8, 5, 2, 3, 2, 3, 1, 7, 9, 2, 0, 0, 7, 3, 9, 2, 4, 7, 3, 3, 1,\n",
      "        4, 6, 1, 1, 5, 4, 1, 9, 0, 5, 1, 2, 7, 2, 3, 0])\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.291709\n",
      "output= tensor([[-2.2987, -2.3115, -2.2959,  ..., -2.2958, -2.3038, -2.3134],\n",
      "        [-2.2951, -2.3029, -2.3005,  ..., -2.3013, -2.3034, -2.3117],\n",
      "        [-2.4247, -2.3122, -2.3549,  ..., -2.3260, -2.1438, -2.2228],\n",
      "        ...,\n",
      "        [-2.2934, -2.3050, -2.3006,  ..., -2.3020, -2.2987, -2.3154],\n",
      "        [-2.2987, -2.3118, -2.2955,  ..., -2.2957, -2.3038, -2.3132],\n",
      "        [-2.2936, -2.3059, -2.3023,  ..., -2.3014, -2.3007, -2.3097]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([5, 4, 4, 8, 3, 7, 1, 9, 5, 7, 2, 4, 2, 5, 6, 9, 3, 1, 0, 0, 6, 6, 6, 8,\n",
      "        1, 9, 0, 3, 5, 5, 3, 0, 5, 5, 4, 1, 1, 5, 3, 6, 5, 3, 5, 4, 0, 7, 2, 7,\n",
      "        3, 7, 3, 8, 4, 0, 3, 7, 2, 1, 8, 9, 7, 4, 9, 5, 2, 4, 0, 4, 2, 7, 2, 2,\n",
      "        2, 3, 1, 5, 1, 4, 3, 9, 6, 0, 4, 2, 4, 4, 4, 9, 5, 0, 9, 7, 6, 9, 4, 2,\n",
      "        5, 8, 6, 1, 9, 8, 2, 6, 6, 1, 7, 8, 6, 5, 4, 2, 9, 7, 3, 3, 9, 4, 0, 4,\n",
      "        0, 4, 6, 0, 8, 9, 6, 3, 6, 3, 5, 0, 9, 5, 0, 8, 2, 6, 2, 7, 5, 7, 9, 1,\n",
      "        3, 4, 1, 0, 1, 3, 6, 1, 0, 1, 9, 3, 7, 9, 3, 7, 1, 8, 9, 6, 9, 7, 6, 5,\n",
      "        7, 2, 1, 8, 0, 9, 7, 3, 9, 5, 6, 1, 8, 5, 0, 2, 1, 3, 1, 5, 1, 2, 2, 7,\n",
      "        2, 9, 5, 3, 0, 2, 6, 8, 4, 0, 8, 5, 8, 9, 3, 0, 7, 4, 6, 5, 4, 8, 5, 7,\n",
      "        1, 7, 6, 3, 1, 2, 6, 1, 7, 9, 3, 8, 6, 5, 7, 2, 1, 3, 3, 3, 2, 8, 2, 9,\n",
      "        6, 8, 2, 3, 1, 0, 3, 7, 1, 0, 5, 9, 7, 7, 2, 2])\n",
      "output= tensor([[-2.2990, -2.0477, -2.1865,  ..., -2.3791, -2.3538, -2.3208],\n",
      "        [-2.2990, -2.3137, -2.2968,  ..., -2.2958, -2.3018, -2.3109],\n",
      "        [-2.2771, -2.3082, -2.2979,  ..., -2.2857, -2.3296, -2.3238],\n",
      "        ...,\n",
      "        [-2.4274, -2.3900, -2.2593,  ..., -2.3104, -2.3748, -2.2448],\n",
      "        [-2.3049, -2.3084, -2.3005,  ..., -2.3169, -2.3083, -2.3024],\n",
      "        [-2.2941, -2.3037, -2.2998,  ..., -2.3011, -2.3000, -2.3149]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 0, 1, 9, 3, 0, 8, 9, 2, 0, 2, 0, 7, 8, 6, 9, 1, 7, 1, 8, 8, 4, 2, 7,\n",
      "        8, 3, 1, 0, 5, 7, 0, 8, 7, 1, 6, 2, 2, 8, 4, 2, 3, 0, 4, 7, 9, 7, 6, 8,\n",
      "        4, 3, 0, 0, 0, 0, 5, 8, 0, 1, 4, 9, 1, 5, 7, 8, 8, 6, 4, 8, 5, 3, 7, 4,\n",
      "        2, 0, 8, 7, 3, 8, 9, 9, 3, 5, 8, 2, 2, 5, 5, 5, 1, 3, 3, 2, 2, 9, 3, 7,\n",
      "        9, 0, 0, 2, 0, 0, 0, 5, 1, 4, 9, 2, 0, 1, 7, 8, 7, 4, 2, 7, 1, 6, 7, 4,\n",
      "        6, 4, 3, 6, 2, 9, 1, 1, 9, 9, 4, 1, 7, 7, 6, 7, 0, 2, 9, 1, 1, 7, 9, 8,\n",
      "        6, 0, 7, 4, 7, 1, 3, 2, 2, 4, 8, 8, 8, 3, 3, 0, 3, 9, 0, 0, 4, 8, 6, 0,\n",
      "        9, 8, 3, 5, 8, 4, 2, 6, 7, 2, 2, 9, 3, 9, 1, 9, 6, 8, 8, 1, 5, 4, 3, 5,\n",
      "        7, 8, 3, 6, 6, 7, 9, 9, 0, 4, 4, 1, 0, 6, 8, 7, 1, 6, 8, 1, 1, 8, 6, 1,\n",
      "        9, 5, 4, 2, 9, 9, 4, 7, 2, 1, 5, 8, 6, 3, 5, 4, 8, 7, 9, 6, 7, 2, 0, 0,\n",
      "        8, 0, 0, 3, 6, 3, 6, 5, 8, 1, 7, 2, 0, 9, 8, 3])\n",
      "output= tensor([[-2.2917, -2.3076, -2.3037,  ..., -2.3029, -2.2987, -2.3108],\n",
      "        [-2.5106, -2.5745, -2.4567,  ..., -2.2628, -2.2449, -1.7241],\n",
      "        [-2.3919, -2.3031, -2.3666,  ..., -2.3156, -2.2695, -2.3144],\n",
      "        ...,\n",
      "        [-2.7328, -2.4953, -1.9936,  ..., -2.1612, -1.9094, -2.4942],\n",
      "        [-2.2736, -2.3120, -2.2996,  ..., -2.2873, -2.3273, -2.3254],\n",
      "        [-2.2809, -2.3158, -2.2934,  ..., -2.2789, -2.3350, -2.3218]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 7, 3, 0, 6, 5, 4, 3, 2, 5, 0, 1, 9, 6, 4, 7, 8, 1, 3, 6, 4, 6, 4, 1,\n",
      "        0, 8, 1, 7, 1, 9, 7, 0, 7, 3, 8, 8, 2, 6, 8, 3, 2, 3, 3, 6, 6, 1, 1, 5,\n",
      "        2, 7, 6, 2, 4, 4, 8, 6, 9, 9, 8, 3, 0, 9, 6, 1, 4, 2, 3, 4, 6, 4, 1, 8,\n",
      "        2, 1, 4, 7, 7, 6, 9, 1, 8, 4, 0, 0, 1, 6, 9, 6, 1, 2, 0, 3, 2, 7, 3, 2,\n",
      "        1, 1, 2, 9, 3, 8, 2, 9, 1, 2, 4, 5, 6, 5, 4, 3, 4, 4, 9, 7, 8, 6, 9, 4,\n",
      "        5, 4, 9, 3, 8, 2, 1, 9, 8, 9, 6, 2, 7, 3, 0, 1, 9, 1, 3, 8, 6, 6, 4, 7,\n",
      "        2, 9, 2, 7, 7, 2, 3, 1, 6, 7, 0, 5, 3, 8, 8, 1, 8, 5, 0, 6, 5, 9, 1, 8,\n",
      "        8, 5, 6, 1, 5, 2, 8, 3, 7, 0, 3, 8, 4, 8, 5, 9, 2, 5, 7, 1, 1, 6, 8, 8,\n",
      "        5, 5, 0, 1, 5, 5, 2, 6, 2, 3, 2, 7, 5, 7, 8, 9, 3, 0, 0, 2, 3, 8, 9, 9,\n",
      "        8, 3, 3, 6, 5, 3, 1, 6, 5, 5, 5, 4, 9, 9, 1, 3, 0, 0, 2, 7, 5, 3, 3, 1,\n",
      "        3, 6, 0, 6, 8, 7, 4, 2, 3, 9, 0, 8, 0, 4, 6, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-2.2816, -2.3145, -2.2905,  ..., -2.2788, -2.3311, -2.3286],\n",
      "        [-2.2721, -2.3143, -2.2991,  ..., -2.2873, -2.3198, -2.3292],\n",
      "        [-2.2816, -2.3164, -2.2933,  ..., -2.2781, -2.3328, -2.3209],\n",
      "        ...,\n",
      "        [-2.2750, -2.3113, -2.2967,  ..., -2.2838, -2.3224, -2.3270],\n",
      "        [-2.3256, -2.3422, -2.2685,  ..., -2.2712, -2.2677, -2.3269],\n",
      "        [-2.2759, -2.3078, -2.2952,  ..., -2.2854, -2.3260, -2.3307]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([8, 7, 7, 6, 1, 4, 0, 4, 9, 1, 3, 2, 1, 0, 2, 1, 0, 8, 0, 4, 2, 3, 2, 1,\n",
      "        7, 9, 0, 3, 4, 2, 6, 9, 2, 4, 4, 0, 2, 2, 8, 3, 9, 5, 8, 2, 4, 1, 5, 6,\n",
      "        0, 6, 4, 4, 7, 4, 1, 0, 8, 5, 9, 8, 7, 2, 4, 9, 7, 9, 4, 6, 7, 0, 8, 1,\n",
      "        3, 4, 8, 7, 1, 2, 6, 7, 2, 6, 1, 1, 7, 0, 3, 8, 8, 3, 3, 6, 3, 9, 4, 9,\n",
      "        5, 5, 8, 3, 8, 2, 4, 7, 3, 4, 5, 6, 1, 9, 8, 3, 1, 3, 6, 9, 6, 1, 3, 8,\n",
      "        0, 3, 8, 0, 3, 6, 3, 5, 1, 8, 5, 7, 8, 3, 1, 7, 1, 7, 0, 1, 7, 1, 2, 6,\n",
      "        7, 0, 0, 4, 3, 5, 0, 8, 2, 5, 0, 0, 8, 9, 9, 1, 9, 9, 0, 1, 5, 6, 1, 7,\n",
      "        2, 5, 0, 3, 1, 0, 4, 0, 3, 0, 5, 9, 7, 8, 2, 7, 2, 2, 2, 0, 8, 4, 5, 1,\n",
      "        6, 2, 4, 2, 7, 0, 1, 1, 4, 2, 4, 8, 2, 8, 8, 7, 4, 8, 4, 9, 8, 0, 6, 6,\n",
      "        1, 8, 3, 2, 1, 0, 5, 0, 0, 8, 6, 7, 6, 2, 9, 0, 8, 1, 6, 5, 8, 7, 4, 2,\n",
      "        7, 3, 0, 6, 7, 6, 0, 8, 5, 1, 9, 3, 7, 0, 5, 7])\n",
      "output= tensor([[-2.2890, -2.3113, -2.3026,  ..., -2.3030, -2.2894, -2.3158],\n",
      "        [-2.2902, -2.3096, -2.3031,  ..., -2.3024, -2.2913, -2.3152],\n",
      "        [-2.6086, -2.2002, -2.2939,  ..., -2.1484, -2.4787, -2.1666],\n",
      "        ...,\n",
      "        [-2.2719, -2.3137, -2.2991,  ..., -2.2875, -2.3196, -2.3298],\n",
      "        [-2.2756, -2.3099, -2.2977,  ..., -2.2850, -2.3265, -2.3235],\n",
      "        [-2.2961, -2.3142, -2.2997,  ..., -2.2974, -2.3019, -2.3092]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([0, 3, 8, 2, 4, 6, 2, 2, 6, 6, 0, 6, 6, 4, 0, 6, 3, 0, 9, 6, 5, 6, 0, 4,\n",
      "        2, 6, 1, 5, 7, 4, 0, 2, 4, 2, 8, 1, 0, 3, 0, 4, 1, 5, 3, 2, 7, 7, 6, 0,\n",
      "        0, 8, 8, 7, 2, 4, 9, 7, 0, 0, 9, 0, 6, 9, 5, 2, 6, 8, 3, 8, 7, 2, 1, 1,\n",
      "        9, 6, 8, 4, 7, 4, 9, 0, 9, 1, 9, 4, 2, 9, 8, 6, 3, 2, 1, 9, 6, 3, 9, 7,\n",
      "        8, 0, 9, 6, 8, 7, 4, 4, 0, 9, 2, 4, 5, 8, 8, 1, 8, 5, 9, 2, 7, 1, 9, 7,\n",
      "        5, 5, 7, 3, 2, 9, 5, 8, 7, 9, 0, 3, 0, 0, 1, 7, 7, 2, 9, 7, 6, 0, 9, 4,\n",
      "        2, 5, 9, 1, 7, 3, 9, 8, 0, 0, 5, 2, 4, 1, 0, 4, 0, 3, 7, 8, 5, 8, 8, 9,\n",
      "        5, 1, 7, 5, 0, 3, 3, 2, 2, 7, 4, 9, 4, 6, 5, 7, 1, 5, 1, 8, 5, 6, 2, 7,\n",
      "        4, 2, 0, 8, 4, 8, 3, 6, 6, 4, 7, 7, 9, 6, 5, 5, 0, 0, 5, 0, 2, 8, 4, 6,\n",
      "        5, 4, 3, 3, 9, 8, 6, 4, 9, 5, 5, 6, 4, 3, 1, 7, 4, 4, 9, 9, 8, 5, 5, 7,\n",
      "        8, 2, 6, 9, 3, 5, 1, 0, 1, 3, 9, 4, 7, 4, 4, 2])\n",
      "output= tensor([[-2.2815, -2.3155, -2.2937,  ..., -2.2775, -2.3331, -2.3204],\n",
      "        [-2.2952, -2.3156, -2.2962,  ..., -2.2975, -2.2969, -2.3167],\n",
      "        [-2.2727, -2.3122, -2.3004,  ..., -2.2872, -2.3249, -2.3248],\n",
      "        ...,\n",
      "        [-2.2771, -2.3203, -2.2944,  ..., -2.2805, -2.3256, -2.3262],\n",
      "        [-2.2959, -2.3131, -2.2967,  ..., -2.2974, -2.2998, -2.3162],\n",
      "        [-1.9788, -2.3751, -2.1989,  ..., -2.2804, -2.3858, -2.3182]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([9, 9, 3, 0, 8, 6, 6, 0, 8, 9, 9, 1, 0, 3, 3, 4, 1, 4, 4, 8, 8, 9, 5, 8,\n",
      "        3, 1, 1, 0, 1, 0, 7, 0, 4, 7, 5, 3, 9, 8, 4, 6, 2, 6, 2, 4, 2, 6, 6, 6,\n",
      "        1, 1, 1, 3, 5, 1, 7, 5, 6, 7, 0, 8, 6, 9, 4, 5, 8, 3, 0, 2, 9, 6, 6, 9,\n",
      "        1, 7, 5, 5, 1, 7, 7, 3, 7, 5, 8, 0, 0, 3, 8, 9, 9, 6, 1, 3, 2, 0, 5, 2,\n",
      "        7, 8, 6, 3, 1, 4, 6, 0, 4, 4, 1, 0, 4, 2, 6, 8, 7, 9, 2, 6, 8, 8, 0, 8,\n",
      "        2, 8, 3, 3, 2, 1, 6, 9, 4, 3, 6, 7, 1, 6, 9, 9, 4, 1, 4, 5, 3, 4, 3, 4,\n",
      "        4, 1, 1, 9, 8, 3, 8, 9, 2, 6, 9, 0, 8, 8, 5, 2, 3, 6, 2, 7, 7, 2, 5, 1,\n",
      "        0, 0, 9, 3, 4, 9, 3, 1, 5, 7, 3, 9, 0, 7, 9, 5, 6, 5, 7, 8, 8, 7, 7, 2,\n",
      "        5, 8, 5, 7, 0, 5, 9, 5, 3, 9, 2, 1, 7, 3, 5, 5, 7, 3, 7, 7, 6, 7, 3, 9,\n",
      "        7, 5, 8, 3, 8, 8, 5, 6, 5, 6, 0, 6, 5, 9, 0, 4, 0, 0, 8, 8, 4, 1, 5, 3,\n",
      "        9, 5, 1, 3, 9, 7, 2, 4, 3, 7, 0, 7, 1, 3, 5, 2])\n",
      "output= tensor([[-2.2992, -2.3103, -2.2948,  ..., -2.2943, -2.3015, -2.3144],\n",
      "        [-2.2732, -2.3112, -2.2970,  ..., -2.2819, -2.3247, -2.3280],\n",
      "        [-2.6914, -2.2948, -2.2836,  ..., -2.1918, -2.2615, -2.1229],\n",
      "        ...,\n",
      "        [-2.2942, -2.3189, -2.3007,  ..., -2.2974, -2.2961, -2.3099],\n",
      "        [-2.4479, -2.3142, -2.1493,  ..., -2.2127, -2.4086, -2.1650],\n",
      "        [-2.2945, -2.3182, -2.2974,  ..., -2.2985, -2.2931, -2.3182]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([1, 2, 2, 2, 8, 5, 9, 1, 0, 4, 4, 3, 4, 8, 4, 6, 8, 9, 8, 5, 5, 2, 1, 1,\n",
      "        3, 2, 8, 6, 7, 5, 7, 6, 5, 1, 7, 6, 3, 7, 8, 4, 6, 3, 5, 5, 2, 4, 5, 7,\n",
      "        5, 8, 0, 9, 5, 5, 8, 8, 4, 4, 2, 6, 2, 6, 9, 8, 6, 4, 8, 6, 2, 4, 4, 6,\n",
      "        3, 6, 8, 0, 0, 9, 7, 5, 5, 5, 3, 1, 9, 1, 5, 1, 8, 0, 4, 3, 1, 2, 8, 5,\n",
      "        3, 0, 4, 8, 2, 3, 3, 5, 0, 8, 1, 1, 6, 2, 4, 2, 0, 6, 0, 5, 3, 9, 0, 5,\n",
      "        7, 5, 0, 1, 0, 5, 1, 2, 4, 4, 6, 0, 8, 8, 6, 8, 4, 2, 8, 3, 3, 5, 9, 3,\n",
      "        1, 4, 7, 1, 6, 3, 8, 7, 6, 3, 8, 9, 8, 1, 6, 9, 0, 5, 4, 5, 6, 6, 5, 0,\n",
      "        2, 2, 4, 2, 5, 6, 1, 9, 5, 2, 1, 8, 7, 1, 4, 3, 9, 8, 9, 1, 0, 8, 4, 7,\n",
      "        0, 3, 3, 3, 9, 4, 7, 1, 2, 2, 8, 5, 3, 9, 4, 8, 0, 1, 7, 6, 8, 7, 6, 9,\n",
      "        0, 3, 2, 0, 6, 5, 8, 2, 8, 0, 8, 9, 2, 1, 8, 2, 5, 4, 7, 8, 9, 9, 9, 5,\n",
      "        9, 0, 1, 0, 3, 2, 5, 3, 5, 1, 8, 9, 0, 8, 6, 4])\n",
      "output= tensor([[-2.2909, -2.3209, -2.2984,  ..., -2.3009, -2.2887, -2.3207],\n",
      "        [-2.2681, -2.3224, -2.2994,  ..., -2.2893, -2.3135, -2.3342],\n",
      "        [-2.6104, -2.4223, -2.3621,  ..., -2.2768, -2.2887, -2.0395],\n",
      "        ...,\n",
      "        [-2.2852, -2.3178, -2.3044,  ..., -2.3050, -2.2814, -2.3185],\n",
      "        [-2.3750, -2.3427, -2.4201,  ..., -2.4535, -2.2051, -2.1991],\n",
      "        [-2.2950, -2.3049, -2.3022,  ..., -2.3007, -2.2998, -2.3078]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([4, 5, 9, 9, 0, 3, 8, 0, 3, 1, 8, 9, 5, 6, 6, 0, 3, 2, 6, 2, 1, 7, 4, 7,\n",
      "        3, 9, 0, 8, 2, 9, 9, 2, 6, 3, 7, 1, 3, 0, 4, 1, 7, 1, 7, 7, 4, 6, 0, 9,\n",
      "        7, 8, 6, 7, 1, 3, 8, 3, 9, 7, 5, 6, 1, 5, 3, 1, 3, 1, 2, 4, 7, 7, 2, 2,\n",
      "        3, 0, 4, 6, 6, 3, 1, 1, 6, 6, 2, 7, 4, 8, 4, 4, 0, 3, 7, 9, 1, 4, 7, 6,\n",
      "        6, 3, 1, 8, 9, 2, 7, 2, 2, 5, 8, 5, 3, 1, 9, 9, 7, 1, 6, 1, 3, 9, 7, 7,\n",
      "        4, 3, 4, 5, 7, 1, 6, 2, 6, 7, 3, 1, 4, 1, 7, 7, 3, 6, 6, 5, 1, 0, 7, 1,\n",
      "        3, 7, 2, 6, 3, 3, 5, 4, 9, 6, 4, 1, 6, 4, 6, 3, 1, 6, 1, 9, 1, 7, 1, 9,\n",
      "        3, 2, 3, 7, 5, 7, 7, 8, 1, 1, 9, 8, 8, 5, 0, 8, 0, 9, 3, 8, 7, 9, 4, 8,\n",
      "        8, 6, 0, 8, 8, 6, 4, 5, 3, 3, 7, 9, 2, 3, 1, 0, 2, 1, 8, 0, 0, 2, 1, 3,\n",
      "        9, 5, 4, 8, 4, 1, 6, 6, 0, 8, 4, 5, 4, 2, 6, 0, 6, 4, 0, 7, 6, 5, 2, 5,\n",
      "        1, 1, 4, 1, 2, 8, 4, 7, 7, 4, 7, 5, 5, 7, 0, 4])\n",
      "output= tensor([[-2.2719, -2.3096, -2.2966,  ..., -2.2824, -2.3270, -2.3308],\n",
      "        [-2.6339, -2.0636, -2.2607,  ..., -2.3269, -2.3048, -2.3389],\n",
      "        [-2.2737, -2.3116, -2.2966,  ..., -2.2822, -2.3261, -2.3281],\n",
      "        ...,\n",
      "        [-2.2938, -2.3214, -2.3005,  ..., -2.3016, -2.2927, -2.3138],\n",
      "        [-2.2652, -2.3194, -2.3006,  ..., -2.2884, -2.3199, -2.3341],\n",
      "        [-2.2782, -2.4304, -2.3299,  ..., -2.2770, -2.0688, -2.3472]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([3, 5, 1, 9, 5, 7, 8, 2, 3, 4, 1, 4, 1, 9, 2, 7, 3, 9, 9, 3, 7, 3, 9, 5,\n",
      "        0, 2, 1, 1, 1, 0, 5, 7, 4, 1, 3, 2, 2, 7, 3, 9, 1, 1, 8, 0, 7, 3, 2, 7,\n",
      "        0, 8, 6, 9, 0, 2, 0, 4, 1, 9, 0, 7, 6, 0, 9, 6, 6, 4, 8, 9, 0, 2, 8, 1,\n",
      "        3, 4, 2, 6, 4, 2, 8, 3, 2, 4, 5, 9, 5, 9, 4, 6, 0, 8, 9, 0, 0, 0, 8, 2,\n",
      "        3, 1, 4, 8, 9, 2, 0, 8, 7, 9, 2, 2, 8, 6, 2, 4, 7, 0, 1, 2, 8, 7, 1, 5,\n",
      "        2, 8, 2, 1, 7, 3, 6, 9, 4, 4, 5, 1, 8, 9, 0, 0, 2, 5, 8, 9, 3, 7, 8, 0,\n",
      "        6, 6, 8, 5, 8, 7, 3, 5, 0, 1, 0, 7, 2, 6, 4, 9, 2, 3, 3, 3, 8, 9, 2, 0,\n",
      "        1, 0, 0, 7, 8, 3, 2, 8, 0, 1, 7, 1, 5, 7, 0, 9, 8, 5, 0, 1, 8, 7, 7, 6,\n",
      "        8, 5, 1, 1, 4, 3, 6, 2, 6, 0, 6, 3, 3, 8, 5, 5, 7, 0, 7, 3, 9, 5, 7, 3,\n",
      "        1, 3, 2, 2, 6, 2, 8, 5, 7, 6, 0, 7, 7, 8, 0, 6, 0, 3, 0, 0, 1, 9, 8, 1,\n",
      "        0, 7, 4, 6, 9, 1, 3, 9, 2, 9, 5, 4, 0, 3, 8, 3])\n",
      "output= tensor([[-2.2811, -2.3190, -2.3049,  ..., -2.3042, -2.2778, -2.3212],\n",
      "        [-2.2886, -2.3067, -2.3019,  ..., -2.2965, -2.2917, -2.3120],\n",
      "        [-2.2314, -2.2607, -2.2552,  ..., -2.3675, -2.4772, -2.3120],\n",
      "        ...,\n",
      "        [-2.2663, -2.3258, -2.2979,  ..., -2.2794, -2.3214, -2.3325],\n",
      "        [-2.2725, -2.3206, -2.2970,  ..., -2.2851, -2.3316, -2.3321],\n",
      "        [-2.2920, -2.3067, -2.3007,  ..., -2.3016, -2.2943, -2.3140]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([9, 2, 4, 8, 0, 6, 8, 5, 7, 9, 1, 3, 1, 4, 3, 9, 0, 6, 1, 6, 1, 1, 9, 9,\n",
      "        6, 8, 4, 2, 1, 5, 1, 9, 7, 3, 8, 3, 9, 1, 0, 4, 4, 4, 5, 1, 9, 6, 6, 1,\n",
      "        3, 6, 8, 8, 6, 3, 6, 9, 2, 3, 6, 8, 0, 0, 7, 5, 8, 2, 2, 0, 9, 7, 2, 8,\n",
      "        6, 1, 4, 2, 7, 3, 7, 1, 7, 0, 6, 9, 5, 3, 4, 5, 2, 2, 2, 9, 8, 7, 7, 7,\n",
      "        5, 1, 1, 1, 6, 0, 3, 8, 1, 6, 4, 4, 1, 2, 3, 9, 9, 9, 8, 2, 8, 2, 7, 0,\n",
      "        9, 7, 0, 3, 9, 3, 7, 9, 0, 0, 2, 9, 4, 4, 5, 2, 1, 5, 0, 0, 7, 5, 4, 1,\n",
      "        2, 4, 6, 9, 2, 9, 5, 2, 6, 7, 8, 0, 6, 3, 1, 2, 8, 1, 8, 4, 0, 3, 7, 9,\n",
      "        3, 2, 0, 7, 0, 4, 0, 7, 7, 5, 9, 8, 7, 7, 3, 4, 0, 0, 0, 1, 5, 4, 2, 3,\n",
      "        9, 7, 9, 4, 1, 6, 3, 3, 0, 1, 6, 8, 9, 4, 9, 5, 5, 2, 4, 0, 2, 9, 3, 1,\n",
      "        4, 9, 6, 0, 2, 6, 7, 5, 9, 1, 0, 7, 4, 6, 7, 7, 6, 0, 0, 0, 8, 0, 9, 1,\n",
      "        4, 3, 0, 6, 6, 1, 3, 4, 0, 2, 0, 9, 7, 3, 0, 5])\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.277835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-2.2894, -2.3172, -2.2971,  ..., -2.2900, -2.2945, -2.3066],\n",
      "        [-3.0847, -2.2045, -1.7647,  ..., -2.4108, -2.4527, -2.6415],\n",
      "        [-2.2693, -2.3101, -2.2959,  ..., -2.2823, -2.3289, -2.3304],\n",
      "        ...,\n",
      "        [-2.5634, -2.2509, -2.1890,  ..., -2.0482, -2.4229, -2.0048],\n",
      "        [-2.3145, -2.3805, -2.3577,  ..., -2.4658, -2.4569, -2.0498],\n",
      "        [-2.2619, -2.3252, -2.2989,  ..., -2.2880, -2.3138, -2.3376]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([4, 3, 3, 4, 1, 0, 8, 2, 8, 8, 4, 6, 8, 9, 3, 0, 4, 7, 7, 5, 9, 9, 6, 6,\n",
      "        3, 1, 2, 3, 1, 6, 7, 3, 7, 6, 3, 8, 1, 0, 0, 2, 7, 8, 4, 6, 7, 6, 7, 9,\n",
      "        0, 8, 1, 1, 4, 8, 2, 3, 0, 7, 9, 1, 9, 0, 7, 6, 0, 6, 9, 0, 3, 1, 3, 8,\n",
      "        4, 0, 0, 4, 7, 1, 6, 6, 6, 0, 8, 6, 1, 6, 7, 1, 4, 4, 1, 0, 9, 3, 3, 5,\n",
      "        2, 7, 6, 7, 0, 4, 6, 3, 4, 5, 3, 9, 1, 1, 0, 3, 0, 1, 4, 5, 1, 2, 7, 3,\n",
      "        5, 9, 0, 1, 1, 4, 0, 9, 0, 5, 6, 6, 9, 4, 1, 7, 9, 3, 2, 6, 6, 1, 8, 9,\n",
      "        6, 4, 0, 9, 7, 2, 0, 9, 6, 0, 9, 4, 7, 1, 0, 1, 6, 1, 2, 8, 5, 9, 4, 1,\n",
      "        6, 3, 2, 1, 0, 0, 6, 7, 5, 1, 7, 7, 7, 1, 6, 6, 5, 7, 9, 9, 8, 0, 7, 9,\n",
      "        2, 1, 4, 6, 4, 4, 8, 8, 8, 8, 1, 8, 6, 8, 6, 7, 7, 2, 4, 2, 9, 0, 0, 5,\n",
      "        7, 5, 8, 9, 3, 3, 3, 0, 4, 1, 8, 0, 9, 2, 7, 5, 7, 3, 8, 4, 9, 0, 0, 5,\n",
      "        7, 5, 7, 5, 8, 0, 0, 9, 5, 0, 6, 1, 0, 2, 6, 7])\n",
      "output= tensor([[-3.6784, -2.2854, -2.2994,  ..., -2.7129, -2.7736, -2.8195],\n",
      "        [-3.2189, -2.4293, -2.0387,  ..., -1.7282, -2.4964, -2.4561],\n",
      "        [-2.2546, -2.3274, -2.2999,  ..., -2.2791, -2.3106, -2.3347],\n",
      "        ...,\n",
      "        [-2.2826, -2.3246, -2.3021,  ..., -2.2926, -2.2870, -2.3102],\n",
      "        [-2.2732, -2.3140, -2.2938,  ..., -2.2762, -2.3321, -2.3293],\n",
      "        [-2.2757, -2.3220, -2.3045,  ..., -2.2984, -2.2767, -2.3172]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([8, 2, 1, 3, 0, 1, 4, 5, 1, 2, 9, 6, 1, 1, 7, 0, 1, 5, 5, 8, 3, 1, 2, 5,\n",
      "        9, 1, 7, 9, 4, 1, 8, 0, 6, 4, 0, 8, 3, 1, 9, 9, 1, 1, 6, 6, 8, 1, 0, 3,\n",
      "        3, 1, 4, 4, 3, 5, 6, 7, 3, 5, 8, 4, 3, 6, 6, 9, 0, 5, 8, 1, 8, 8, 7, 5,\n",
      "        3, 2, 3, 0, 2, 1, 7, 6, 4, 8, 7, 6, 4, 4, 0, 6, 3, 0, 7, 1, 1, 7, 9, 1,\n",
      "        0, 9, 3, 4, 6, 9, 9, 5, 3, 5, 0, 4, 8, 0, 2, 8, 1, 6, 8, 5, 7, 1, 7, 1,\n",
      "        4, 1, 6, 1, 2, 6, 5, 0, 9, 9, 7, 2, 8, 4, 4, 4, 3, 7, 6, 5, 1, 8, 6, 1,\n",
      "        9, 4, 3, 1, 1, 0, 2, 5, 8, 9, 7, 6, 1, 0, 5, 6, 6, 1, 6, 2, 7, 3, 0, 8,\n",
      "        7, 6, 5, 2, 3, 6, 7, 6, 5, 2, 4, 4, 5, 4, 4, 5, 5, 9, 0, 6, 3, 3, 6, 0,\n",
      "        9, 8, 7, 8, 6, 4, 6, 4, 0, 9, 2, 2, 2, 3, 2, 8, 7, 8, 5, 0, 0, 3, 2, 8,\n",
      "        0, 4, 9, 7, 5, 1, 7, 5, 9, 6, 5, 2, 6, 4, 0, 2, 9, 3, 9, 2, 7, 9, 7, 6,\n",
      "        2, 7, 3, 9, 7, 6, 3, 5, 7, 5, 5, 6, 2, 7, 1, 8])\n",
      "output= tensor([[-3.1104, -2.1867, -2.2818,  ..., -2.1902, -2.0455, -2.2989],\n",
      "        [-2.2343, -2.6164, -2.1523,  ..., -1.9708, -2.3190, -2.2424],\n",
      "        [-2.4679, -1.9901, -2.6781,  ..., -2.0853, -2.1466, -2.0288],\n",
      "        ...,\n",
      "        [-2.2710, -2.3189, -2.2920,  ..., -2.2745, -2.3289, -2.3334],\n",
      "        [-2.2855, -2.3152, -2.3006,  ..., -2.2882, -2.2900, -2.3072],\n",
      "        [-2.2871, -2.3105, -2.3011,  ..., -2.2903, -2.2997, -2.3044]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([9, 9, 8, 9, 1, 7, 6, 3, 8, 6, 5, 6, 4, 9, 4, 6, 2, 3, 9, 0, 2, 3, 9, 2,\n",
      "        5, 6, 0, 5, 6, 4, 1, 5, 9, 3, 1, 9, 7, 5, 5, 6, 3, 1, 5, 9, 1, 4, 8, 1,\n",
      "        8, 5, 9, 4, 2, 4, 1, 8, 2, 3, 1, 5, 3, 0, 5, 9, 8, 7, 7, 3, 1, 7, 3, 8,\n",
      "        6, 8, 0, 0, 3, 8, 5, 0, 0, 4, 7, 8, 4, 2, 0, 2, 7, 9, 4, 7, 2, 2, 4, 7,\n",
      "        5, 8, 0, 1, 8, 7, 9, 7, 8, 1, 9, 1, 5, 4, 8, 8, 1, 0, 5, 9, 1, 5, 4, 3,\n",
      "        1, 7, 7, 7, 0, 4, 3, 9, 2, 2, 6, 7, 6, 4, 5, 4, 6, 5, 0, 7, 7, 1, 6, 9,\n",
      "        0, 4, 6, 4, 1, 7, 7, 8, 0, 8, 3, 2, 0, 7, 8, 6, 8, 4, 0, 0, 3, 4, 3, 1,\n",
      "        7, 9, 1, 4, 9, 5, 7, 2, 2, 0, 5, 7, 4, 0, 6, 4, 6, 6, 4, 8, 0, 0, 1, 0,\n",
      "        9, 7, 4, 4, 3, 2, 4, 5, 8, 8, 3, 6, 6, 2, 2, 8, 1, 1, 3, 8, 1, 3, 8, 4,\n",
      "        9, 8, 3, 3, 1, 2, 2, 1, 4, 7, 7, 5, 6, 7, 9, 3, 2, 1, 6, 2, 0, 6, 6, 4,\n",
      "        5, 8, 2, 9, 1, 5, 7, 8, 5, 8, 1, 1, 6, 7, 9, 7])\n",
      "output= tensor([[-2.5101, -2.4774, -2.2496,  ..., -2.2977, -2.1015, -2.3098],\n",
      "        [-2.2533, -2.3237, -2.3006,  ..., -2.2763, -2.3138, -2.3364],\n",
      "        [-2.2825, -2.3197, -2.3049,  ..., -2.2929, -2.2899, -2.3090],\n",
      "        ...,\n",
      "        [-2.2885, -2.3046, -2.3023,  ..., -2.3016, -2.2886, -2.3167],\n",
      "        [-3.2313, -2.2114, -2.2104,  ..., -1.6847, -2.2734, -1.7397],\n",
      "        [-2.9761, -1.9531, -2.3275,  ..., -1.9131, -2.2521, -2.2265]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([8, 5, 1, 1, 7, 5, 3, 7, 0, 3, 1, 9, 4, 9, 2, 1, 5, 7, 0, 7, 7, 5, 6, 7,\n",
      "        9, 0, 1, 3, 2, 2, 3, 5, 7, 0, 3, 6, 8, 4, 3, 2, 7, 3, 6, 1, 1, 8, 3, 2,\n",
      "        3, 1, 6, 1, 4, 5, 0, 2, 3, 0, 2, 7, 2, 4, 0, 7, 7, 9, 1, 0, 3, 1, 5, 9,\n",
      "        3, 0, 7, 9, 4, 1, 3, 5, 1, 5, 6, 1, 8, 2, 2, 4, 2, 6, 9, 6, 7, 8, 5, 6,\n",
      "        6, 4, 6, 4, 5, 2, 2, 2, 8, 8, 1, 7, 6, 7, 4, 8, 2, 5, 5, 2, 7, 7, 8, 4,\n",
      "        0, 5, 0, 5, 9, 1, 5, 3, 2, 3, 9, 9, 7, 8, 5, 9, 9, 8, 5, 3, 0, 5, 6, 9,\n",
      "        8, 3, 4, 8, 6, 1, 3, 4, 6, 0, 5, 8, 2, 4, 8, 6, 5, 4, 0, 4, 8, 8, 7, 5,\n",
      "        4, 5, 2, 3, 6, 2, 6, 8, 7, 2, 9, 4, 7, 6, 9, 6, 2, 9, 8, 8, 9, 4, 2, 0,\n",
      "        8, 8, 1, 7, 9, 0, 7, 9, 8, 7, 3, 5, 3, 5, 6, 9, 9, 8, 8, 2, 9, 7, 7, 3,\n",
      "        8, 7, 2, 0, 9, 9, 2, 2, 7, 8, 9, 9, 5, 9, 9, 6, 0, 4, 3, 3, 2, 5, 9, 6,\n",
      "        7, 1, 5, 3, 2, 1, 0, 2, 8, 3, 8, 2, 0, 9, 9, 4])\n",
      "output= tensor([[-2.2577, -2.3198, -2.3039,  ..., -2.2764, -2.3251, -2.3284],\n",
      "        [-2.3867, -2.3141, -2.3912,  ..., -2.1850, -2.2461, -2.2210],\n",
      "        [-2.4214, -2.2814, -2.2983,  ..., -2.5190, -2.0722, -2.3015],\n",
      "        ...,\n",
      "        [-2.5914, -2.7971, -2.2872,  ..., -1.8970, -1.9654, -1.8079],\n",
      "        [-2.2643, -2.3143, -2.3023,  ..., -2.2876, -2.3278, -2.3321],\n",
      "        [-2.3409, -2.3063, -2.1740,  ..., -2.2452, -2.4296, -2.3398]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 3, 8, 4, 3, 7, 7, 9, 8, 2, 5, 1, 2, 1, 1, 8, 1, 4, 4, 2, 3, 0, 4, 1,\n",
      "        8, 9, 6, 3, 5, 7, 6, 9, 6, 4, 4, 0, 8, 2, 7, 1, 4, 3, 2, 3, 9, 8, 8, 3,\n",
      "        0, 4, 6, 7, 6, 7, 7, 1, 0, 4, 6, 3, 3, 5, 0, 9, 8, 5, 9, 1, 7, 8, 8, 1,\n",
      "        4, 7, 4, 1, 5, 0, 4, 1, 4, 0, 2, 6, 6, 8, 1, 5, 8, 9, 1, 3, 8, 9, 8, 3,\n",
      "        5, 5, 2, 8, 8, 0, 8, 6, 0, 9, 3, 8, 0, 9, 1, 1, 6, 0, 4, 3, 7, 9, 0, 2,\n",
      "        0, 0, 7, 3, 1, 0, 4, 0, 8, 7, 5, 2, 6, 3, 2, 0, 8, 6, 0, 3, 3, 7, 9, 6,\n",
      "        5, 4, 7, 9, 6, 5, 9, 8, 5, 5, 1, 6, 5, 6, 7, 2, 1, 8, 0, 7, 1, 8, 9, 0,\n",
      "        8, 0, 0, 6, 4, 7, 9, 2, 1, 4, 7, 4, 7, 4, 5, 7, 1, 8, 7, 1, 8, 7, 8, 5,\n",
      "        6, 8, 4, 8, 0, 8, 3, 4, 6, 3, 0, 2, 2, 1, 4, 8, 7, 0, 5, 9, 1, 6, 2, 7,\n",
      "        5, 9, 3, 6, 3, 8, 0, 8, 5, 2, 1, 4, 8, 9, 4, 1, 5, 7, 5, 7, 7, 7, 4, 0,\n",
      "        3, 6, 3, 9, 4, 6, 0, 2, 4, 5, 0, 4, 6, 9, 1, 4])\n",
      "output= tensor([[-2.2885, -2.3050, -2.3087,  ..., -2.3078, -2.2938, -2.3130],\n",
      "        [-2.2827, -2.3188, -2.3011,  ..., -2.2863, -2.2779, -2.3100],\n",
      "        [-2.2875, -2.3175, -2.3030,  ..., -2.2848, -2.2910, -2.3015],\n",
      "        ...,\n",
      "        [-2.2665, -2.3256, -2.2942,  ..., -2.2779, -2.3196, -2.3439],\n",
      "        [-2.2970, -2.3042, -2.3016,  ..., -2.2985, -2.3031, -2.3077],\n",
      "        [-2.2794, -2.3113, -2.3052,  ..., -2.2908, -2.2775, -2.3110]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([6, 4, 4, 5, 8, 9, 1, 1, 4, 1, 9, 3, 3, 2, 4, 1, 7, 5, 2, 1, 7, 8, 8, 9,\n",
      "        9, 5, 6, 6, 8, 3, 2, 2, 6, 3, 0, 0, 4, 7, 4, 2, 4, 0, 0, 5, 9, 1, 2, 2,\n",
      "        0, 3, 0, 5, 3, 1, 1, 4, 3, 6, 8, 2, 5, 3, 0, 1, 6, 7, 8, 1, 2, 1, 9, 1,\n",
      "        2, 8, 6, 7, 4, 6, 7, 7, 6, 4, 7, 5, 2, 6, 2, 2, 2, 1, 0, 7, 9, 5, 9, 3,\n",
      "        6, 9, 6, 2, 5, 1, 3, 0, 8, 8, 0, 2, 6, 9, 6, 6, 6, 9, 4, 6, 7, 0, 9, 8,\n",
      "        6, 3, 2, 5, 9, 4, 6, 2, 5, 6, 0, 4, 7, 8, 7, 0, 9, 4, 6, 6, 5, 5, 5, 5,\n",
      "        4, 9, 1, 6, 6, 0, 8, 2, 7, 5, 3, 1, 4, 7, 5, 7, 9, 6, 0, 8, 2, 9, 7, 0,\n",
      "        0, 0, 6, 1, 7, 3, 8, 0, 5, 4, 2, 1, 7, 6, 8, 0, 0, 4, 3, 7, 6, 8, 4, 1,\n",
      "        9, 3, 3, 5, 9, 9, 1, 5, 9, 5, 9, 1, 2, 2, 3, 6, 5, 1, 5, 8, 8, 4, 1, 7,\n",
      "        1, 9, 8, 0, 7, 4, 4, 2, 2, 9, 2, 6, 3, 4, 1, 3, 6, 7, 9, 8, 0, 3, 6, 6,\n",
      "        2, 3, 6, 9, 7, 5, 0, 6, 7, 0, 3, 4, 1, 3, 8, 1])\n",
      "output= tensor([[-2.0243, -2.2849, -2.2049,  ..., -2.1312, -2.4228, -2.3742],\n",
      "        [-2.2815, -2.3135, -2.3072,  ..., -2.2936, -2.2911, -2.3061],\n",
      "        [-2.2825, -2.3063, -2.3054,  ..., -2.2906, -2.2938, -2.3064],\n",
      "        ...,\n",
      "        [-2.2663, -2.3158, -2.2924,  ..., -2.2760, -2.3251, -2.3407],\n",
      "        [-2.2499, -2.3232, -2.3009,  ..., -2.2742, -2.3088, -2.3388],\n",
      "        [-2.2589, -2.3129, -2.3001,  ..., -2.2696, -2.3324, -2.3261]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([4, 1, 5, 4, 9, 8, 7, 1, 6, 1, 5, 7, 8, 5, 1, 9, 9, 0, 7, 1, 1, 1, 1, 3,\n",
      "        2, 7, 2, 8, 0, 1, 2, 9, 9, 2, 5, 7, 5, 4, 0, 0, 8, 7, 0, 9, 7, 0, 8, 9,\n",
      "        7, 2, 4, 6, 3, 5, 5, 8, 3, 7, 3, 8, 2, 8, 3, 9, 8, 5, 0, 3, 9, 6, 2, 0,\n",
      "        7, 6, 8, 2, 7, 6, 7, 0, 3, 4, 3, 8, 1, 7, 6, 6, 1, 0, 7, 4, 7, 6, 5, 8,\n",
      "        4, 8, 9, 3, 7, 0, 4, 3, 0, 7, 4, 5, 4, 3, 7, 9, 7, 0, 1, 1, 6, 3, 0, 7,\n",
      "        2, 6, 5, 4, 0, 4, 4, 9, 5, 0, 9, 7, 1, 9, 9, 2, 0, 6, 5, 0, 6, 6, 2, 2,\n",
      "        5, 3, 1, 7, 9, 6, 6, 2, 7, 3, 1, 4, 9, 6, 9, 6, 2, 5, 5, 3, 5, 4, 7, 6,\n",
      "        7, 4, 1, 5, 7, 6, 0, 9, 3, 4, 2, 8, 0, 7, 1, 1, 1, 9, 5, 9, 3, 7, 9, 9,\n",
      "        4, 4, 0, 1, 6, 7, 0, 5, 1, 8, 3, 3, 2, 7, 5, 4, 4, 7, 1, 8, 7, 3, 3, 4,\n",
      "        0, 9, 9, 7, 3, 3, 1, 8, 3, 3, 4, 2, 7, 2, 5, 5, 4, 4, 1, 5, 0, 2, 3, 9,\n",
      "        3, 8, 0, 4, 8, 6, 7, 5, 1, 3, 8, 7, 5, 9, 7, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-3.1781, -2.6561, -2.2579,  ..., -2.2419, -1.6003, -1.7121],\n",
      "        [-2.2579, -2.3146, -2.2982,  ..., -2.2675, -2.3328, -2.3286],\n",
      "        [-2.2624, -2.3110, -2.3016,  ..., -2.2838, -2.3351, -2.3347],\n",
      "        ...,\n",
      "        [-2.2846, -2.3060, -2.3041,  ..., -2.3044, -2.2834, -2.3249],\n",
      "        [-2.2571, -2.3232, -2.2928,  ..., -2.2632, -2.3225, -2.3389],\n",
      "        [-2.2308, -2.4160, -2.4695,  ..., -2.2912, -2.3039, -2.2308]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([8, 5, 3, 9, 7, 7, 1, 9, 9, 3, 6, 1, 1, 3, 3, 1, 1, 6, 1, 2, 8, 6, 6, 4,\n",
      "        5, 8, 5, 3, 5, 0, 6, 0, 6, 0, 3, 3, 2, 9, 9, 7, 5, 8, 2, 3, 1, 7, 1, 2,\n",
      "        5, 9, 6, 5, 9, 9, 7, 3, 8, 5, 8, 6, 8, 0, 9, 2, 0, 0, 5, 0, 1, 6, 7, 8,\n",
      "        2, 6, 8, 7, 9, 5, 0, 9, 5, 2, 0, 9, 0, 5, 3, 3, 1, 5, 9, 5, 9, 4, 2, 2,\n",
      "        2, 5, 0, 4, 2, 9, 3, 0, 9, 5, 6, 6, 9, 2, 7, 6, 1, 0, 3, 6, 2, 7, 1, 0,\n",
      "        2, 7, 4, 8, 3, 2, 3, 0, 6, 2, 0, 3, 2, 9, 6, 4, 8, 5, 4, 9, 3, 9, 1, 4,\n",
      "        9, 6, 3, 1, 9, 8, 8, 4, 5, 1, 4, 7, 1, 7, 8, 6, 1, 5, 6, 7, 7, 1, 3, 1,\n",
      "        9, 9, 8, 2, 8, 7, 6, 4, 1, 4, 6, 9, 4, 6, 9, 3, 2, 3, 1, 5, 0, 3, 5, 2,\n",
      "        2, 3, 4, 3, 2, 9, 8, 4, 5, 6, 0, 2, 2, 9, 7, 5, 7, 0, 8, 0, 2, 7, 0, 8,\n",
      "        8, 1, 7, 7, 2, 8, 4, 1, 9, 7, 9, 2, 6, 5, 8, 1, 1, 8, 8, 5, 4, 4, 6, 2,\n",
      "        1, 9, 1, 8, 7, 6, 6, 0, 1, 0, 5, 8, 4, 1, 3, 9])\n",
      "output= tensor([[-2.2672, -2.3110, -2.2932,  ..., -2.2718, -2.3350, -2.3394],\n",
      "        [-2.3675, -2.3111, -2.3312,  ..., -2.2500, -2.4241, -2.1999],\n",
      "        [-2.2648, -2.3145, -2.2947,  ..., -2.2772, -2.3320, -2.3426],\n",
      "        ...,\n",
      "        [-2.2930, -2.3091, -2.3019,  ..., -2.2982, -2.2991, -2.3144],\n",
      "        [-2.2647, -2.3113, -2.2935,  ..., -2.2743, -2.3344, -2.3419],\n",
      "        [-2.2879, -2.2831, -2.3023,  ..., -2.2307, -2.3298, -2.2882]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([5, 7, 6, 1, 4, 8, 2, 4, 9, 7, 8, 8, 5, 2, 9, 3, 1, 1, 2, 2, 0, 9, 0, 9,\n",
      "        5, 8, 8, 4, 6, 3, 9, 3, 4, 3, 1, 3, 2, 2, 0, 2, 1, 4, 8, 4, 6, 1, 8, 4,\n",
      "        1, 2, 7, 9, 1, 4, 0, 8, 9, 4, 5, 0, 3, 4, 4, 8, 8, 9, 0, 0, 2, 2, 1, 8,\n",
      "        2, 1, 1, 4, 5, 6, 5, 0, 2, 8, 0, 0, 8, 7, 5, 3, 0, 1, 3, 4, 8, 1, 1, 8,\n",
      "        0, 5, 4, 7, 2, 9, 4, 7, 0, 3, 3, 1, 7, 4, 9, 2, 7, 2, 4, 0, 1, 9, 7, 6,\n",
      "        3, 9, 0, 5, 7, 5, 7, 5, 0, 3, 1, 3, 5, 5, 5, 7, 9, 7, 6, 6, 7, 1, 7, 7,\n",
      "        9, 9, 1, 9, 2, 1, 0, 4, 5, 3, 9, 7, 4, 3, 1, 0, 0, 8, 5, 2, 8, 4, 4, 3,\n",
      "        2, 5, 2, 1, 9, 6, 0, 6, 3, 5, 8, 9, 7, 4, 9, 0, 7, 4, 4, 3, 4, 4, 7, 1,\n",
      "        7, 8, 3, 7, 9, 1, 4, 4, 0, 3, 5, 6, 8, 6, 7, 9, 7, 0, 3, 0, 8, 6, 0, 3,\n",
      "        3, 6, 3, 8, 5, 0, 4, 9, 2, 8, 9, 4, 9, 5, 7, 4, 2, 6, 4, 8, 8, 9, 5, 5,\n",
      "        8, 1, 1, 8, 8, 2, 8, 0, 9, 1, 1, 9, 0, 1, 6, 0])\n",
      "output= tensor([[-2.2623, -2.3145, -2.2991,  ..., -2.2636, -2.3445, -2.3278],\n",
      "        [-2.2889, -2.3004, -2.3038,  ..., -2.2996, -2.2894, -2.3191],\n",
      "        [-2.2841, -2.3112, -2.3020,  ..., -2.2921, -2.2814, -2.3179],\n",
      "        ...,\n",
      "        [-2.6593, -2.3905, -2.2256,  ..., -1.6298, -2.8185, -2.1398],\n",
      "        [-2.2917, -2.3008, -2.3049,  ..., -2.3011, -2.3011, -2.3139],\n",
      "        [-2.2980, -2.3051, -2.3002,  ..., -2.2960, -2.3035, -2.3108]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 1, 4, 4, 1, 8, 5, 6, 5, 9, 5, 9, 9, 3, 8, 1, 6, 9, 9, 1, 5, 1, 6, 3,\n",
      "        9, 4, 9, 3, 6, 7, 0, 6, 6, 2, 5, 9, 8, 1, 3, 4, 2, 9, 7, 4, 3, 8, 8, 5,\n",
      "        2, 8, 0, 0, 5, 0, 4, 5, 3, 4, 4, 0, 6, 8, 5, 4, 9, 8, 4, 4, 2, 3, 5, 1,\n",
      "        3, 5, 1, 4, 8, 9, 3, 5, 4, 9, 4, 0, 1, 5, 8, 4, 4, 4, 4, 5, 1, 0, 9, 5,\n",
      "        0, 5, 8, 7, 6, 6, 9, 4, 6, 7, 3, 7, 2, 0, 0, 1, 3, 0, 1, 2, 2, 7, 5, 9,\n",
      "        1, 8, 9, 5, 4, 9, 1, 0, 1, 4, 6, 2, 1, 3, 0, 0, 0, 3, 5, 6, 6, 5, 7, 8,\n",
      "        4, 9, 1, 0, 9, 7, 3, 7, 4, 4, 9, 4, 0, 4, 1, 8, 5, 4, 7, 4, 1, 7, 0, 3,\n",
      "        5, 8, 4, 4, 4, 3, 1, 5, 9, 2, 3, 1, 0, 8, 3, 9, 0, 9, 5, 4, 3, 4, 9, 6,\n",
      "        4, 7, 6, 4, 5, 0, 9, 1, 0, 2, 3, 8, 7, 1, 3, 7, 7, 7, 1, 8, 4, 8, 8, 3,\n",
      "        0, 0, 8, 4, 8, 2, 3, 8, 4, 7, 1, 4, 7, 9, 0, 1, 3, 8, 3, 7, 4, 3, 2, 4,\n",
      "        6, 2, 5, 4, 9, 8, 3, 1, 5, 7, 3, 7, 5, 8, 3, 1])\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.294753\n",
      "output= tensor([[-2.2597, -2.3136, -2.2936,  ..., -2.2732, -2.3408, -2.3433],\n",
      "        [-2.2905, -2.2997, -2.3079,  ..., -2.3043, -2.2998, -2.3121],\n",
      "        [-2.7395, -2.7789, -2.2657,  ..., -2.3194, -2.4673, -1.7921],\n",
      "        ...,\n",
      "        [-2.2611, -2.3111, -2.2935,  ..., -2.2719, -2.3424, -2.3428],\n",
      "        [-2.2944, -2.3216, -2.3104,  ..., -2.2386, -2.3063, -2.2924],\n",
      "        [-2.2633, -2.3111, -2.2988,  ..., -2.2708, -2.3402, -2.3423]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 6, 8, 6, 6, 0, 9, 3, 9, 3, 7, 7, 8, 2, 9, 7, 7, 3, 8, 3, 0, 7, 0, 0,\n",
      "        3, 8, 0, 3, 8, 1, 6, 1, 3, 0, 2, 2, 8, 8, 8, 1, 1, 7, 1, 0, 8, 6, 6, 7,\n",
      "        8, 9, 2, 1, 8, 8, 4, 4, 4, 7, 4, 8, 1, 9, 9, 8, 3, 3, 6, 1, 5, 7, 0, 2,\n",
      "        9, 0, 8, 3, 9, 6, 9, 7, 9, 5, 2, 4, 4, 4, 9, 9, 9, 1, 1, 2, 1, 9, 6, 6,\n",
      "        8, 5, 2, 3, 4, 6, 2, 4, 6, 2, 4, 3, 1, 2, 3, 6, 4, 3, 9, 7, 5, 4, 6, 0,\n",
      "        9, 4, 5, 7, 9, 6, 1, 2, 1, 2, 1, 7, 6, 1, 1, 2, 9, 6, 2, 9, 2, 1, 1, 9,\n",
      "        5, 1, 5, 1, 5, 1, 3, 2, 3, 4, 6, 4, 1, 2, 7, 8, 6, 2, 7, 4, 2, 7, 5, 4,\n",
      "        1, 0, 6, 4, 8, 1, 1, 1, 1, 0, 0, 0, 8, 5, 2, 6, 8, 1, 8, 1, 9, 3, 8, 4,\n",
      "        6, 4, 2, 0, 8, 4, 8, 2, 3, 7, 0, 1, 7, 4, 5, 7, 4, 5, 7, 7, 4, 3, 2, 9,\n",
      "        4, 7, 1, 2, 5, 9, 4, 7, 0, 0, 7, 8, 4, 5, 7, 3, 5, 7, 9, 1, 1, 6, 6, 4,\n",
      "        8, 2, 4, 9, 7, 8, 1, 6, 9, 8, 1, 4, 4, 0, 5, 0])\n",
      "output= tensor([[-2.4664, -2.1088, -2.0979,  ..., -2.1735, -2.5492, -2.1284],\n",
      "        [-2.2570, -2.3725, -2.2808,  ..., -2.2585, -2.3282, -2.3354],\n",
      "        [-2.6005, -2.3641, -2.1582,  ..., -2.1248, -2.0194, -2.2953],\n",
      "        ...,\n",
      "        [-2.2850, -2.3039, -2.3049,  ..., -2.2937, -2.2968, -2.3082],\n",
      "        [-2.7054, -1.9385, -2.1070,  ..., -2.2524, -2.4471, -2.2297],\n",
      "        [-2.3438, -2.3380, -2.3383,  ..., -2.2942, -2.2457, -2.2124]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 8, 3, 2, 7, 1, 9, 8, 1, 3, 2, 6, 0, 8, 1, 7, 9, 9, 1, 7, 0, 6, 6, 8,\n",
      "        6, 7, 7, 9, 7, 1, 6, 4, 8, 2, 3, 5, 5, 5, 0, 7, 2, 1, 6, 5, 0, 2, 7, 0,\n",
      "        2, 4, 3, 0, 8, 1, 4, 9, 9, 2, 0, 0, 6, 1, 1, 4, 6, 6, 6, 9, 8, 6, 4, 1,\n",
      "        8, 7, 0, 3, 5, 5, 3, 1, 1, 9, 4, 1, 6, 7, 3, 3, 6, 1, 8, 9, 7, 1, 1, 3,\n",
      "        0, 8, 1, 5, 6, 6, 4, 7, 3, 6, 9, 1, 3, 9, 1, 7, 4, 0, 0, 5, 4, 6, 9, 6,\n",
      "        7, 1, 2, 0, 9, 6, 6, 4, 8, 1, 3, 1, 6, 6, 6, 2, 3, 3, 7, 1, 3, 2, 7, 1,\n",
      "        1, 9, 5, 4, 9, 3, 5, 2, 5, 0, 9, 2, 3, 2, 7, 7, 3, 6, 9, 5, 5, 4, 1, 6,\n",
      "        6, 9, 8, 1, 7, 4, 0, 3, 0, 1, 9, 3, 4, 0, 0, 3, 5, 0, 8, 2, 9, 3, 5, 4,\n",
      "        4, 1, 4, 4, 7, 5, 9, 6, 2, 9, 8, 4, 1, 0, 2, 6, 4, 6, 2, 3, 6, 1, 9, 3,\n",
      "        9, 9, 1, 8, 3, 7, 6, 9, 6, 9, 2, 0, 3, 6, 1, 1, 2, 3, 2, 2, 3, 2, 0, 7,\n",
      "        6, 3, 3, 2, 9, 0, 5, 9, 4, 7, 8, 4, 1, 6, 8, 2])\n",
      "output= tensor([[-2.3207, -2.3715, -2.3300,  ..., -2.3376, -2.2323, -2.1617],\n",
      "        [-2.4106, -2.2304, -2.1920,  ..., -2.3989, -2.3509, -2.3521],\n",
      "        [-2.4738, -2.3165, -2.2817,  ..., -2.3572, -2.4519, -2.1238],\n",
      "        ...,\n",
      "        [-2.2884, -2.3020, -2.3089,  ..., -2.2946, -2.2982, -2.3092],\n",
      "        [-2.4984, -2.4280, -2.0934,  ..., -2.3526, -2.3139, -2.1842],\n",
      "        [-2.2821, -2.3887, -2.2649,  ..., -2.1437, -2.5438, -2.2710]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([4, 4, 3, 8, 6, 2, 2, 5, 6, 7, 9, 8, 4, 1, 5, 2, 1, 7, 2, 7, 8, 2, 1, 9,\n",
      "        0, 4, 7, 4, 0, 1, 4, 2, 8, 2, 7, 1, 6, 2, 8, 2, 2, 2, 2, 8, 0, 2, 7, 0,\n",
      "        0, 2, 2, 2, 9, 0, 5, 6, 8, 3, 0, 3, 4, 9, 6, 1, 8, 4, 8, 3, 3, 5, 7, 9,\n",
      "        8, 3, 2, 4, 6, 5, 7, 8, 3, 5, 2, 5, 0, 8, 6, 2, 0, 3, 7, 5, 5, 0, 2, 1,\n",
      "        4, 1, 9, 0, 8, 8, 4, 3, 7, 1, 1, 8, 2, 6, 5, 3, 1, 7, 3, 4, 7, 9, 3, 6,\n",
      "        3, 4, 7, 1, 1, 8, 0, 0, 9, 3, 5, 0, 0, 7, 6, 6, 0, 9, 2, 5, 4, 9, 6, 9,\n",
      "        4, 3, 7, 9, 3, 7, 4, 5, 9, 7, 5, 6, 4, 2, 5, 9, 5, 1, 9, 6, 5, 1, 4, 8,\n",
      "        9, 2, 3, 6, 1, 2, 4, 8, 9, 3, 1, 6, 9, 5, 2, 2, 2, 8, 7, 9, 2, 2, 6, 4,\n",
      "        1, 8, 7, 3, 9, 1, 6, 6, 6, 1, 3, 7, 5, 3, 6, 7, 7, 5, 3, 5, 3, 7, 6, 8,\n",
      "        1, 1, 1, 3, 6, 9, 1, 2, 1, 2, 7, 7, 4, 6, 8, 3, 3, 9, 1, 1, 9, 3, 0, 9,\n",
      "        7, 7, 3, 5, 4, 2, 6, 7, 8, 2, 3, 4, 2, 0, 6, 9])\n",
      "output= tensor([[-2.2593, -2.3096, -2.2995,  ..., -2.2674, -2.3518, -2.3310],\n",
      "        [-2.2824, -2.4747, -2.2258,  ..., -2.0770, -2.3180, -2.1186],\n",
      "        [-2.4817, -1.9747, -2.4680,  ..., -1.6562, -2.3626, -2.5942],\n",
      "        ...,\n",
      "        [-3.5974, -2.0986, -2.3962,  ..., -2.2767, -2.9718, -1.9068],\n",
      "        [-2.6527, -2.5845, -2.2694,  ..., -2.2200, -2.4375, -1.6014],\n",
      "        [-2.3621, -2.3051, -2.3190,  ..., -2.3179, -2.3356, -2.2599]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([3, 3, 0, 2, 8, 1, 5, 5, 9, 8, 7, 1, 0, 6, 2, 4, 4, 3, 5, 2, 4, 0, 9, 1,\n",
      "        2, 6, 9, 6, 8, 2, 9, 0, 6, 4, 5, 8, 7, 0, 3, 3, 7, 0, 4, 0, 4, 5, 4, 4,\n",
      "        0, 0, 9, 7, 1, 1, 0, 1, 8, 8, 7, 2, 2, 5, 0, 8, 0, 1, 1, 9, 7, 1, 6, 4,\n",
      "        9, 6, 8, 2, 6, 3, 7, 7, 5, 3, 0, 6, 6, 9, 5, 0, 6, 7, 8, 5, 1, 9, 7, 6,\n",
      "        1, 4, 4, 7, 9, 8, 6, 1, 5, 5, 0, 4, 7, 7, 7, 4, 6, 4, 0, 0, 1, 1, 6, 1,\n",
      "        3, 3, 6, 2, 9, 7, 6, 1, 3, 1, 9, 6, 7, 9, 7, 3, 5, 7, 9, 7, 0, 1, 3, 5,\n",
      "        6, 5, 8, 5, 9, 6, 3, 0, 4, 9, 9, 2, 2, 8, 8, 1, 1, 6, 2, 0, 7, 0, 3, 8,\n",
      "        1, 2, 5, 8, 1, 7, 5, 7, 6, 3, 7, 4, 9, 7, 6, 4, 0, 2, 8, 5, 2, 5, 6, 8,\n",
      "        8, 9, 1, 4, 5, 5, 8, 3, 3, 7, 7, 3, 4, 9, 6, 1, 3, 8, 8, 7, 3, 1, 7, 3,\n",
      "        4, 6, 8, 2, 1, 1, 5, 4, 9, 4, 7, 9, 3, 2, 4, 2, 7, 3, 5, 2, 2, 1, 2, 7,\n",
      "        2, 0, 6, 2, 5, 5, 0, 8, 6, 0, 5, 6, 0, 3, 3, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-2.5539, -2.2188, -2.1757,  ..., -2.1950, -2.3577, -2.2584],\n",
      "        [-2.2619, -2.3075, -2.3003,  ..., -2.2679, -2.3495, -2.3423],\n",
      "        [-2.2547, -2.3047, -2.2983,  ..., -2.2746, -2.3468, -2.3422],\n",
      "        ...,\n",
      "        [-2.2831, -2.3231, -2.2969,  ..., -2.2712, -2.3482, -2.3150],\n",
      "        [-2.6388, -2.3624, -2.2846,  ..., -2.2004, -2.1100, -2.1406],\n",
      "        [-2.2915, -2.2935, -2.3082,  ..., -2.3041, -2.3023, -2.3109]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 7, 9, 0, 1, 8, 9, 0, 9, 8, 1, 3, 1, 4, 3, 5, 8, 8, 3, 7, 8, 1, 3, 2,\n",
      "        0, 1, 5, 9, 1, 1, 6, 0, 8, 7, 8, 7, 4, 4, 4, 9, 1, 7, 6, 8, 9, 3, 4, 2,\n",
      "        2, 2, 8, 0, 4, 1, 4, 9, 1, 6, 6, 1, 7, 7, 9, 7, 0, 2, 7, 4, 3, 7, 1, 5,\n",
      "        8, 1, 5, 2, 1, 5, 8, 5, 9, 1, 6, 4, 8, 4, 5, 0, 2, 6, 3, 1, 7, 1, 5, 4,\n",
      "        3, 5, 0, 8, 5, 8, 3, 5, 0, 4, 7, 1, 5, 7, 0, 0, 1, 9, 2, 6, 2, 6, 5, 0,\n",
      "        4, 2, 1, 6, 1, 3, 0, 6, 7, 5, 4, 6, 7, 2, 0, 5, 7, 2, 0, 1, 0, 7, 8, 1,\n",
      "        7, 8, 3, 2, 3, 4, 0, 3, 3, 5, 0, 6, 9, 4, 4, 5, 7, 7, 0, 2, 9, 0, 4, 2,\n",
      "        4, 8, 9, 4, 9, 7, 8, 2, 2, 5, 4, 2, 7, 0, 7, 7, 8, 8, 2, 2, 8, 3, 0, 6,\n",
      "        5, 5, 6, 1, 2, 0, 0, 2, 2, 9, 7, 1, 4, 6, 1, 4, 6, 7, 6, 5, 8, 9, 7, 5,\n",
      "        8, 9, 8, 9, 6, 7, 8, 3, 1, 6, 8, 7, 2, 6, 6, 3, 1, 6, 2, 1, 6, 3, 8, 0,\n",
      "        3, 6, 1, 7, 4, 5, 3, 5, 4, 1, 7, 9, 2, 6, 3, 6])\n",
      "output= tensor([[-2.2924, -2.2952, -2.3107,  ..., -2.2999, -2.2998, -2.3057],\n",
      "        [-2.1424, -2.6137, -2.1009,  ..., -2.5202, -2.1507, -2.2298],\n",
      "        [-3.2909, -2.5767, -2.0028,  ..., -1.4625, -2.7319, -1.6498],\n",
      "        ...,\n",
      "        [-2.2703, -2.3312, -2.3013,  ..., -2.2075, -2.4095, -2.2886],\n",
      "        [-3.8825, -2.6406, -1.6707,  ..., -2.4762, -3.3211, -3.3037],\n",
      "        [-2.2514, -2.3140, -2.2945,  ..., -2.2614, -2.3481, -2.3394]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([9, 9, 2, 6, 0, 0, 3, 1, 2, 1, 6, 6, 3, 7, 9, 1, 8, 1, 3, 8, 5, 8, 3, 6,\n",
      "        1, 1, 7, 1, 3, 6, 6, 8, 3, 1, 5, 2, 9, 0, 1, 6, 0, 6, 3, 5, 5, 9, 5, 2,\n",
      "        4, 7, 0, 4, 8, 6, 4, 3, 5, 8, 9, 7, 4, 1, 1, 3, 2, 5, 5, 1, 6, 3, 1, 4,\n",
      "        0, 9, 3, 0, 4, 4, 0, 4, 1, 2, 9, 2, 9, 5, 6, 0, 3, 9, 6, 0, 4, 2, 5, 2,\n",
      "        5, 2, 1, 6, 2, 3, 8, 5, 3, 4, 2, 6, 1, 2, 5, 6, 4, 0, 4, 8, 4, 5, 7, 5,\n",
      "        2, 3, 9, 8, 4, 4, 7, 0, 6, 6, 2, 4, 8, 9, 0, 9, 1, 8, 1, 3, 0, 6, 5, 8,\n",
      "        9, 6, 1, 9, 9, 2, 9, 4, 1, 1, 6, 8, 0, 9, 9, 2, 1, 9, 9, 0, 4, 9, 8, 1,\n",
      "        7, 0, 3, 1, 9, 7, 1, 7, 5, 7, 3, 7, 6, 9, 1, 4, 8, 6, 1, 9, 7, 1, 1, 3,\n",
      "        3, 1, 6, 3, 2, 8, 2, 0, 1, 6, 7, 3, 7, 1, 0, 6, 4, 3, 6, 6, 2, 7, 6, 6,\n",
      "        1, 5, 0, 9, 0, 7, 0, 9, 2, 6, 9, 1, 4, 3, 2, 5, 0, 7, 4, 2, 5, 3, 7, 1,\n",
      "        7, 5, 1, 3, 4, 0, 3, 6, 3, 4, 3, 7, 9, 9, 0, 1])\n",
      "output= tensor([[-2.2823, -2.2993, -2.3088,  ..., -2.2974, -2.2947, -2.3060],\n",
      "        [-2.2882, -2.2957, -2.3052,  ..., -2.3030, -2.2941, -2.3162],\n",
      "        [-2.3314, -1.9199, -1.8521,  ..., -2.2296, -1.8853, -3.1429],\n",
      "        ...,\n",
      "        [-2.2898, -2.3028, -2.3089,  ..., -2.2893, -2.3007, -2.3003],\n",
      "        [-2.2940, -2.3057, -2.2985,  ..., -2.2951, -2.2977, -2.3190],\n",
      "        [-2.4122, -2.0448, -2.6462,  ..., -2.4555, -2.3996, -2.1450]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 1, 9, 5, 8, 6, 8, 7, 4, 2, 5, 5, 1, 5, 6, 4, 9, 8, 7, 3, 7, 2, 7, 7,\n",
      "        1, 1, 2, 4, 4, 8, 3, 0, 9, 1, 8, 3, 2, 8, 5, 6, 5, 0, 0, 5, 5, 7, 6, 1,\n",
      "        9, 4, 2, 0, 9, 6, 9, 7, 8, 4, 6, 4, 1, 8, 7, 1, 9, 6, 8, 1, 5, 4, 5, 1,\n",
      "        4, 1, 7, 1, 5, 1, 4, 2, 0, 3, 9, 5, 8, 8, 7, 2, 5, 3, 7, 1, 8, 1, 3, 2,\n",
      "        0, 3, 1, 4, 6, 8, 9, 6, 2, 9, 0, 8, 5, 8, 6, 9, 0, 9, 3, 8, 7, 1, 1, 7,\n",
      "        2, 2, 1, 1, 2, 6, 5, 8, 0, 3, 5, 4, 6, 9, 5, 3, 6, 1, 5, 9, 6, 1, 9, 6,\n",
      "        3, 2, 1, 4, 5, 7, 7, 6, 7, 6, 6, 9, 6, 7, 6, 9, 4, 1, 1, 5, 1, 0, 2, 4,\n",
      "        7, 9, 0, 3, 2, 2, 0, 4, 8, 8, 2, 4, 3, 9, 8, 0, 2, 2, 3, 6, 3, 8, 1, 2,\n",
      "        5, 2, 5, 4, 4, 8, 0, 7, 4, 6, 9, 0, 7, 0, 7, 4, 5, 9, 2, 2, 4, 4, 1, 8,\n",
      "        4, 3, 7, 9, 7, 8, 8, 3, 3, 1, 0, 6, 2, 3, 6, 0, 6, 8, 7, 0, 6, 8, 6, 5,\n",
      "        7, 2, 3, 7, 6, 1, 3, 4, 7, 2, 4, 7, 3, 2, 0, 0])\n",
      "output= tensor([[-2.2663, -2.2982, -2.3410,  ..., -2.2657, -2.3237, -2.3321],\n",
      "        [-2.4790, -2.4864, -2.1362,  ..., -2.1085, -2.3853, -2.1573],\n",
      "        [-2.2571, -2.3047, -2.2959,  ..., -2.2690, -2.3598, -2.3433],\n",
      "        ...,\n",
      "        [-2.3874, -2.4193, -2.2946,  ..., -2.3102, -2.2732, -2.2302],\n",
      "        [-2.2959, -2.2967, -2.3070,  ..., -2.2967, -2.3058, -2.3069],\n",
      "        [-2.8625, -1.7720, -2.6431,  ..., -1.8302, -2.2945, -2.3621]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([9, 0, 0, 7, 1, 7, 4, 7, 3, 7, 7, 0, 9, 9, 2, 9, 5, 5, 1, 5, 2, 8, 7, 7,\n",
      "        5, 6, 1, 9, 9, 7, 0, 3, 1, 4, 3, 8, 1, 3, 7, 6, 6, 3, 5, 6, 0, 4, 3, 9,\n",
      "        5, 7, 2, 3, 4, 9, 6, 3, 8, 0, 2, 6, 5, 9, 3, 6, 1, 2, 8, 8, 5, 9, 9, 2,\n",
      "        7, 6, 7, 0, 9, 2, 5, 9, 7, 2, 5, 8, 1, 4, 9, 0, 9, 5, 8, 7, 6, 6, 4, 9,\n",
      "        1, 8, 0, 0, 4, 0, 9, 5, 9, 0, 2, 6, 7, 7, 6, 0, 5, 9, 9, 6, 7, 1, 2, 9,\n",
      "        6, 1, 0, 1, 9, 9, 2, 8, 4, 8, 8, 1, 6, 5, 4, 4, 3, 0, 2, 6, 1, 5, 0, 0,\n",
      "        0, 1, 6, 3, 5, 3, 6, 1, 8, 7, 5, 9, 7, 4, 9, 1, 8, 3, 4, 9, 9, 6, 1, 8,\n",
      "        6, 6, 2, 4, 2, 0, 3, 7, 7, 3, 8, 8, 1, 4, 7, 9, 2, 3, 9, 9, 6, 8, 7, 9,\n",
      "        5, 7, 8, 6, 7, 8, 9, 3, 1, 3, 7, 9, 3, 7, 1, 7, 9, 3, 7, 1, 8, 3, 7, 6,\n",
      "        3, 1, 5, 0, 7, 7, 2, 4, 7, 5, 3, 8, 5, 1, 5, 7, 2, 1, 1, 4, 7, 1, 6, 5,\n",
      "        1, 4, 9, 4, 6, 4, 4, 8, 0, 0, 9, 6, 8, 9, 5, 3])\n",
      "output= tensor([[-2.7620, -2.7099, -1.9378,  ..., -2.1532, -2.9556, -2.1451],\n",
      "        [-2.2890, -2.3052, -2.3045,  ..., -2.2896, -2.2990, -2.3072],\n",
      "        [-2.0046, -2.9990, -2.3288,  ..., -2.1948, -2.5214, -1.9433],\n",
      "        ...,\n",
      "        [-2.3617, -2.2766, -2.4239,  ..., -2.1852, -2.5647, -2.2214],\n",
      "        [-2.2941, -2.2967, -2.3051,  ..., -2.3003, -2.3041, -2.3095],\n",
      "        [-2.4874, -2.3371, -2.2695,  ..., -2.2796, -2.3360, -2.2023]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([2, 6, 9, 0, 4, 9, 3, 4, 1, 2, 7, 1, 4, 3, 7, 8, 5, 5, 7, 8, 6, 6, 0, 2,\n",
      "        9, 3, 1, 0, 4, 1, 0, 2, 3, 1, 9, 1, 1, 1, 9, 3, 7, 7, 8, 8, 6, 9, 7, 8,\n",
      "        1, 7, 0, 2, 6, 0, 0, 2, 6, 5, 0, 0, 6, 5, 1, 0, 6, 4, 3, 6, 0, 5, 2, 1,\n",
      "        2, 5, 7, 4, 8, 6, 0, 7, 3, 1, 5, 4, 7, 2, 0, 3, 5, 3, 6, 4, 5, 2, 2, 0,\n",
      "        4, 4, 0, 1, 5, 8, 7, 7, 0, 0, 7, 6, 4, 7, 8, 2, 0, 7, 0, 9, 6, 2, 7, 7,\n",
      "        5, 7, 1, 7, 2, 2, 5, 6, 3, 3, 8, 5, 6, 7, 2, 4, 6, 5, 4, 1, 1, 6, 4, 4,\n",
      "        7, 8, 2, 9, 6, 1, 2, 9, 4, 7, 4, 4, 5, 5, 6, 0, 1, 3, 1, 6, 6, 6, 8, 7,\n",
      "        2, 1, 0, 8, 5, 5, 0, 8, 2, 4, 7, 0, 9, 3, 6, 0, 0, 7, 7, 2, 4, 3, 0, 9,\n",
      "        7, 9, 1, 5, 2, 5, 5, 8, 9, 3, 1, 9, 1, 1, 3, 6, 6, 7, 0, 1, 0, 0, 0, 7,\n",
      "        2, 0, 0, 2, 5, 2, 6, 5, 8, 8, 2, 7, 0, 8, 7, 2, 1, 7, 4, 7, 9, 8, 4, 3,\n",
      "        0, 5, 8, 1, 4, 8, 3, 5, 0, 9, 9, 1, 5, 3, 3, 3])\n",
      "output= tensor([[-3.9818, -2.3631, -1.9705,  ..., -2.3235, -2.2277, -2.0270],\n",
      "        [-2.2515, -2.3081, -2.3013,  ..., -2.2552, -2.3610, -2.3316],\n",
      "        [-2.2853, -2.2988, -2.3093,  ..., -2.2897, -2.2895, -2.3081],\n",
      "        ...,\n",
      "        [-2.2969, -2.2937, -2.3077,  ..., -2.2951, -2.3061, -2.3052],\n",
      "        [-2.2696, -2.3167, -2.2727,  ..., -2.1728, -2.2920, -2.3587],\n",
      "        [-2.2915, -2.3027, -2.3072,  ..., -2.2843, -2.3008, -2.3032]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([3, 9, 2, 0, 4, 6, 1, 8, 5, 0, 2, 8, 1, 6, 3, 8, 0, 3, 7, 7, 8, 4, 4, 9,\n",
      "        2, 5, 8, 6, 8, 4, 7, 3, 5, 8, 3, 4, 0, 5, 8, 0, 5, 8, 0, 6, 7, 1, 9, 7,\n",
      "        1, 3, 1, 1, 7, 5, 9, 3, 6, 5, 0, 9, 6, 9, 6, 0, 2, 5, 6, 0, 5, 5, 9, 7,\n",
      "        5, 7, 5, 2, 8, 9, 9, 1, 1, 4, 6, 5, 4, 7, 2, 1, 8, 3, 1, 4, 2, 7, 2, 4,\n",
      "        6, 2, 8, 5, 4, 3, 2, 1, 2, 8, 8, 1, 1, 3, 3, 4, 8, 2, 0, 9, 6, 9, 4, 3,\n",
      "        4, 3, 9, 3, 0, 0, 9, 5, 7, 2, 3, 9, 4, 5, 0, 4, 2, 2, 5, 1, 1, 7, 4, 8,\n",
      "        8, 5, 2, 8, 9, 5, 9, 9, 7, 6, 9, 4, 9, 4, 7, 9, 7, 3, 6, 8, 6, 7, 8, 4,\n",
      "        2, 5, 3, 2, 6, 1, 6, 5, 3, 8, 2, 3, 9, 0, 4, 4, 2, 5, 3, 8, 9, 9, 4, 8,\n",
      "        3, 6, 4, 5, 1, 7, 6, 8, 8, 1, 7, 9, 0, 0, 0, 1, 3, 0, 2, 7, 9, 1, 7, 2,\n",
      "        1, 6, 8, 5, 7, 0, 9, 4, 3, 6, 6, 5, 5, 7, 2, 9, 6, 3, 7, 2, 5, 8, 8, 6,\n",
      "        7, 9, 7, 3, 1, 5, 7, 8, 1, 1, 6, 2, 5, 3, 5, 6])\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.276055\n",
      "output= tensor([[-3.1980, -3.1055, -1.9176,  ..., -2.8843, -2.6513, -1.1821],\n",
      "        [-2.2958, -2.2914, -2.3013,  ..., -2.2303, -2.3173, -2.3281],\n",
      "        [-2.7366, -2.2206, -2.4860,  ..., -2.3056, -1.7759, -2.5201],\n",
      "        ...,\n",
      "        [-2.2939, -2.3311, -2.2681,  ..., -2.1194, -2.4085, -2.2286],\n",
      "        [-2.3644, -2.4414, -2.3503,  ..., -2.3536, -2.4670, -2.1894],\n",
      "        [-2.2466, -2.3103, -2.2958,  ..., -2.2546, -2.3604, -2.3400]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([9, 5, 3, 7, 6, 4, 3, 7, 6, 7, 9, 5, 2, 7, 5, 8, 2, 5, 9, 7, 0, 0, 8, 6,\n",
      "        5, 5, 2, 6, 1, 0, 5, 8, 5, 1, 5, 0, 9, 2, 8, 2, 5, 4, 4, 1, 6, 5, 4, 0,\n",
      "        3, 8, 1, 9, 9, 8, 0, 1, 7, 4, 9, 6, 0, 0, 8, 5, 5, 1, 7, 6, 3, 1, 7, 5,\n",
      "        3, 9, 0, 9, 8, 9, 8, 9, 2, 9, 0, 0, 9, 0, 6, 7, 0, 3, 8, 0, 4, 6, 2, 9,\n",
      "        3, 5, 2, 6, 1, 5, 5, 6, 1, 1, 4, 4, 8, 1, 1, 0, 5, 1, 4, 2, 9, 8, 1, 7,\n",
      "        8, 9, 2, 8, 0, 1, 4, 6, 6, 0, 8, 6, 5, 9, 4, 7, 6, 4, 3, 8, 7, 8, 7, 3,\n",
      "        5, 4, 0, 7, 3, 2, 1, 7, 9, 6, 0, 8, 1, 3, 2, 7, 4, 5, 0, 9, 7, 1, 1, 1,\n",
      "        2, 5, 2, 9, 9, 9, 5, 6, 8, 6, 9, 4, 3, 2, 1, 7, 6, 8, 0, 5, 3, 5, 9, 6,\n",
      "        3, 9, 0, 0, 6, 6, 8, 1, 6, 8, 7, 3, 2, 2, 8, 0, 6, 1, 6, 8, 3, 4, 3, 0,\n",
      "        7, 5, 4, 0, 8, 7, 3, 4, 4, 1, 2, 0, 5, 0, 3, 5, 7, 0, 3, 2, 1, 1, 3, 9,\n",
      "        7, 4, 6, 3, 3, 4, 8, 5, 8, 4, 3, 3, 0, 8, 6, 4])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output= tensor([[-2.2631, -2.7613, -2.7481,  ..., -2.4480, -2.2830, -2.2666],\n",
      "        [-3.0259, -1.8449, -2.2313,  ..., -1.9385, -2.4652, -2.2687],\n",
      "        [-2.2883, -2.3051, -2.3062,  ..., -2.2838, -2.2873, -2.3103],\n",
      "        ...,\n",
      "        [-2.2966, -2.2980, -2.3044,  ..., -2.2916, -2.2950, -2.3149],\n",
      "        [-2.9705, -2.1507, -2.3557,  ..., -2.0502, -2.2214, -2.0655],\n",
      "        [-2.2959, -2.2978, -2.3088,  ..., -2.2949, -2.3046, -2.3096]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([4, 5, 1, 8, 0, 6, 2, 4, 1, 2, 8, 4, 3, 0, 6, 2, 6, 1, 9, 7, 6, 8, 5, 9,\n",
      "        9, 8, 0, 9, 2, 9, 1, 6, 6, 3, 3, 7, 2, 8, 6, 9, 3, 0, 5, 6, 0, 4, 4, 2,\n",
      "        2, 4, 6, 5, 4, 5, 5, 2, 7, 7, 9, 3, 5, 9, 6, 0, 5, 6, 8, 1, 6, 7, 2, 0,\n",
      "        2, 6, 2, 7, 4, 4, 0, 0, 5, 3, 0, 6, 8, 8, 4, 9, 8, 5, 6, 0, 0, 3, 8, 3,\n",
      "        5, 1, 9, 2, 0, 3, 5, 5, 3, 7, 9, 0, 6, 3, 9, 1, 9, 2, 5, 2, 2, 4, 5, 1,\n",
      "        0, 4, 4, 5, 5, 4, 3, 1, 3, 1, 3, 1, 5, 9, 8, 9, 8, 7, 0, 2, 8, 1, 5, 0,\n",
      "        1, 2, 0, 5, 4, 5, 1, 6, 4, 8, 8, 7, 9, 2, 6, 4, 4, 1, 6, 2, 9, 7, 9, 3,\n",
      "        3, 1, 3, 8, 9, 1, 7, 9, 7, 0, 2, 9, 9, 1, 6, 5, 2, 2, 8, 0, 0, 0, 6, 5,\n",
      "        1, 9, 8, 0, 6, 1, 9, 7, 2, 1, 6, 2, 3, 0, 8, 6, 0, 5, 2, 2, 7, 9, 4, 3,\n",
      "        5, 1, 3, 2, 6, 3, 3, 0, 6, 1, 3, 2, 8, 2, 4, 3, 7, 6, 5, 5, 4, 0, 7, 0,\n",
      "        7, 5, 9, 6, 6, 1, 2, 5, 0, 7, 2, 4, 3, 9, 5, 1])\n",
      "output= tensor([[-2.5902, -2.3773, -2.4235,  ..., -2.4258, -2.5787, -2.2203],\n",
      "        [-2.2447, -2.3060, -2.2970,  ..., -2.2613, -2.3666, -2.3368],\n",
      "        [-2.2863, -2.2974, -2.3139,  ..., -2.2921, -2.2975, -2.3020],\n",
      "        ...,\n",
      "        [-3.5599, -3.0727, -1.8725,  ..., -2.1831, -2.2033, -2.0707],\n",
      "        [-4.1775, -1.6919, -2.9165,  ..., -3.0868, -1.0624, -2.4822],\n",
      "        [-2.2966, -2.2896, -2.3101,  ..., -2.3004, -2.3075, -2.3022]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([7, 5, 6, 2, 2, 1, 1, 0, 4, 5, 7, 0, 1, 4, 3, 8, 2, 2, 3, 6, 4, 0, 1, 1,\n",
      "        1, 1, 3, 9, 2, 0, 6, 1, 3, 1, 9, 7, 4, 7, 0, 3, 3, 6, 8, 9, 8, 4, 9, 3,\n",
      "        0, 0, 5, 4, 8, 9, 9, 3, 7, 1, 9, 1, 1, 4, 6, 2, 4, 8, 3, 4, 2, 9, 4, 6,\n",
      "        1, 2, 2, 7, 9, 7, 1, 7, 0, 3, 7, 4, 3, 3, 4, 9, 5, 4, 1, 8, 6, 0, 1, 3,\n",
      "        7, 2, 8, 6, 4, 4, 5, 0, 3, 5, 4, 5, 6, 3, 9, 8, 3, 0, 5, 6, 0, 5, 2, 9,\n",
      "        3, 3, 9, 7, 6, 7, 9, 9, 8, 5, 0, 7, 3, 5, 1, 6, 2, 2, 8, 9, 0, 5, 7, 3,\n",
      "        0, 2, 9, 7, 8, 3, 4, 8, 5, 6, 4, 9, 5, 9, 7, 0, 7, 0, 9, 3, 8, 3, 0, 2,\n",
      "        0, 4, 5, 8, 7, 3, 2, 5, 9, 1, 1, 0, 1, 7, 5, 9, 1, 3, 0, 9, 2, 7, 4, 6,\n",
      "        9, 3, 6, 1, 8, 2, 9, 8, 3, 9, 5, 1, 4, 4, 3, 5, 3, 3, 4, 3, 7, 4, 4, 6,\n",
      "        1, 7, 1, 7, 1, 4, 2, 0, 6, 1, 1, 2, 5, 2, 7, 8, 8, 9, 8, 0, 6, 4, 1, 4,\n",
      "        9, 6, 5, 9, 3, 3, 3, 0, 5, 4, 4, 4, 2, 3, 2, 7])\n",
      "output= tensor([[-2.3201, -2.3648, -2.1891,  ..., -2.1992, -2.2928, -2.3280],\n",
      "        [-2.6317, -2.7959, -2.2957,  ..., -1.8831, -2.3441, -1.5942],\n",
      "        [-2.2407, -2.3069, -2.2969,  ..., -2.2651, -2.3604, -2.3469],\n",
      "        ...,\n",
      "        [-2.2619, -2.3745, -2.3070,  ..., -2.3357, -2.2611, -2.2949],\n",
      "        [-2.3539, -2.2352, -2.2735,  ..., -2.2462, -2.3515, -2.2175],\n",
      "        [-2.2963, -2.2885, -2.3106,  ..., -2.3012, -2.3085, -2.3018]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "target= tensor([3, 4, 7, 5, 0, 2, 2, 3, 1, 3, 3, 3, 6, 8, 7, 1, 1, 8, 1, 3, 7, 6, 7, 6,\n",
      "        7, 2, 8, 4, 3, 3, 1, 7, 4, 1, 0, 7, 5, 8, 5, 1, 0, 9, 7, 3, 1, 7, 4, 0,\n",
      "        3, 8, 2, 4, 9, 1, 4, 0, 3, 5, 2, 6, 4, 5, 1, 3, 7, 2, 0, 8, 4, 3, 7, 1,\n",
      "        6, 3, 7, 2, 7, 7, 2, 6, 3, 7, 0, 1, 1, 9, 7, 6, 7, 6, 3, 2, 6, 5, 1, 5,\n",
      "        8, 6, 0, 0, 6, 1, 1, 9, 3, 9, 6, 7, 5, 0, 8, 7, 3, 6, 4, 5, 8, 8, 5, 1,\n",
      "        0, 1, 4, 0, 8, 5, 3, 6, 7, 8, 5, 1, 5, 4, 4, 9, 9, 6, 0, 3, 3, 6, 1, 0,\n",
      "        6, 9, 7, 3, 8, 8, 2, 8, 1, 3, 0, 9, 9, 4, 5, 9, 1, 3, 6, 0, 4, 3, 3, 9,\n",
      "        1, 1, 1, 8, 4, 3, 3, 9, 7, 2, 9, 3, 0, 4, 9, 1, 5, 9, 3, 0, 7, 1, 1, 1,\n",
      "        0, 1, 5, 3, 0, 6, 3, 7, 9, 6, 5, 8, 1, 9, 3, 8, 5, 7, 3, 9, 9, 1, 1, 7,\n",
      "        2, 7, 8, 5, 3, 5, 8, 1, 9, 8, 0, 7, 7, 4, 1, 6, 0, 1, 4, 3, 4, 1, 5, 3,\n",
      "        4, 6, 7, 1, 2, 4, 7, 3, 1, 1, 7, 4, 3, 5, 7, 0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ef6e122ea50c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-a10081d0784f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'target='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  output = network(example_data)\n",
    "# compare the model's output.\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4WyZ8PFFuMT"
   },
   "source": [
    "(4) For a batch of 256 random samples, compute the gradient of the average of the neural network outputs (over the batch) w.r.t to the weights using torch autograd. Compute the gradients for the torch.nn based model in (3) and validate the gradients match those from those computed with (2). \n",
    "\n",
    "**Note**: The network here is $f: \\mathcal{R}^{HW}\\rightarrow\\mathcal{R}$, with $256$ samples you should obtain $o=\\frac{1}{256}\\sum_{i=0}^{255}f(x_i)$. You are asked to find $\\nabla_w o$ for all the parameters $w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV1 avg grad=\n",
      " tensor([[[-0.0115, -0.0148,  0.0041,  0.0047, -0.0047],\n",
      "         [-0.0101,  0.0090,  0.0160,  0.0061, -0.0109],\n",
      "         [ 0.0149,  0.0364,  0.0252,  0.0043, -0.0108],\n",
      "         [ 0.0229,  0.0234,  0.0192,  0.0084, -0.0163],\n",
      "         [ 0.0127,  0.0159,  0.0247,  0.0119, -0.0239]]])\n",
      "CONV1 bais= tensor([ 0.0719,  0.0204,  0.0418, -0.0840, -0.0738,  0.0930, -0.0252, -0.0163,\n",
      "         0.0376, -0.0187])\n",
      "CONV2 avg grad=\n",
      " tensor([[[ 8.1622e-03,  1.1241e-03, -1.1303e-03, -3.4079e-03, -3.8529e-03],\n",
      "         [ 7.4713e-03,  2.0216e-03, -1.0730e-03, -2.3892e-03, -4.3317e-03],\n",
      "         [ 8.1102e-03,  3.1657e-03,  1.0417e-03, -3.0093e-03, -4.9821e-03],\n",
      "         [ 6.2450e-03,  8.6071e-03,  3.9458e-03,  2.6482e-03, -4.0992e-03],\n",
      "         [ 7.9142e-03,  9.0671e-03,  7.3794e-03,  4.4229e-03,  1.3005e-03]],\n",
      "\n",
      "        [[-6.3245e-03,  1.1890e-02,  1.0024e-02, -3.3405e-03,  1.4274e-02],\n",
      "         [-3.8762e-03,  1.3886e-02,  1.4757e-03,  7.3571e-03,  8.5690e-03],\n",
      "         [ 1.7839e-03,  3.2817e-03, -1.4601e-03,  5.0020e-03, -4.3942e-03],\n",
      "         [-3.0261e-03, -1.9262e-04,  2.7268e-04,  4.1846e-03, -4.8927e-03],\n",
      "         [-2.2153e-03, -2.7750e-03,  1.4936e-04,  1.1347e-02, -3.1673e-03]],\n",
      "\n",
      "        [[ 8.4768e-03,  5.2685e-03,  5.4123e-03, -1.0437e-03, -4.6782e-03],\n",
      "         [ 1.0096e-02,  5.3242e-03,  2.9043e-03, -4.3900e-03, -1.0985e-02],\n",
      "         [ 8.7934e-03,  4.7792e-03,  3.0143e-03, -4.5455e-03, -4.3415e-03],\n",
      "         [ 6.7981e-03,  1.0088e-02,  7.5940e-03, -3.6223e-03,  2.3959e-03],\n",
      "         [ 6.1566e-03,  1.4112e-02,  1.0102e-02,  7.9944e-03, -6.8506e-03]],\n",
      "\n",
      "        [[ 1.1483e-03,  4.2556e-03,  5.6883e-03, -9.6276e-03,  2.4819e-03],\n",
      "         [ 9.1749e-04,  7.8782e-03,  7.1680e-03, -4.4020e-04, -3.5133e-03],\n",
      "         [ 1.0702e-03, -1.8500e-03,  1.1009e-02,  1.0196e-02,  1.9343e-03],\n",
      "         [ 2.6477e-04,  1.7828e-03, -8.4488e-05, -4.7696e-03, -4.3800e-03],\n",
      "         [-1.2310e-02, -9.0957e-03, -7.1488e-03, -3.2761e-03, -2.9894e-03]],\n",
      "\n",
      "        [[-3.0199e-03,  2.8563e-03,  6.1185e-03,  8.1443e-03,  5.6353e-04],\n",
      "         [-6.0868e-03, -3.0534e-03, -1.0792e-03, -2.1234e-03, -2.5824e-03],\n",
      "         [ 4.8143e-03,  3.7338e-03,  6.4094e-03, -8.4741e-03, -1.3521e-02],\n",
      "         [ 6.8102e-03,  1.1041e-03,  1.2737e-04, -9.2468e-05, -9.3481e-03],\n",
      "         [-9.6235e-04,  1.0463e-03,  2.7951e-03, -3.1377e-03, -2.4164e-03]],\n",
      "\n",
      "        [[-4.2943e-03, -6.0461e-03, -8.8629e-03, -4.3061e-04, -1.2365e-02],\n",
      "         [-7.4959e-03, -9.6564e-03, -9.0152e-03, -8.8952e-04, -7.6768e-03],\n",
      "         [-5.1643e-03, -2.9433e-03, -9.4226e-03, -8.7667e-03, -3.6248e-03],\n",
      "         [-5.3816e-03, -7.6322e-03, -3.4683e-03, -1.2913e-02, -5.5628e-03],\n",
      "         [-2.9024e-03, -4.2295e-03, -1.3798e-02, -1.9412e-02, -9.4358e-03]],\n",
      "\n",
      "        [[ 1.9412e-03,  1.0522e-03,  8.3248e-05, -2.6718e-04, -6.9597e-04],\n",
      "         [ 1.9343e-03,  5.4572e-04,  1.7834e-03, -2.1002e-03, -2.3174e-03],\n",
      "         [ 1.7078e-03,  3.0964e-04, -8.5580e-04, -1.1234e-03, -1.7795e-03],\n",
      "         [ 9.6566e-04,  7.1278e-04,  7.8636e-05, -8.5705e-04, -1.9289e-03],\n",
      "         [-4.6062e-04,  1.2229e-03,  1.3346e-03,  7.3866e-04,  2.4661e-04]],\n",
      "\n",
      "        [[-7.1226e-03, -3.7617e-03, -1.8290e-03,  1.1671e-04,  5.7937e-03],\n",
      "         [ 1.3360e-03,  8.4458e-03,  4.5943e-03,  7.5846e-03,  3.9304e-03],\n",
      "         [-9.1954e-03,  2.5088e-03,  7.7241e-03,  3.2634e-03,  2.6514e-03],\n",
      "         [-6.8337e-03, -7.5879e-03, -4.3359e-03,  2.5700e-03, -2.3092e-05],\n",
      "         [-5.7780e-03, -5.4488e-03, -1.8904e-03,  4.6354e-03, -2.4570e-03]],\n",
      "\n",
      "        [[-4.6056e-03, -6.9322e-03,  2.1824e-03, -9.8225e-04,  2.3488e-03],\n",
      "         [-2.0537e-03, -3.3932e-04,  1.9196e-03, -4.0310e-04, -1.0453e-03],\n",
      "         [-1.1278e-03,  1.0214e-03,  1.0957e-03, -3.5196e-04,  4.1599e-04],\n",
      "         [-1.9448e-04, -1.0727e-03, -4.4580e-03, -3.1441e-03, -1.2433e-03],\n",
      "         [ 4.2287e-04,  3.1431e-04, -3.1710e-03, -2.9448e-03,  2.7420e-03]],\n",
      "\n",
      "        [[ 1.2887e-02,  1.9902e-03, -4.7720e-04, -5.2254e-03, -4.5522e-03],\n",
      "         [ 1.2154e-02,  3.9796e-03,  1.2683e-03, -6.2461e-03, -7.4682e-03],\n",
      "         [ 1.3894e-02,  3.7181e-03,  6.0308e-04, -4.3666e-03, -1.0031e-02],\n",
      "         [ 1.4902e-02,  1.4449e-02,  6.6666e-03, -2.7596e-03, -7.9150e-03],\n",
      "         [ 1.4737e-02,  1.9065e-02,  1.3012e-02,  1.0617e-02,  3.1032e-03]]])\n",
      "CONV2 bais= tensor([-0.2013,  0.0000,  0.0000, -0.2485,  0.0000,  0.0117,  0.0000, -0.0330,\n",
      "         0.0000,  0.0000,  0.2050,  0.3159,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.1239,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "print('CONV1 avg grad=\\n',sum(network.conv1.weight.grad)/len(network.conv1.weight.grad)) \n",
    "print('CONV1 bais=',network.conv1.bias.grad)\n",
    "print('CONV2 avg grad=\\n',sum(network.conv2.weight.grad)/len(network.conv2.weight.grad)) \n",
    "print('CONV2 bais=',network.conv2.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YHbWOIQHKow"
   },
   "source": [
    "(5) Perform  the forward and backward passes from (3), 10 times on cpu and 10 times on gpu, report the average time for both. Repeat this for just the forward pass. In the end you should obtain 4 average run times (forward and backward, forward only) x (cpu, gpu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.034178\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 1.803627\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 1.873235\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 1.976927\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 1.889993\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.906535\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 1.946473\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 1.864058\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 1.912492\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 1.888984\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 1.817260\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 1.765820\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 1.912878\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 1.782560\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 1.866216\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 1.854770\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 1.779593\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 1.828561\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 1.946491\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 1.843549\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 1.888188\n",
      "Train Epoch: 0 [53760/60000 (89%)]\tLoss: 1.816595\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 1.742820\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 1.976514\n",
      "Train Time for epoch:  0 = 153.93541343900142\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.874336\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 1.829302\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 1.796278\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 1.852680\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 1.859425\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.908821\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 1.764860\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 1.758926\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 1.866199\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 1.726527\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 1.748868\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 1.784663\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 1.669021\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 1.681598\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 1.970746\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 1.750055\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 1.667885\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 1.803483\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 1.805350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-14c4fd2589e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train Time for epoch: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-ee6d5b152335>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "total_t=0\n",
    "for iter in range(10):\n",
    "    start = timeit.default_timer()\n",
    "    for epoch in range(1):        \n",
    "        train(epoch)    \n",
    "    stop = timeit.default_timer()\n",
    "    print('Train Time for epoch: ',epoch,'=', stop - start) \n",
    "    total_t=total_t+(stop - start)\n",
    "print('avg_time=',total_t/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab1_part2_Ex.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
