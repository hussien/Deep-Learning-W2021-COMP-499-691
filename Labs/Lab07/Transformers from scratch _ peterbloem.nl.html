<!DOCTYPE html>
<!-- saved from url=(0038)http://peterbloem.nl/blog/transformers -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Global site tag (gtag.js) - Google Analytics -->
	<script type="text/javascript" async="" src="./Transformers from scratch _ peterbloem.nl_files/analytics.js.download"></script><script async="" src="./Transformers from scratch _ peterbloem.nl_files/js"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());
	
	  gtag('config', 'UA-33416628-1');
	</script>

	
    <title> Transformers from scratch | peterbloem.nl</title>
    
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="./Transformers from scratch _ peterbloem.nl_files/screen.pb.css">
    <link rel="stylesheet" type="text/css" href="./Transformers from scratch _ peterbloem.nl_files/MyFontsWebfontsKit.css">

    
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
        
    
    	
    
     
    <link rel="stylesheet" href="./Transformers from scratch _ peterbloem.nl_files/default.min.css">
	<script src="./Transformers from scratch _ peterbloem.nl_files/highlight.min.js.download"></script>
	<script>hljs.initHighlightingOnLoad();</script>
	
	
    
    <script type="text/x-mathjax-config;executed=true">
  	MathJax.Hub.Config({
    	extensions: ["tex2jax.js"],
    	jax: ["input/TeX", "output/HTML-CSS"],
    	tex2jax: {
      		inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      		displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    		processEscapes: true
	    },
		"HTML-CSS": { 
			availableFonts: [], preferredFont: null,
			webFont: "Neo-Euler",
			mtextFontInherit: true
		}, 
		TeX: {
			extensions: ["color.js"],
			Macros: {
				lgc: ["{\\color{my-light-green} #1}", 1],
				gc: ["{\\color{my-green} #1}", 1],
				lrc: ["{\\color{my-light-red} #1}", 1],
				rc: ["{\\color{my-red} #1}", 1],
				lbc: ["{\\color{my-light-blue} #1}", 1],
				bc: ["{\\color{my-blue} #1}", 1],
				kc: ["{\\color{my-gray} #1}", 1],
				loc: ["{\\color{my-light-orange} #1}", 1],
				oc: ["{\\color{my-orange} #1}", 1],
			
				a: ["\\mathbf a"],
				A: ["\\mathbf A"],
				b: ["\\mathbf b"],	
				B: ["\\mathbf B"],	
				c: ["\\mathbf c"],	
				C: ["\\mathbf C"],					
				d: ["\\mathbf d"],	
				D: ["\\mathbf D"],
				E: ["\\mathbf E"],	
				I: ["\\mathbf I"],
				M: ["\\mathbf M"],				
				r: ["\\mathbf r"],	
				s: ["\\mathbf s"],	
				t: ["\\mathbf t"],	
				S: ["\\mathbf S"],	
				x: ["\\mathbf x"],
				z: ["\\mathbf z"],
				v: ["\\mathbf v"],
				y: ["\\mathbf y"],
				k: ["\\mathbf k"],
				bp: ["\\mathbf p"],
				P: ["\\mathbf P"],
				q: ["\\mathbf q"],
				e: ["\\mathbf e"],
				X: ["\\mathbf X"],
				v: ["\\mathbf v"],				
				V: ["\\mathbf V"],
				w: ["\\mathbf w"],
				W: ["\\mathbf W"],
				Y: ["\\mathbf Y"],
				z: ["\\mathbf z"],
				Z: ["\\mathbf Z"],
				p: ["\\,\\text{.}"],
				
				argmin: ["\\underset{#1}{\\text{argmin}}", 1],
				argmax: ["\\underset{#1}{\\text{argmax}}", 1],
			}
		}
  	});
  	
  	MathJax.Hub.Register.StartupHook("TeX color Ready", function() {
     	MathJax.Extension["TeX/color"].colors["my-green"] = '#677d00';
     	MathJax.Extension["TeX/color"].colors["my-light-green"] = '#acd373';
     	MathJax.Extension["TeX/color"].colors["my-red"] = '#b13e26';
     	MathJax.Extension["TeX/color"].colors["my-light-red"] = '#d38473';
     	MathJax.Extension["TeX/color"].colors["my-blue"] = '#306693';
       	MathJax.Extension["TeX/color"].colors["my-light-blue"] = '#73a7d3';
       	MathJax.Extension["TeX/color"].colors["my-gray"] = '#999';
       	MathJax.Extension["TeX/color"].colors["my-orange"] = '#E69500';
       	MathJax.Extension["TeX/color"].colors["my-light-orange"] = '#FFC353';


	});
	</script>
	
	<script type="text/javascript" async="" src="./Transformers from scratch _ peterbloem.nl_files/MathJax.js.download">
	</script>
        
    
       

    
        
    <script src="./Transformers from scratch _ peterbloem.nl_files/scripts.js.download"></script>
    
    <link rel="icon" type="image/png" href="http://peterbloem.nl/images/favicon128.png" sizes="128">
    <link rel="icon" type="image/png" href="http://peterbloem.nl/images/favicon32.png" sizes="32,16">
    		
  <style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none; box-sizing: content-box}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_test.mjx-test-display {display: table!important}
.MathJax_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_test.mjx-test-default {display: block!important; clear: both}
.MathJax_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.MathJax_em_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60em}
.mjx-test-inline .MathJax_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
</style><style type="text/css">@font-face {font-family: NeoEulerMathJax_Main; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/woff/NeoEulerMathJax_Main-Regular.woff?V=2.7.5') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/otf/NeoEulerMathJax_Main-Regular.otf?V=2.7.5') format('opentype')}
</style><style type="text/css">@font-face {font-family: NeoEulerMathJax_Normal; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/woff/NeoEulerMathJax_Normal-Regular.woff?V=2.7.5') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/otf/NeoEulerMathJax_Normal-Regular.otf?V=2.7.5') format('opentype')}
</style><style type="text/css">@font-face {font-family: NeoEulerMathJax_Size1; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/woff/NeoEulerMathJax_Size1-Regular.woff?V=2.7.5') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/otf/NeoEulerMathJax_Size1-Regular.otf?V=2.7.5') format('opentype')}
</style><style type="text/css">@font-face {font-family: NeoEulerMathJax_Variants; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/woff/NeoEulerMathJax_Variants-Regular.woff?V=2.7.5') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/otf/NeoEulerMathJax_Variants-Regular.otf?V=2.7.5') format('opentype')}
</style><style type="text/css">@font-face {font-family: NeoEulerMathJax_Alphabets; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/woff/NeoEulerMathJax_Alphabets-Regular.woff?V=2.7.5') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/otf/NeoEulerMathJax_Alphabets-Regular.otf?V=2.7.5') format('opentype')}
</style><style type="text/css">@font-face {font-family: NeoEulerMathJax_Marks; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/woff/NeoEulerMathJax_Marks-Regular.woff?V=2.7.5') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/otf/NeoEulerMathJax_Marks-Regular.otf?V=2.7.5') format('opentype')}
</style><style type="text/css">@font-face {font-family: NeoEulerMathJax_Arrows; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/woff/NeoEulerMathJax_Arrows-Regular.woff?V=2.7.5') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/otf/NeoEulerMathJax_Arrows-Regular.otf?V=2.7.5') format('opentype')}
</style><style type="text/css">@font-face {font-family: NeoEulerMathJax_Operators; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/woff/NeoEulerMathJax_Operators-Regular.woff?V=2.7.5') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/fonts/HTML-CSS/Neo-Euler/otf/NeoEulerMathJax_Operators-Regular.otf?V=2.7.5') format('opentype')}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style></head>
  <body id="body" class="body  " data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed=""><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>
    
	
	   <article>
		 <!--  -->

<header>
<h1>Transformers from scratch</h1>

</header>
<ul class="links">
	<li>18 Aug 2019</li>
	<li><a class="code" href="https://github.com/pbloem/former">code on github</a></li>
	<li><a class="code" href="https://www.youtube.com/playlist?list=PLIXJ-Sacf8u60G1TwcznBmK6rEL3gmZmV">video lecture</a></li>
</ul>

<aside>
Transformers are a very exciting family of machine learning architectures. Many good tutorials exist (e.g. [1, 2]) but in the last few years, transformers have mostly become simpler, so that it is now much more straightforward to explain how modern architectures work. This post is an attempt to explain directly how modern transformers work, and why, without some of the historical baggage.
</aside>

<p>I will assume a basic understanding of neural networks and backpropagation. If you’d like to brush up, <a href="https://youtu.be/1NVgspM98W0">this lecture</a> will give you the basics of neural networks and <a href="https://youtu.be/DidHjsp_OV0">this one</a> will explain how these principles are applied in modern deep learning systems.</p>

<p>A <a href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html">working knowledge of Pytorch</a> is required to understand the programming examples, but these can also be safely skipped.</p>

<h2 id="self-attention">Self-attention</h2>

<p>The fundamental operation of any transformer architecture is the <em>self-attention operation</em>.</p>

<aside>
We'll explain where the name "self-attention" comes from later. For now, don't read too much in to it.
</aside>

<p>Self-attention is a sequence-to-sequence operation: a sequence of vectors goes in, and a sequence of vectors comes out. Let’s call the input vectors <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1" style="width: 5.694em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.121em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.517em, 1005.12em, 2.459em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="msubsup" id="MathJax-Span-3"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-4"><span class="mrow" id="MathJax-Span-5"><span class="mi" id="MathJax-Span-6" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="mn" id="MathJax-Span-7" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-8" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-9" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-10"><span class="mrow" id="MathJax-Span-11"><span class="mi" id="MathJax-Span-12" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="mn" id="MathJax-Span-13" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-14" style="font-family: NeoEulerMathJax_Main;">,</span><span class="mo" id="MathJax-Span-15" style="font-family: NeoEulerMathJax_Main; padding-left: 0.166em;">…</span><span class="mo" id="MathJax-Span-16" style="font-family: NeoEulerMathJax_Main; padding-left: 0.166em;">,</span><span class="msubsup" id="MathJax-Span-17" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-18"><span class="mrow" id="MathJax-Span-19"><span class="mi" id="MathJax-Span-20" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="mi" id="MathJax-Span-21" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">t</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.27em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-1">\x_1, \x_2, \ldots, \x_t</script> and the corresponding output vectors <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-22" style="width: 6.104em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.489em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.517em, 1005.49em, 2.541em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-23"><span class="msubsup" id="MathJax-Span-24"><span style="display: inline-block; position: relative; width: 1.108em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-25"><span class="mrow" id="MathJax-Span-26"><span class="mi" id="MathJax-Span-27" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="mn" id="MathJax-Span-28" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-29" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-30" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.108em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-31"><span class="mrow" id="MathJax-Span-32"><span class="mi" id="MathJax-Span-33" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="mn" id="MathJax-Span-34" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-35" style="font-family: NeoEulerMathJax_Main;">,</span><span class="mo" id="MathJax-Span-36" style="font-family: NeoEulerMathJax_Main; padding-left: 0.166em;">…</span><span class="mo" id="MathJax-Span-37" style="font-family: NeoEulerMathJax_Main; padding-left: 0.166em;">,</span><span class="msubsup" id="MathJax-Span-38" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.026em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-39"><span class="mrow" id="MathJax-Span-40"><span class="mi" id="MathJax-Span-41" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="mi" id="MathJax-Span-42" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">t</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.361em; border-left: 0px solid; width: 0px; height: 0.957em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-2">\y_1, \y_2, \ldots, \y_t</script>. The vectors all have dimension <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-43" style="width: 0.657em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.58em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-44"><span class="mi" id="MathJax-Span-45" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-3">k</script>.</p>

<p>To produce output vector <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-46" style="width: 1.108em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.99em, 2.5em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-47"><span class="msubsup" id="MathJax-Span-48"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-49"><span class="mrow" id="MathJax-Span-50"><span class="mi" id="MathJax-Span-51" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="texatom" id="MathJax-Span-52"><span class="mrow" id="MathJax-Span-53"><span class="mstyle" id="MathJax-Span-54" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-55" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-56" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.361em; border-left: 0px solid; width: 0px; height: 0.957em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-4">\y_\rc{i}</script>, the self attention operation simply takes <em>a weighted average over all the input vectors</em></p>
<p><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-57" style="width: 7.25em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.513em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.067em, 1006.51em, 3.606em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-58"><span class="msubsup" id="MathJax-Span-59"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-60"><span class="mrow" id="MathJax-Span-61"><span class="mi" id="MathJax-Span-62" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="texatom" id="MathJax-Span-63"><span class="mrow" id="MathJax-Span-64"><span class="mstyle" id="MathJax-Span-65" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-66" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-67" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-68" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="munderover" id="MathJax-Span-69" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(2.95em, 1001.35em, 4.588em, -999.998em); top: -4.011em; left: 0em;"><span class="mo" id="MathJax-Span-70" style="font-family: NeoEulerMathJax_Size1; vertical-align: -0.244em;">∑</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.17em, 4.384em, -999.998em); top: -2.905em; left: 0.616em;"><span class="texatom" id="MathJax-Span-71"><span class="mrow" id="MathJax-Span-72"><span class="texatom" id="MathJax-Span-73"><span class="mrow" id="MathJax-Span-74"><span class="mstyle" id="MathJax-Span-75" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-76" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-77" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-78" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-79" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.821em;"><span class="texatom" id="MathJax-Span-80"><span class="mrow" id="MathJax-Span-81"><span class="texatom" id="MathJax-Span-82"><span class="mrow" id="MathJax-Span-83"><span class="mstyle" id="MathJax-Span-84" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-85" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-86" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-87"><span class="mrow" id="MathJax-Span-88"><span class="mstyle" id="MathJax-Span-89" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-90" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-91" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-92"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-93"><span class="mrow" id="MathJax-Span-94"><span class="mi" id="MathJax-Span-95" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-96"><span class="mrow" id="MathJax-Span-97"><span class="mstyle" id="MathJax-Span-98" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-99" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-100" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mspace" id="MathJax-Span-101" style="height: 0em; vertical-align: 0em; width: 0.166em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-102" style=""><span style="font-size: 90%;">.</span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.543em; border-left: 0px solid; width: 0px; height: 2.639em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-5">
\y_\rc{i} = \sum_{\gc{j}} w_{\rc{i}\gc{j}} \x_\gc{j} \p
</script></p>

<p>Where <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-103" style="width: 0.371em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.33em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.21em, 2.5em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-104"><span class="texatom" id="MathJax-Span-105"><span class="mrow" id="MathJax-Span-106"><span class="mstyle" id="MathJax-Span-107" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-108" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-109" style="font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.093em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-6">\gc{j}</script> indexes over the whole sequence and the weights sum to one over all <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-110" style="width: 0.371em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.33em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.21em, 2.5em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-111"><span class="texatom" id="MathJax-Span-112"><span class="mrow" id="MathJax-Span-113"><span class="mstyle" id="MathJax-Span-114" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-115" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-116" style="font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.093em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-7">\gc{j}</script>. The weight <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-117" style="width: 1.558em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.517em, 1001.39em, 2.541em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-118"><span class="msubsup" id="MathJax-Span-119"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-120" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.821em;"><span class="texatom" id="MathJax-Span-121"><span class="mrow" id="MathJax-Span-122"><span class="texatom" id="MathJax-Span-123"><span class="mrow" id="MathJax-Span-124"><span class="mstyle" id="MathJax-Span-125" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-126" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-127" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-128"><span class="mrow" id="MathJax-Span-129"><span class="mstyle" id="MathJax-Span-130" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-131" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-132" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.407em; border-left: 0px solid; width: 0px; height: 0.957em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-8">w_{\rc{i}\gc{j}}</script> is not a parameter, as in a normal neural net, but it is <em>derived</em> from a function over <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-133" style="width: 0.985em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.86em, 2.377em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-134"><span class="msubsup" id="MathJax-Span-135"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-136"><span class="mrow" id="MathJax-Span-137"><span class="mi" id="MathJax-Span-138" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-139"><span class="mrow" id="MathJax-Span-140"><span class="mstyle" id="MathJax-Span-141" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-142" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-143" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.225em; border-left: 0px solid; width: 0px; height: 0.82em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-9">\x_\rc{i}</script> and <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-144" style="width: 0.985em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.86em, 2.541em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-145"><span class="msubsup" id="MathJax-Span-146"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-147"><span class="mrow" id="MathJax-Span-148"><span class="mi" id="MathJax-Span-149" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-150"><span class="mrow" id="MathJax-Span-151"><span class="mstyle" id="MathJax-Span-152" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-153" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-154" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.407em; border-left: 0px solid; width: 0px; height: 1.002em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-10">\x_\gc{j}</script>. The simplest option for this function is the dot product:</p>
<p><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-155" style="width: 5.858em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.285em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.108em, 1005.28em, 2.746em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-156"><span class="msubsup" id="MathJax-Span-157"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-158" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.483em, 1000.33em, 4.097em, -999.998em); top: -4.339em; left: 0.821em;"><span class="mo" id="MathJax-Span-159" style="font-size: 70.7%; font-family: NeoEulerMathJax_Variants;">′</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.58em, 4.302em, -999.998em); top: -3.683em; left: 0.821em;"><span class="texatom" id="MathJax-Span-160"><span class="mrow" id="MathJax-Span-161"><span class="texatom" id="MathJax-Span-162"><span class="mrow" id="MathJax-Span-163"><span class="mstyle" id="MathJax-Span-164" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-165" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-166" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-167"><span class="mrow" id="MathJax-Span-168"><span class="mstyle" id="MathJax-Span-169" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-170" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-171" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-172" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="msubsup" id="MathJax-Span-173" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 1.353em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.86em, 4.302em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-174"><span class="mrow" id="MathJax-Span-175"><span class="msubsup" id="MathJax-Span-176"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-177"><span class="mrow" id="MathJax-Span-178"><span class="mi" id="MathJax-Span-179" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-180"><span class="mrow" id="MathJax-Span-181"><span class="mstyle" id="MathJax-Span-182" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-183" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-184" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -4.421em; left: 0.862em;"><span class="mi" id="MathJax-Span-185" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-186"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-187"><span class="mrow" id="MathJax-Span-188"><span class="mi" id="MathJax-Span-189" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-190"><span class="mrow" id="MathJax-Span-191"><span class="mstyle" id="MathJax-Span-192" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-193" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-194" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mspace" id="MathJax-Span-195" style="height: 0em; vertical-align: 0em; width: 0.166em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-196" style=""><span style="font-size: 90%;">.</span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.639em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-11">
w'_{\rc{i}\gc{j}} = {\x_\rc{i}}^T\x_\gc{j} \p
</script></p>
<aside>Note that <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-197" style="width: 0.982em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.893em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.516em, 1000.89em, 2.407em, -999.998em); top: -2.135em; left: 0em;"><span class="mrow" id="MathJax-Span-198"><span class="msubsup" id="MathJax-Span-199"><span style="display: inline-block; position: relative; width: 0.893em; height: 0px;"><span style="position: absolute; clip: rect(3.386em, 1000.54em, 4.143em, -999.998em); top: -4.005em; left: 0em;"><span class="texatom" id="MathJax-Span-200"><span class="mrow" id="MathJax-Span-201"><span class="mi" id="MathJax-Span-202" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -3.871em; left: 0.537em;"><span class="texatom" id="MathJax-Span-203"><span class="mrow" id="MathJax-Span-204"><span class="mstyle" id="MathJax-Span-205" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-206" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-207" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.139em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.195em; border-left: 0px solid; width: 0px; height: 0.843em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-12">\x_\rc{i}</script> is the input vector at the same position as the current output vector <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-208" style="width: 1.115em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.982em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.516em, 1000.98em, 2.54em, -999.998em); top: -2.135em; left: 0em;"><span class="mrow" id="MathJax-Span-209"><span class="msubsup" id="MathJax-Span-210"><span style="display: inline-block; position: relative; width: 0.982em; height: 0px;"><span style="position: absolute; clip: rect(3.386em, 1000.54em, 4.366em, -999.998em); top: -4.005em; left: 0em;"><span class="texatom" id="MathJax-Span-211"><span class="mrow" id="MathJax-Span-212"><span class="mi" id="MathJax-Span-213" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span><span style="position: absolute; top: -3.738em; left: 0.67em;"><span class="texatom" id="MathJax-Span-214"><span class="mrow" id="MathJax-Span-215"><span class="mstyle" id="MathJax-Span-216" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-217" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-218" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.01em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.139em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.343em; border-left: 0px solid; width: 0px; height: 0.942em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-13">\y_\rc{i}</script>. For the next output vector, we get an entirely new series of dot products, and a different weighted sum.</aside>

<p>The dot product gives us a value anywhere between negative and positive infinity, so we apply a softmax to map the values to <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-219" style="width: 2.254em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.009em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1001.89em, 2.459em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-220"><span class="mo" id="MathJax-Span-221" style="font-family: NeoEulerMathJax_Main;">[</span><span class="mn" id="MathJax-Span-222" style="font-family: NeoEulerMathJax_Main;">0</span><span class="mo" id="MathJax-Span-223" style="font-family: NeoEulerMathJax_Main;">,</span><span class="mn" id="MathJax-Span-224" style="font-family: NeoEulerMathJax_Main; padding-left: 0.166em;">1</span><span class="mo" id="MathJax-Span-225" style="font-family: NeoEulerMathJax_Main;">]</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.27em; border-left: 0px solid; width: 0px; height: 1.139em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-14">[0, 1]</script> and to ensure that they sum to 1 over the whole sequence:</p>

<p><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-226" style="width: 8.888em; display: inline-block;"><span style="display: inline-block; position: relative; width: 7.987em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(0.166em, 1007.99em, 3.565em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-227"><span class="msubsup" id="MathJax-Span-228"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-229" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.821em;"><span class="texatom" id="MathJax-Span-230"><span class="mrow" id="MathJax-Span-231"><span class="texatom" id="MathJax-Span-232"><span class="mrow" id="MathJax-Span-233"><span class="mstyle" id="MathJax-Span-234" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-235" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-236" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-237"><span class="mrow" id="MathJax-Span-238"><span class="mstyle" id="MathJax-Span-239" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-240" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-241" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-242" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="mfrac" id="MathJax-Span-243" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 4.67em; height: 0px; margin-right: 0.125em; margin-left: 0.125em;"><span style="position: absolute; clip: rect(2.991em, 1003.03em, 4.629em, -999.998em); top: -4.953em; left: 50%; margin-left: -1.513em;"><span class="mrow" id="MathJax-Span-244"><span class="mtext" id="MathJax-Span-245" style=""><span style="font-size: 90%;">exp&nbsp;</span></span><span class="msubsup" id="MathJax-Span-246"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-247" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.483em, 1000.33em, 4.097em, -999.998em); top: -4.339em; left: 0.821em;"><span class="mo" id="MathJax-Span-248" style="font-size: 70.7%; font-family: NeoEulerMathJax_Variants;">′</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.58em, 4.302em, -999.998em); top: -3.683em; left: 0.821em;"><span class="texatom" id="MathJax-Span-249"><span class="mrow" id="MathJax-Span-250"><span class="texatom" id="MathJax-Span-251"><span class="mrow" id="MathJax-Span-252"><span class="mstyle" id="MathJax-Span-253" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-254" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-255" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-256"><span class="mrow" id="MathJax-Span-257"><span class="mstyle" id="MathJax-Span-258" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-259" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-260" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(2.991em, 1004.55em, 4.629em, -999.998em); top: -3.151em; left: 50%; margin-left: -2.25em;"><span class="mrow" id="MathJax-Span-261"><span class="munderover" id="MathJax-Span-262"><span style="display: inline-block; position: relative; width: 1.353em; height: 0px;"><span style="position: absolute; clip: rect(3.155em, 1000.99em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="mo" id="MathJax-Span-263" style="font-family: NeoEulerMathJax_Operators; vertical-align: -0.203em;">∑</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 1.067em;"><span class="texatom" id="MathJax-Span-264"><span class="mrow" id="MathJax-Span-265"><span class="mstyle" id="MathJax-Span-266" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-267" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-268" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mtext" id="MathJax-Span-269" style="padding-left: 0.166em;"><span style="font-size: 90%;">exp&nbsp;</span></span><span class="msubsup" id="MathJax-Span-270"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-271" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.483em, 1000.33em, 4.097em, -999.998em); top: -4.339em; left: 0.821em;"><span class="mo" id="MathJax-Span-272" style="font-size: 70.7%; font-family: NeoEulerMathJax_Variants;">′</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.58em, 4.302em, -999.998em); top: -3.683em; left: 0.821em;"><span class="texatom" id="MathJax-Span-273"><span class="mrow" id="MathJax-Span-274"><span class="texatom" id="MathJax-Span-275"><span class="mrow" id="MathJax-Span-276"><span class="mstyle" id="MathJax-Span-277" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-278" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-279" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-280"><span class="mrow" id="MathJax-Span-281"><span class="mstyle" id="MathJax-Span-282" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-283" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-284" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(0.903em, 1004.67em, 1.19em, -999.998em); top: -1.267em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.5px solid; width: 4.67em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.067em;"></span></span></span></span><span class="mspace" id="MathJax-Span-285" style="height: 0em; vertical-align: 0em; width: 0.166em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-286" style=""><span style="font-size: 90%;">.</span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.498em; border-left: 0px solid; width: 0px; height: 3.593em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-15">
w_{\rc{i}\gc{j}} = \frac{\text{exp } w'_{\rc{i}\gc{j}}}{\sum_\gc{j} \text{exp }w'_{\rc{i}\gc{j}}} \p
</script></p>

<p>And that’s the basic operation of self attention.</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/self-attention.svg">
<figcaption> A visual illustration of basic self-attention. Note that the softmax operation over the <span class="rc">weights</span> is not illustrated.
</figcaption>
</figure>

<p>A few other ingredients are needed for a complete transformer, which we’ll discuss later, but this is the fundamental operation. More importantly, this is the only operation in the whole architecture that propagates information <em>between</em> vectors. Every other operation in the transformer is applied to each vector in the input sequence without interactions between vectors.</p>

<h3 id="understanding-why-self-attention-works">Understanding why self-attention works</h3>

<p>Despite its simplicity, it’s not immediately obvious why self-attention should work so well. To build up some intuition, let’s look first at the standard approach to <em>movie recommendation</em>.</p>

<p>Let’s say you run a movie rental business and you have some movies, and some users, and you would like to recommend movies to your users that they are likely to enjoy.</p>

<p>One way to go about this, is to create manual features for your movies, such as how much romance there is in the movie, and how much action, and then to design corresponding features for your users: how much they enjoy romantic movies and how much they enjoy action-based movies. If you did this, the dot product between the two feature vectors would give you a score for how well the attributes of the movie match what the user enjoys.</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/dot-product.svg">
</figure>

<p>If the signs of a feature match for the user and the movie—the movie is romantic and the user loves romance or the movie is <em>unromantic</em> and the user hates romance—then the resulting dot product gets a positive term for that feature. If the signs don’t match—the movie is romantic and the user hates romance or vice versa—the corresponding term is negative.</p>

<p>Furthermore, the <em>magnitudes</em> of the features indicate how much the feature should contribute to the total score: a movie may be a little romantic, but not in a noticeable way, or a user may simply prefer no romance, but be largely ambivalent.</p>

<p>Of course, gathering such features is not practical. Annotating a database of millions of movies is very costly, and annotating users with their likes and dislikes is pretty much impossible.</p>

<p>What happens instead is that we make the movie features and user features <em>parameters</em> of the model. We then ask users for a small number of movies that they like and we optimize the user features and movie features so that their dot product matches the known likes.</p>

<p>Even though we don’t tell the model what any of the features should mean, in practice, it turns out that after training the features do actually reflect meaningful semantics about the movie content.</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/movie-features.svg">
<figcaption> The first two learned features from a basic matrix factorization model. The model had no access to any information about the content of the movies, only which users liked them. Note that movies are arranged from low-brow to high-brow horizontally, and from mainstream to quirky vertically. From [4]. 
</figcaption>
</figure>

<aside>See <a href="https://youtu.be/TwCYexIpqUU">this lecture</a> for more details on recommender systems. For now, this suffices as an explanation of how the dot product helps us to represent objects and their relations.</aside>

<p>This is the basic principle at work in the self-attention. Let’s say we are faced with a sequence of words. To apply self-attention, we simply assign each word <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-287" style="width: 0.452em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.412em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.394em, 1000.41em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-288"><span class="texatom" id="MathJax-Span-289"><span class="mrow" id="MathJax-Span-290"><span class="mstyle" id="MathJax-Span-291" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-292" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-293" style="font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">t</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.775em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-16">\bc{t}</script> in our vocabulary an <em>embedding vector</em> <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-294" style="width: 1.026em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.9em, 2.377em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-295"><span class="msubsup" id="MathJax-Span-296"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-297"><span class="mrow" id="MathJax-Span-298"><span class="mi" id="MathJax-Span-299" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-300"><span class="mrow" id="MathJax-Span-301"><span class="mstyle" id="MathJax-Span-302" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-303" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-304" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">t</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.225em; border-left: 0px solid; width: 0px; height: 0.82em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-17">\v_\bc{t}</script> (the values of which we’ll learn). This is what’s known as an <em>embedding layer</em> in sequence modeling. It turns the word sequence 
<span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-18-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-305" style="width: 12.697em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.427em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.108em, 1011.43em, 2.459em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-306"><span class="texatom" id="MathJax-Span-307"><span class="mrow" id="MathJax-Span-308"><span class="mstyle" id="MathJax-Span-309" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-310" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-311" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">the</span></span></span></span></span></span><span class="mo" id="MathJax-Span-312" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-313" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-314"><span class="mstyle" id="MathJax-Span-315" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-316" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-317" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">cat</span></span></span></span></span></span><span class="mo" id="MathJax-Span-318" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-319" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-320"><span class="mstyle" id="MathJax-Span-321" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-322" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-323" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">walks</span></span></span></span></span></span><span class="mo" id="MathJax-Span-324" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-325" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-326"><span class="mstyle" id="MathJax-Span-327" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-328" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-329" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">on</span></span></span></span></span></span><span class="mo" id="MathJax-Span-330" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-331" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-332"><span class="mstyle" id="MathJax-Span-333" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-334" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-335" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">the</span></span></span></span></span></span><span class="mo" id="MathJax-Span-336" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-337" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-338"><span class="mstyle" id="MathJax-Span-339" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-340" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-341" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">street</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.27em; border-left: 0px solid; width: 0px; height: 1.32em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-18">\bc{\text{the}}, \bc{\text{cat}}, \bc{\text{walks}}, \bc{\text{on}}, \bc{\text{the}}, \bc{\text{street}}</script>
into the vector sequence</p>

<p><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-19-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-342" style="width: 14.294em; display: inline-block;"><span style="display: inline-block; position: relative; width: 12.86em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.108em, 1012.86em, 2.746em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-343"><span class="msubsup" id="MathJax-Span-344"><span style="display: inline-block; position: relative; width: 1.517em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-345"><span class="mrow" id="MathJax-Span-346"><span class="mi" id="MathJax-Span-347" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-348"><span class="mrow" id="MathJax-Span-349"><span class="mstyle" id="MathJax-Span-350" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-351" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-352" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">the</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-353" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-354" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-355"><span class="mrow" id="MathJax-Span-356"><span class="mi" id="MathJax-Span-357" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-358"><span class="mrow" id="MathJax-Span-359"><span class="mstyle" id="MathJax-Span-360" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-361" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-362" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">cat</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-363" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-364" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 2.213em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-365"><span class="mrow" id="MathJax-Span-366"><span class="mi" id="MathJax-Span-367" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-368"><span class="mrow" id="MathJax-Span-369"><span class="mstyle" id="MathJax-Span-370" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-371" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-372" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">walks</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-373" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-374" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.353em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-375"><span class="mrow" id="MathJax-Span-376"><span class="mi" id="MathJax-Span-377" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-378"><span class="mrow" id="MathJax-Span-379"><span class="mstyle" id="MathJax-Span-380" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-381" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-382" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">on</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-383" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-384" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.517em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-385"><span class="mrow" id="MathJax-Span-386"><span class="mi" id="MathJax-Span-387" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-388"><span class="mrow" id="MathJax-Span-389"><span class="mstyle" id="MathJax-Span-390" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-391" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-392" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">the</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-393" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-394" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 2.213em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-395"><span class="mrow" id="MathJax-Span-396"><span class="mi" id="MathJax-Span-397" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-398"><span class="mrow" id="MathJax-Span-399"><span class="mstyle" id="MathJax-Span-400" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-401" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-402" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">street</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mspace" id="MathJax-Span-403" style="height: 0em; vertical-align: 0em; width: 0.166em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-404" style=""><span style="font-size: 90%;">.</span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.639em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-19">\v_\bc{\text{the}}, \v_\bc{\text{cat}}, \v_\bc{\text{walks}}, \v_\bc{\text{on}}, \v_\bc{\text{the}}, \v_\bc{\text{street}} \p
</script></p>

<p>If we feed this sequence into a self-attention layer, the output is another sequence of vectors 
<span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-20-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-405" style="width: 14.662em; display: inline-block;"><span style="display: inline-block; position: relative; width: 13.188em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.517em, 1013.19em, 2.746em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-406"><span class="msubsup" id="MathJax-Span-407"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-408"><span class="mrow" id="MathJax-Span-409"><span class="mi" id="MathJax-Span-410" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-411"><span class="mrow" id="MathJax-Span-412"><span class="mstyle" id="MathJax-Span-413" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-414" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-415" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">the</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-416" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-417" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.558em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-418"><span class="mrow" id="MathJax-Span-419"><span class="mi" id="MathJax-Span-420" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-421"><span class="mrow" id="MathJax-Span-422"><span class="mstyle" id="MathJax-Span-423" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-424" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-425" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">cat</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-426" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-427" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 2.336em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-428"><span class="mrow" id="MathJax-Span-429"><span class="mi" id="MathJax-Span-430" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-431"><span class="mrow" id="MathJax-Span-432"><span class="mstyle" id="MathJax-Span-433" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-434" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-435" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">walks</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-436" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-437" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.476em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-438"><span class="mrow" id="MathJax-Span-439"><span class="mi" id="MathJax-Span-440" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-441"><span class="mrow" id="MathJax-Span-442"><span class="mstyle" id="MathJax-Span-443" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-444" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-445" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">on</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-446" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-447" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-448"><span class="mrow" id="MathJax-Span-449"><span class="mi" id="MathJax-Span-450" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-451"><span class="mrow" id="MathJax-Span-452"><span class="mstyle" id="MathJax-Span-453" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-454" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-455" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">the</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-456" style="font-family: NeoEulerMathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-457" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 2.336em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-458"><span class="mrow" id="MathJax-Span-459"><span class="mi" id="MathJax-Span-460" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-461"><span class="mrow" id="MathJax-Span-462"><span class="mstyle" id="MathJax-Span-463" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-464" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-465" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">street</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-20">\y_\bc{\text{the}}, \y_\bc{\text{cat}}, \y_\bc{\text{walks}}, \y_\bc{\text{on}}, \y_\bc{\text{the}}, \y_\bc{\text{street}}
</script>
where <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-21-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-466" style="width: 1.722em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.558em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1001.56em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-467"><span class="msubsup" id="MathJax-Span-468"><span style="display: inline-block; position: relative; width: 1.558em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-469"><span class="mrow" id="MathJax-Span-470"><span class="mi" id="MathJax-Span-471" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-472"><span class="mrow" id="MathJax-Span-473"><span class="mstyle" id="MathJax-Span-474" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-475" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-476" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">cat</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-21">\y_\bc{\text{cat}}</script> is a weighted sum over all the embedding vectors in the first sequence, weighted by their (normalized) dot-product with <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-22-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-477" style="width: 1.599em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1001.43em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-478"><span class="msubsup" id="MathJax-Span-479"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-480"><span class="mrow" id="MathJax-Span-481"><span class="mi" id="MathJax-Span-482" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-483"><span class="mrow" id="MathJax-Span-484"><span class="mstyle" id="MathJax-Span-485" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-486" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-487" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">cat</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-22">\v_\bc{\text{cat}}</script>.</p>

<p>Since we are <em>learning</em> what the values in <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-23-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-488" style="width: 1.026em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.9em, 2.377em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-489"><span class="msubsup" id="MathJax-Span-490"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-491"><span class="mrow" id="MathJax-Span-492"><span class="mi" id="MathJax-Span-493" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-494"><span class="mrow" id="MathJax-Span-495"><span class="mstyle" id="MathJax-Span-496" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-497" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-498" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">t</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.225em; border-left: 0px solid; width: 0px; height: 0.82em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-23">\v_\bc{t}</script> should be, how "related" two words are is entirely determined by the task. In most cases, the definite article <span class="bc">the</span> is not very relevant to the interpretation of the other words in the sentence; therefore, we will likely end up with an embedding <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-24-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-499" style="width: 1.681em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.517em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1001.52em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-500"><span class="msubsup" id="MathJax-Span-501"><span style="display: inline-block; position: relative; width: 1.517em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-502"><span class="mrow" id="MathJax-Span-503"><span class="mi" id="MathJax-Span-504" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-505"><span class="mrow" id="MathJax-Span-506"><span class="mstyle" id="MathJax-Span-507" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-508" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-509" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">the</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-24">\v_\bc{\text{the}}</script> that has a low or negative dot product with all other words. On the other hand, to interpret what <span class="bc">walks</span> means in this sentence, it's very helpful to work out <em>who</em> is doing the walking. This is likely expressed by a noun, so for nouns like <span class="bc">cat</span> and verbs like <span class="bc">walks</span>, we will likely learn embeddings <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-25-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-510" style="width: 1.599em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1001.43em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-511"><span class="msubsup" id="MathJax-Span-512"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-513"><span class="mrow" id="MathJax-Span-514"><span class="mi" id="MathJax-Span-515" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-516"><span class="mrow" id="MathJax-Span-517"><span class="mstyle" id="MathJax-Span-518" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-519" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-520" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">cat</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-25">\v_\bc{\text{cat}}</script> and <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-26-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-521" style="width: 2.459em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.213em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1002.21em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-522"><span class="msubsup" id="MathJax-Span-523"><span style="display: inline-block; position: relative; width: 2.213em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-524"><span class="mrow" id="MathJax-Span-525"><span class="mi" id="MathJax-Span-526" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-527"><span class="mrow" id="MathJax-Span-528"><span class="mstyle" id="MathJax-Span-529" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-530" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-531" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">walks</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-26">\v_\bc{\text{walks}}</script> that have a high, positive dot product together.</p>

<p>This is the basic intuition behind self-attention. The dot product expresses how related two vectors in the input sequence are, with “related” defined by the learning task, and the output vectors are weighted sums over the whole input sequence, with the weights determined by these dot products.</p>

<p>Before we move on, it’s worthwhile to note the following properties, which are unusual for a sequence-to-sequence operation:</p>

<ul>
  <li>There are no parameters (yet). What the basic self-attention actually does is entirely determined by whatever mechanism creates the input sequence. Upstream mechanisms, like an embedding layer, drive the self-attention by learning representations with particular dot products (although we’ll add a few parameters later).</li>
  <li>Self attention sees its input as a <em>set</em>, not a sequence. If we permute the input sequence, the output sequence will be exactly the same, except permuted also (i.e. self-attention is <em>permutation  equivariant</em>).  We will mitigate this somewhat when we build the full transformer, but the self-attention by itself actually <em>ignores</em> the sequential nature of the input.</li>
</ul>

<h3 id="in-pytorch-basic-self-attention">In Pytorch: basic self-attention</h3>

<p>What I cannot create, I do not understand, as Feynman said. So we’ll build a simple transformer as we go along. We’ll start by implementing this basic self-attention operation in Pytorch.</p>

<p>The first thing we should do is work out how to express the self attention in matrix multiplications. A naive implementation that loops over all vectors to compute the weights and outputs would be much too slow.</p>

<p>We’ll represent the input, a sequence of <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-27-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-532" style="width: 0.452em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.412em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.394em, 1000.41em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-533"><span class="mi" id="MathJax-Span-534" style="font-family: NeoEulerMathJax_Main;">t</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.775em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-27">t</script> vectors of dimension <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-28-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-535" style="width: 0.657em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.58em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-536"><span class="mi" id="MathJax-Span-537" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-28">k</script> as a <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-29-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-538" style="width: 0.452em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.412em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.394em, 1000.41em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-539"><span class="mi" id="MathJax-Span-540" style="font-family: NeoEulerMathJax_Main;">t</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.775em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-29">t</script> by <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-30-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-541" style="width: 0.657em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.58em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-542"><span class="mi" id="MathJax-Span-543" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-30">k</script> matrix <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-31-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-544" style="width: 0.821em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.739em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.7em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-545"><span class="texatom" id="MathJax-Span-546"><span class="mrow" id="MathJax-Span-547"><span class="mi" id="MathJax-Span-548" style="font-family: NeoEulerMathJax_Normal;">𝐗</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.911em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-31">\X</script>. Including a minibatch dimension <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-32-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-549" style="width: 0.657em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.49em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-550"><span class="mi" id="MathJax-Span-551" style="font-family: NeoEulerMathJax_Main;">b</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-32">b</script>, gives us an input tensor of size <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-33-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-552" style="width: 3.606em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.237em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1003.11em, 2.459em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-553"><span class="mo" id="MathJax-Span-554" style="font-family: NeoEulerMathJax_Main;">(</span><span class="mi" id="MathJax-Span-555" style="font-family: NeoEulerMathJax_Main;">b</span><span class="mo" id="MathJax-Span-556" style="font-family: NeoEulerMathJax_Main;">,</span><span class="mi" id="MathJax-Span-557" style="font-family: NeoEulerMathJax_Main; padding-left: 0.166em;">t</span><span class="mo" id="MathJax-Span-558" style="font-family: NeoEulerMathJax_Main;">,</span><span class="mi" id="MathJax-Span-559" style="font-family: NeoEulerMathJax_Main; padding-left: 0.166em;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-560" style="font-family: NeoEulerMathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.27em; border-left: 0px solid; width: 0px; height: 1.139em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-33">(b, t, k)</script>.</p>

<p>The set of all raw dot products <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-34-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-561" style="width: 1.558em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1001.39em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-562"><span class="msubsup" id="MathJax-Span-563"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-564" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.483em, 1000.33em, 4.097em, -999.998em); top: -4.339em; left: 0.821em;"><span class="mo" id="MathJax-Span-565" style="font-size: 70.7%; font-family: NeoEulerMathJax_Variants;">′</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.58em, 4.302em, -999.998em); top: -3.683em; left: 0.821em;"><span class="texatom" id="MathJax-Span-566"><span class="mrow" id="MathJax-Span-567"><span class="texatom" id="MathJax-Span-568"><span class="mrow" id="MathJax-Span-569"><span class="mstyle" id="MathJax-Span-570" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-571" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-572" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-573"><span class="mrow" id="MathJax-Span-574"><span class="mstyle" id="MathJax-Span-575" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-576" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-577" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.411em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-34">w'_{\rc{i}\gc{j}}</script> forms a matrix, which we can compute simply by multiplying <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-35-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-578" style="width: 0.821em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.739em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.7em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-579"><span class="texatom" id="MathJax-Span-580"><span class="mrow" id="MathJax-Span-581"><span class="mi" id="MathJax-Span-582" style="font-family: NeoEulerMathJax_Normal;">𝐗</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.911em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-35">\X</script> by its transpose:
</p>

<pre><code class="hljs makefile">import torch
import torch.nn.functional as F

<span class="hljs-comment"># assume we have some tensor x with size (b, t, k)</span>
x = ...

raw_weights = torch.bmm(x, x.transpose(1, 2))
<span class="hljs-comment"># - torch.bmm is a batched matrix multiplication. It </span>
<span class="hljs-comment">#   applies matrix multiplication over batches of </span>
<span class="hljs-comment">#   matrices.</span></code></pre>

<p>Then, to turn the raw weights <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-36-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-583" style="width: 1.558em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1001.39em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-584"><span class="msubsup" id="MathJax-Span-585"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-586" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.483em, 1000.33em, 4.097em, -999.998em); top: -4.339em; left: 0.821em;"><span class="mo" id="MathJax-Span-587" style="font-size: 70.7%; font-family: NeoEulerMathJax_Variants;">′</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.58em, 4.302em, -999.998em); top: -3.683em; left: 0.821em;"><span class="texatom" id="MathJax-Span-588"><span class="mrow" id="MathJax-Span-589"><span class="texatom" id="MathJax-Span-590"><span class="mrow" id="MathJax-Span-591"><span class="mstyle" id="MathJax-Span-592" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-593" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-594" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-595"><span class="mrow" id="MathJax-Span-596"><span class="mstyle" id="MathJax-Span-597" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-598" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-599" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.411em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-36">w'_{\rc{i}\gc{j}}</script> into positive values that sum to one, we apply a <em>row-wise</em> softmax:</p>
<pre><code class="hljs ini"><span class="hljs-attr">weights</span> = F.softmax(raw_weights, dim=<span class="hljs-number">2</span>)</code></pre>

<p>Finally, to compute the output sequence, we just multiply the weight matrix by <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-37-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-600" style="width: 0.821em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.739em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.7em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-601"><span class="texatom" id="MathJax-Span-602"><span class="mrow" id="MathJax-Span-603"><span class="mi" id="MathJax-Span-604" style="font-family: NeoEulerMathJax_Normal;">𝐗</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.911em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-37">\X</script>. This results in a batch of output matrices <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-38-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-605" style="width: 0.739em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.657em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.66em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-606"><span class="texatom" id="MathJax-Span-607"><span class="mrow" id="MathJax-Span-608"><span class="mi" id="MathJax-Span-609" style="font-family: NeoEulerMathJax_Normal;">𝐘<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.084em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-38">\Y</script> of size <code>(b, t, k)</code> whose rows are weighted sums over the rows of <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-39-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-610" style="width: 0.821em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.739em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.7em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-611"><span class="texatom" id="MathJax-Span-612"><span class="mrow" id="MathJax-Span-613"><span class="mi" id="MathJax-Span-614" style="font-family: NeoEulerMathJax_Normal;">𝐗</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.911em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-39">\X</script>.</p>
<pre><code class="hljs ini"><span class="hljs-attr">y</span> = torch.bmm(weights, x)</code></pre>

<p>That’s all. Two matrix multiplications and one softmax gives us a basic self-attention.</p>

<h3 id="additional-tricks">Additional tricks</h3>

<p>The actual self-attention used in modern transformers relies on three additional tricks.</p>

<h4 id="1-queries-keys-and-values">1) Queries, keys and values</h4>

<p>Every input vector <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-40-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-615" style="width: 0.985em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.86em, 2.377em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-616"><span class="msubsup" id="MathJax-Span-617"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-618"><span class="mrow" id="MathJax-Span-619"><span class="mi" id="MathJax-Span-620" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-621"><span class="mrow" id="MathJax-Span-622"><span class="mstyle" id="MathJax-Span-623" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-624" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-625" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.225em; border-left: 0px solid; width: 0px; height: 0.82em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-40">\x_\rc{i}</script> is used in three different ways in the self attention operation:</p>
<ul>
  <li>It is compared to every other vector to establish the weights for its own output <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-41-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-626" style="width: 1.108em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.99em, 2.5em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-627"><span class="msubsup" id="MathJax-Span-628"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-629"><span class="mrow" id="MathJax-Span-630"><span class="mi" id="MathJax-Span-631" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="texatom" id="MathJax-Span-632"><span class="mrow" id="MathJax-Span-633"><span class="mstyle" id="MathJax-Span-634" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-635" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-636" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.361em; border-left: 0px solid; width: 0px; height: 0.957em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-41">\y_\rc{i}</script></li>
  <li>It is compared to every other vector to establish the weights for the output  of the <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-42-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-637" style="width: 0.371em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.33em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.21em, 2.5em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-638"><span class="texatom" id="MathJax-Span-639"><span class="mrow" id="MathJax-Span-640"><span class="mstyle" id="MathJax-Span-641" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-642" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-643" style="font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.093em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-42">\gc{j}</script>-th vector <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-43-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-644" style="width: 1.108em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.99em, 2.664em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-645"><span class="msubsup" id="MathJax-Span-646"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-647"><span class="mrow" id="MathJax-Span-648"><span class="mi" id="MathJax-Span-649" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="texatom" id="MathJax-Span-650"><span class="mrow" id="MathJax-Span-651"><span class="mstyle" id="MathJax-Span-652" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-653" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-654" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.543em; border-left: 0px solid; width: 0px; height: 1.139em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-43">\y_\gc{j}</script></li>
  <li>It is used as part of the weighted sum to compute each output vector once the weights have been established.</li>
</ul>

<p>These roles are often called the <strong>query</strong>, the <strong>key</strong> and the <strong>value</strong> (we'll explain where these names come from later). 

In the basic self-attention we've seen so far, each input vector must play all three roles. We make its life a little easier by deriving new vectors for each role, by applying a linear transformation to the original input vector. In other words, we add three <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-44-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-655" style="width: 2.541em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.295em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1002.29em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-656"><span class="mi" id="MathJax-Span-657" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-658" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">×</span><span class="mi" id="MathJax-Span-659" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-44">k  \times k</script> weight matrices <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-45-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-660" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1001.64em, 2.541em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-661"><span class="msubsup" id="MathJax-Span-662"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-663"><span class="mrow" id="MathJax-Span-664"><span class="mi" id="MathJax-Span-665" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 1.108em;"><span class="mi" id="MathJax-Span-666" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">q</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.407em; border-left: 0px solid; width: 0px; height: 1.23em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-45">\W_q</script>, <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-46-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-667" style="width: 1.804em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.599em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1001.6em, 2.377em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-668"><span class="msubsup" id="MathJax-Span-669"><span style="display: inline-block; position: relative; width: 1.599em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-670"><span class="mrow" id="MathJax-Span-671"><span class="mi" id="MathJax-Span-672" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 1.108em;"><span class="mi" id="MathJax-Span-673" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.225em; border-left: 0px solid; width: 0px; height: 1.048em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-46">\W_k</script>,<span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-47-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-674" style="width: 1.722em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.558em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1001.56em, 2.377em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-675"><span class="msubsup" id="MathJax-Span-676"><span style="display: inline-block; position: relative; width: 1.558em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-677"><span class="mrow" id="MathJax-Span-678"><span class="mi" id="MathJax-Span-679" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 1.108em;"><span class="mi" id="MathJax-Span-680" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">v</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.225em; border-left: 0px solid; width: 0px; height: 1.048em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-47">\W_v</script> and compute three linear transformations of each <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-48-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-681" style="width: 0.985em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.517em, 1000.86em, 2.377em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-682"><span class="msubsup" id="MathJax-Span-683"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-684" style="font-family: NeoEulerMathJax_Main;">x</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-685"><span class="mrow" id="MathJax-Span-686"><span class="mstyle" id="MathJax-Span-687" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-688" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-689" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.225em; border-left: 0px solid; width: 0px; height: 0.775em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-48">x_\rc{i}</script>, for the three different parts of the self attention:
<span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-49-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-690" style="width: 20.149em; display: inline-block;"><span style="display: inline-block; position: relative; width: 18.143em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.149em, 1018.14em, 2.541em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-691"><span class="mtable" id="MathJax-Span-692"><span style="display: inline-block; position: relative; width: 17.815em; height: 0px; margin-right: 0.166em; margin-left: 0.166em;"><span style="position: absolute; clip: rect(3.36em, 1000.99em, 4.425em, -999.998em); top: -4.011em; left: 0em;"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.36em, 1000.99em, 4.425em, -999.998em); top: -4.011em; right: 0em;"><span class="mtd" id="MathJax-Span-693"><span class="mrow" id="MathJax-Span-694"><span class="msubsup" id="MathJax-Span-695"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.36em, 1000.58em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-696"><span class="mrow" id="MathJax-Span-697"><span class="mi" id="MathJax-Span-698" style="font-family: NeoEulerMathJax_Normal;">𝐪</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="texatom" id="MathJax-Span-699"><span class="mrow" id="MathJax-Span-700"><span class="mstyle" id="MathJax-Span-701" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-702" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-703" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.196em, 1003.77em, 4.466em, -999.998em); top: -4.011em; left: 0.985em;"><span style="display: inline-block; position: relative; width: 3.769em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1003.77em, 4.466em, -999.998em); top: -4.011em; left: 0em;"><span class="mtd" id="MathJax-Span-704"><span class="mrow" id="MathJax-Span-705"><span class="mi" id="MathJax-Span-706"></span><span class="mo" id="MathJax-Span-707" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="msubsup" id="MathJax-Span-708" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-709"><span class="mrow" id="MathJax-Span-710"><span class="mi" id="MathJax-Span-711" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 1.108em;"><span class="mi" id="MathJax-Span-712" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">q</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-713"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-714"><span class="mrow" id="MathJax-Span-715"><span class="mi" id="MathJax-Span-716" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-717"><span class="mrow" id="MathJax-Span-718"><span class="mstyle" id="MathJax-Span-719" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-720" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-721" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.196em, 1000.94em, 4.302em, -999.998em); top: -4.011em; left: 6.677em;"><span style="display: inline-block; position: relative; width: 0.944em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1000.94em, 4.302em, -999.998em); top: -4.011em; right: 0em;"><span class="mtd" id="MathJax-Span-722"><span class="mrow" id="MathJax-Span-723"><span class="msubsup" id="MathJax-Span-724"><span style="display: inline-block; position: relative; width: 0.944em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1000.62em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-725"><span class="mrow" id="MathJax-Span-726"><span class="mi" id="MathJax-Span-727" style="font-family: NeoEulerMathJax_Normal;">𝐤<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.616em;"><span class="texatom" id="MathJax-Span-728"><span class="mrow" id="MathJax-Span-729"><span class="mstyle" id="MathJax-Span-730" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-731" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-732" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.196em, 1003.73em, 4.302em, -999.998em); top: -4.011em; left: 7.619em;"><span style="display: inline-block; position: relative; width: 3.729em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1003.73em, 4.302em, -999.998em); top: -4.011em; left: 0em;"><span class="mtd" id="MathJax-Span-733"><span class="mrow" id="MathJax-Span-734"><span class="mi" id="MathJax-Span-735"></span><span class="mo" id="MathJax-Span-736" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="msubsup" id="MathJax-Span-737" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 1.599em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-738"><span class="mrow" id="MathJax-Span-739"><span class="mi" id="MathJax-Span-740" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 1.108em;"><span class="mi" id="MathJax-Span-741" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-742"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-743"><span class="mrow" id="MathJax-Span-744"><span class="mi" id="MathJax-Span-745" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-746"><span class="mrow" id="MathJax-Span-747"><span class="mstyle" id="MathJax-Span-748" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-749" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-750" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.86em, 4.302em, -999.998em); top: -4.011em; left: 13.27em;"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.86em, 4.302em, -999.998em); top: -4.011em; right: 0em;"><span class="mtd" id="MathJax-Span-751"><span class="mrow" id="MathJax-Span-752"><span class="msubsup" id="MathJax-Span-753"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-754"><span class="mrow" id="MathJax-Span-755"><span class="mi" id="MathJax-Span-756" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-757"><span class="mrow" id="MathJax-Span-758"><span class="mstyle" id="MathJax-Span-759" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-760" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-761" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.196em, 1003.69em, 4.302em, -999.998em); top: -4.011em; left: 14.13em;"><span style="display: inline-block; position: relative; width: 3.688em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1003.69em, 4.302em, -999.998em); top: -4.011em; left: 0em;"><span class="mtd" id="MathJax-Span-762"><span class="mrow" id="MathJax-Span-763"><span class="mi" id="MathJax-Span-764"></span><span class="mo" id="MathJax-Span-765" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="msubsup" id="MathJax-Span-766" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 1.558em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-767"><span class="mrow" id="MathJax-Span-768"><span class="mi" id="MathJax-Span-769" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 1.108em;"><span class="mi" id="MathJax-Span-770" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">v</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-771"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-772"><span class="mrow" id="MathJax-Span-773"><span class="mi" id="MathJax-Span-774" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-775"><span class="mrow" id="MathJax-Span-776"><span class="mstyle" id="MathJax-Span-777" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-778" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-779" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.407em; border-left: 0px solid; width: 0px; height: 1.32em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-49">
\begin{align*}
\q_\rc{i} &= \W_q\x_\rc{i} &
\k_\rc{i} &= \W_k\x_\rc{i} &
\v_\rc{i} &= \W_v\x_\rc{i} 
\end{align*}
</script>

<span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-50-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-780" style="width: 9.175em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.274em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(-1.104em, 1008.15em, 4.793em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-781"><span class="mtable" id="MathJax-Span-782"><span style="display: inline-block; position: relative; width: 7.946em; height: 0px; margin-right: 0.166em; margin-left: 0.166em;"><span style="position: absolute; clip: rect(2.377em, 1001.39em, 6.964em, -999.998em); top: -5.362em; left: 0em;"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.39em, 4.629em, -999.998em); top: -6.181em; right: 0em;"><span class="mtd" id="MathJax-Span-783"><span class="mrow" id="MathJax-Span-784"><span class="msubsup" id="MathJax-Span-785"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-786" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.483em, 1000.33em, 4.097em, -999.998em); top: -4.339em; left: 0.821em;"><span class="mo" id="MathJax-Span-787" style="font-size: 70.7%; font-family: NeoEulerMathJax_Variants;">′</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.58em, 4.302em, -999.998em); top: -3.683em; left: 0.821em;"><span class="texatom" id="MathJax-Span-788"><span class="mrow" id="MathJax-Span-789"><span class="texatom" id="MathJax-Span-790"><span class="mrow" id="MathJax-Span-791"><span class="mstyle" id="MathJax-Span-792" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-793" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-794" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-795"><span class="mrow" id="MathJax-Span-796"><span class="mstyle" id="MathJax-Span-797" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-798" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-799" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.442em, 1001.39em, 4.466em, -999.998em); top: -4.502em; right: 0em;"><span class="mtd" id="MathJax-Span-826"><span class="mrow" id="MathJax-Span-827"><span class="msubsup" id="MathJax-Span-828"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-829" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.821em;"><span class="texatom" id="MathJax-Span-830"><span class="mrow" id="MathJax-Span-831"><span class="texatom" id="MathJax-Span-832"><span class="mrow" id="MathJax-Span-833"><span class="mstyle" id="MathJax-Span-834" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-835" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-836" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-837"><span class="mrow" id="MathJax-Span-838"><span class="mstyle" id="MathJax-Span-839" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-840" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-841" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.99em, 4.425em, -999.998em); top: -2.783em; right: 0em;"><span class="mtd" id="MathJax-Span-864"><span class="mrow" id="MathJax-Span-865"><span class="msubsup" id="MathJax-Span-866"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-867"><span class="mrow" id="MathJax-Span-868"><span class="mi" id="MathJax-Span-869" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="texatom" id="MathJax-Span-870"><span class="mrow" id="MathJax-Span-871"><span class="mstyle" id="MathJax-Span-872" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-873" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-874" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 5.367em;"></span></span><span style="position: absolute; clip: rect(3.442em, 1006.43em, 9.339em, -999.998em); top: -6.632em; left: 1.394em;"><span style="display: inline-block; position: relative; width: 6.554em; height: 0px;"><span style="position: absolute; clip: rect(2.991em, 1003.65em, 4.466em, -999.998em); top: -6.181em; left: 0em;"><span class="mtd" id="MathJax-Span-800"><span class="mrow" id="MathJax-Span-801"><span class="mi" id="MathJax-Span-802"></span><span class="mo" id="MathJax-Span-803" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="msubsup" id="MathJax-Span-804" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 1.476em; height: 0px;"><span style="position: absolute; clip: rect(3.36em, 1000.99em, 4.425em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-805"><span class="mrow" id="MathJax-Span-806"><span class="msubsup" id="MathJax-Span-807"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.36em, 1000.58em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-808"><span class="mrow" id="MathJax-Span-809"><span class="mi" id="MathJax-Span-810" style="font-family: NeoEulerMathJax_Normal;">𝐪</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="texatom" id="MathJax-Span-811"><span class="mrow" id="MathJax-Span-812"><span class="mstyle" id="MathJax-Span-813" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-814" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-815" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -4.421em; left: 0.985em;"><span class="mi" id="MathJax-Span-816" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-817"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1000.62em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-818"><span class="mrow" id="MathJax-Span-819"><span class="mi" id="MathJax-Span-820" style="font-family: NeoEulerMathJax_Normal;">𝐤<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.616em;"><span class="texatom" id="MathJax-Span-821"><span class="mrow" id="MathJax-Span-822"><span class="mstyle" id="MathJax-Span-823" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-824" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-825" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(2.991em, 1006.43em, 4.629em, -999.998em); top: -4.502em; left: 0em;"><span class="mtd" id="MathJax-Span-842"><span class="mrow" id="MathJax-Span-843"><span class="mi" id="MathJax-Span-844"></span><span class="mo" id="MathJax-Span-845" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="mtext" id="MathJax-Span-846" style="padding-left: 0.248em;"><span style="font-size: 90%;">softmax</span></span><span class="mo" id="MathJax-Span-847" style="font-family: NeoEulerMathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-848"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-849" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.483em, 1000.33em, 4.097em, -999.998em); top: -4.339em; left: 0.821em;"><span class="mo" id="MathJax-Span-850" style="font-size: 70.7%; font-family: NeoEulerMathJax_Variants;">′</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.58em, 4.302em, -999.998em); top: -3.683em; left: 0.821em;"><span class="texatom" id="MathJax-Span-851"><span class="mrow" id="MathJax-Span-852"><span class="texatom" id="MathJax-Span-853"><span class="mrow" id="MathJax-Span-854"><span class="mstyle" id="MathJax-Span-855" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-856" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-857" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-858"><span class="mrow" id="MathJax-Span-859"><span class="mstyle" id="MathJax-Span-860" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-861" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-862" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-863" style="font-family: NeoEulerMathJax_Main;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(2.95em, 1005.49em, 5.489em, -999.998em); top: -2.783em; left: 0em;"><span class="mtd" id="MathJax-Span-875"><span class="mrow" id="MathJax-Span-876"><span class="mi" id="MathJax-Span-877"></span><span class="mo" id="MathJax-Span-878" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="munderover" id="MathJax-Span-879" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(2.95em, 1001.35em, 4.588em, -999.998em); top: -4.011em; left: 0em;"><span class="mo" id="MathJax-Span-880" style="font-family: NeoEulerMathJax_Size1; vertical-align: -0.244em;">∑</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.17em, 4.384em, -999.998em); top: -2.905em; left: 0.616em;"><span class="texatom" id="MathJax-Span-881"><span class="mrow" id="MathJax-Span-882"><span class="mstyle" id="MathJax-Span-883" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-884" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-885" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-886" style="padding-left: 0.166em;"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-887" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.821em;"><span class="texatom" id="MathJax-Span-888"><span class="mrow" id="MathJax-Span-889"><span class="texatom" id="MathJax-Span-890"><span class="mrow" id="MathJax-Span-891"><span class="mstyle" id="MathJax-Span-892" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-893" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-894" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-895"><span class="mrow" id="MathJax-Span-896"><span class="mstyle" id="MathJax-Span-897" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-898" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-899" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-900"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-901"><span class="mrow" id="MathJax-Span-902"><span class="mi" id="MathJax-Span-903" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-904"><span class="mrow" id="MathJax-Span-905"><span class="mstyle" id="MathJax-Span-906" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-907" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-908" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mspace" id="MathJax-Span-909" style="height: 0em; vertical-align: 0em; width: 0.166em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-910" style=""><span style="font-size: 90%;">.</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 6.636em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -2.907em; border-left: 0px solid; width: 0px; height: 6.366em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-50">
\begin{align*}
w'_{\rc{i}\gc{j}} &= {\q_\rc{i}}^T\k_\gc{j} \\
w_{\rc{i}\gc{j}} &= \text{softmax}(w'_{\rc{i}\gc{j}})\\
\y_\rc{i} &= \sum_\gc{j} w_{\rc{i}\gc{j}} \v_\gc{j}\p\\
\end{align*}
</script>
</p>

<p>This gives the self-attention layer some controllable parameters, and allows it to modify the incoming vectors to suit the three roles they must play.</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/key-query-value.svg">
<figcaption>Illustration of the self-attention with <span class="bc">key</span>, <span class="rc">query</span> and <span class="gc">value</span> transformations.</figcaption>
</figure>

<h4 id="2-scaling-the-dot-product">2) Scaling the dot product</h4>

<p>The softmax function can be sensitive to very large input values. These kill the gradient, and slow down learning, or cause it to stop altogether. Since the average value of the  dot product grows with the embedding dimension <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-51-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-911" style="width: 0.657em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.58em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-912"><span class="mi" id="MathJax-Span-913" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-51">k</script>, it helps to scale the dot product back a little to stop the inputs to the softmax function from growing too large:</p>

<p><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-52-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="MathJax-Span-914" style="width: 6.063em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.448em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(0.412em, 1005.45em, 3.196em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-915"><span class="msubsup" id="MathJax-Span-916"><span style="display: inline-block; position: relative; width: 1.394em; height: 0px;"><span style="position: absolute; clip: rect(3.442em, 1000.78em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-917" style="font-family: NeoEulerMathJax_Main;">w</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.483em, 1000.33em, 4.097em, -999.998em); top: -4.339em; left: 0.821em;"><span class="mo" id="MathJax-Span-918" style="font-size: 70.7%; font-family: NeoEulerMathJax_Variants;">′</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.58em, 4.302em, -999.998em); top: -3.683em; left: 0.821em;"><span class="texatom" id="MathJax-Span-919"><span class="mrow" id="MathJax-Span-920"><span class="texatom" id="MathJax-Span-921"><span class="mrow" id="MathJax-Span-922"><span class="mstyle" id="MathJax-Span-923" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-924" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-925" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span class="texatom" id="MathJax-Span-926"><span class="mrow" id="MathJax-Span-927"><span class="mstyle" id="MathJax-Span-928" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-929" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-930" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="mo" id="MathJax-Span-931" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="mfrac" id="MathJax-Span-932" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 2.541em; height: 0px; margin-right: 0.125em; margin-left: 0.125em;"><span style="position: absolute; clip: rect(3.032em, 1002.42em, 4.466em, -999.998em); top: -4.748em; left: 50%; margin-left: -1.186em;"><span class="mrow" id="MathJax-Span-933"><span class="msubsup" id="MathJax-Span-934"><span style="display: inline-block; position: relative; width: 1.476em; height: 0px;"><span style="position: absolute; clip: rect(3.36em, 1000.99em, 4.425em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-935"><span class="mrow" id="MathJax-Span-936"><span class="msubsup" id="MathJax-Span-937"><span style="display: inline-block; position: relative; width: 0.985em; height: 0px;"><span style="position: absolute; clip: rect(3.36em, 1000.58em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-938"><span class="mrow" id="MathJax-Span-939"><span class="mi" id="MathJax-Span-940" style="font-family: NeoEulerMathJax_Normal;">𝐪</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.724em; left: 0.657em;"><span class="texatom" id="MathJax-Span-941"><span class="mrow" id="MathJax-Span-942"><span class="mstyle" id="MathJax-Span-943" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-944" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-945" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -4.38em; left: 0.985em;"><span class="mi" id="MathJax-Span-946" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-947"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1000.62em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-948"><span class="mrow" id="MathJax-Span-949"><span class="mi" id="MathJax-Span-950" style="font-family: NeoEulerMathJax_Normal;">𝐤<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.616em;"><span class="texatom" id="MathJax-Span-951"><span class="mrow" id="MathJax-Span-952"><span class="mstyle" id="MathJax-Span-953" style="color: rgb(103, 125, 0);"><span class="mrow" id="MathJax-Span-954" style="color: rgb(103, 125, 0);"><span class="mi" id="MathJax-Span-955" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(103, 125, 0);">j</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.032em, 1001.43em, 4.261em, -999.998em); top: -3.233em; left: 50%; margin-left: -0.694em;"><span class="msqrt" id="MathJax-Span-956"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1000.58em, 4.138em, -999.998em); top: -4.011em; left: 0.821em;"><span class="mrow" id="MathJax-Span-957"><span class="mi" id="MathJax-Span-958" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.606em, 1000.58em, 3.892em, -999.998em); top: -4.584em; left: 0.821em;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px;"><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.011em; left: -0.039em;">−<span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.011em; left: -0.121em;">−<span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(2.91em, 1000.86em, 4.138em, -999.998em); top: -3.888em; left: 0em;"><span style="font-family: NeoEulerMathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(0.903em, 1002.54em, 1.19em, -999.998em); top: -1.267em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.5px solid; width: 2.541em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.067em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.089em; border-left: 0px solid; width: 0px; height: 2.911em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-52">
w'_{\rc{i}\gc{j}} = \frac{{\q_\rc{i}}^T\k_\gc{j}}{\sqrt{k}}
</script></p>

<aside>Why <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-53-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-959" style="width: 1.604em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.426em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.159em, 1001.45em, 2.405em, -1000.02em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-960"><span class="msqrt" id="MathJax-Span-961"><span style="display: inline-block; position: relative; width: 1.426em; height: 0px;"><span style="position: absolute; clip: rect(3.205em, 1000.56em, 4.14em, -1000.02em); top: -4.002em; left: 0.848em;"><span class="mrow" id="MathJax-Span-962"><span class="mi" id="MathJax-Span-963" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.006em;"></span></span><span style="position: absolute; clip: rect(3.606em, 1000.6em, 3.917em, -1000.02em); top: -4.58em; left: 0.848em;"><span style="display: inline-block; position: relative; width: 0.581em; height: 0px;"><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.002em; left: -0.042em;">−<span style="display: inline-block; width: 0px; height: 4.006em;"></span></span><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.002em; left: -0.131em;">−<span style="display: inline-block; width: 0px; height: 4.006em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.006em;"></span></span><span style="position: absolute; clip: rect(2.894em, 1000.87em, 4.14em, -1000.02em); top: -3.868em; left: 0em;"><span style="font-family: NeoEulerMathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.006em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.195em; border-left: 0px solid; width: 0px; height: 1.188em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-53">\sqrt{k}</script>? Imagine a vector in <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-54-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-964" style="width: 1.203em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.07em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(0.981em, 1001.09em, 2.449em, -1000.02em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-965"><span class="texatom" id="MathJax-Span-966"><span class="mrow" id="MathJax-Span-967"><span class="msubsup" id="MathJax-Span-968"><span style="display: inline-block; position: relative; width: 1.07em; height: 0px;"><span style="position: absolute; clip: rect(1.248em, 1000.6em, 2.494em, -1000.02em); top: -2.178em; left: 0em;"><span class="texatom" id="MathJax-Span-969"><span class="mrow" id="MathJax-Span-970"><span class="mi" id="MathJax-Span-971"><span style="font-family: STIXGeneral, &quot;Arial Unicode MS&quot;, serif; font-size: 90%; font-style: normal; font-weight: normal;">ℝ</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.182em;"></span></span><span style="position: absolute; top: -4.536em; left: 0.581em;"><span class="mi" id="MathJax-Span-972" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.006em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.244em; border-left: 0px solid; width: 0px; height: 1.435em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-54">{\mathbb R^k}</script> with values all <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-55-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-973" style="width: 0.536em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.492em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.515em, 1000.47em, 2.271em, -1000.02em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-974"><span class="mi" id="MathJax-Span-975" style="font-family: NeoEulerMathJax_Main;">c</span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.047em; border-left: 0px solid; width: 0px; height: 0.644em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-55">c</script>. Its Euclidean length is <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-56-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-976" style="width: 2.138em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.915em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.159em, 1001.89em, 2.405em, -1000.02em); top: -2.133em; left: 0em;"><span class="mrow" id="MathJax-Span-977"><span class="msqrt" id="MathJax-Span-978"><span style="display: inline-block; position: relative; width: 1.426em; height: 0px;"><span style="position: absolute; clip: rect(3.205em, 1000.56em, 4.14em, -1000.02em); top: -4.002em; left: 0.848em;"><span class="mrow" id="MathJax-Span-979"><span class="mi" id="MathJax-Span-980" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.006em;"></span></span><span style="position: absolute; clip: rect(3.606em, 1000.6em, 3.917em, -1000.02em); top: -4.58em; left: 0.848em;"><span style="display: inline-block; position: relative; width: 0.581em; height: 0px;"><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.002em; left: -0.042em;">−<span style="display: inline-block; width: 0px; height: 4.006em;"></span></span><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.002em; left: -0.131em;">−<span style="display: inline-block; width: 0px; height: 4.006em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.006em;"></span></span><span style="position: absolute; clip: rect(2.894em, 1000.87em, 4.14em, -1000.02em); top: -3.868em; left: 0em;"><span style="font-family: NeoEulerMathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.006em;"></span></span></span></span><span class="mi" id="MathJax-Span-981" style="font-family: NeoEulerMathJax_Main;">c</span></span><span style="display: inline-block; width: 0px; height: 2.138em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.195em; border-left: 0px solid; width: 0px; height: 1.188em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-56">\sqrt{k}c</script>. Therefore, we are dividing out the amount by which the increase in dimension increases the length of the average vectors.</aside>

<h4 id="3-multi-head-attention">3) Multi-head attention</h4>

<p>Finally, we must account for the fact that a word can mean different things to different neighbours. Consider the following example.
<span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-57-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-982" style="width: 11.959em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.772em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.108em, 1010.77em, 2.459em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-983"><span class="texatom" id="MathJax-Span-984"><span class="mrow" id="MathJax-Span-985"><span class="mstyle" id="MathJax-Span-986" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-987" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-988" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">mary</span></span></span></span></span></span><span class="mo" id="MathJax-Span-989" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-990" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-991"><span class="mstyle" id="MathJax-Span-992" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-993" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-994" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">gave</span></span></span></span></span></span><span class="mo" id="MathJax-Span-995" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-996" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-997"><span class="mstyle" id="MathJax-Span-998" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-999" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-1000" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">roses</span></span></span></span></span></span><span class="mo" id="MathJax-Span-1001" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-1002" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-1003"><span class="mstyle" id="MathJax-Span-1004" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1005" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-1006" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">to</span></span></span></span></span></span><span class="mo" id="MathJax-Span-1007" style="font-family: NeoEulerMathJax_Main;">,</span><span class="texatom" id="MathJax-Span-1008" style="padding-left: 0.166em;"><span class="mrow" id="MathJax-Span-1009"><span class="mstyle" id="MathJax-Span-1010" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1011" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-1012" style="color: rgb(48, 102, 147);"><span style="font-size: 90%;">susan</span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.27em; border-left: 0px solid; width: 0px; height: 1.32em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-57">\bc{\text{mary}}, \bc{\text{gave}}, \bc{\text{roses}}, \bc{\text{to}}, \bc{\text{susan}}</script>
We see that the word <span class="bc">gave</span> has different relations to different parts of the sentence.  <span class="bc">mary</span> expresses who’s doing the giving,  <span class="bc">roses</span> expresses what’s being given, and <span class="bc">susan</span> expresses who the recipient is.</p>

<p>In a single self-attention operation, all this information just gets summed together. If Susan gave Mary the roses instead, the output vector <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-58-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1013" style="width: 2.254em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.009em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1002.01em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1014"><span class="msubsup" id="MathJax-Span-1015"><span style="display: inline-block; position: relative; width: 2.009em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1016"><span class="mrow" id="MathJax-Span-1017"><span class="mi" id="MathJax-Span-1018" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-1019"><span class="mrow" id="MathJax-Span-1020"><span class="mstyle" id="MathJax-Span-1021" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1022" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-1023" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">gave</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-58">\y_\bc{\text{gave}}</script> would be the same, even though the meaning has changed.</p>

<p>We can give the self attention greater power of discrimination, by combining several self attention mechanisms (which we'll index with <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-59-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1024" style="width: 0.493em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.452em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.517em, 1000.45em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1025"><span class="texatom" id="MathJax-Span-1026"><span class="mrow" id="MathJax-Span-1027"><span class="mstyle" id="MathJax-Span-1028" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1029" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1030" style="font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.639em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-59">\bc{r}</script>), each with different matrices <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-60-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1031" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.623em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1032"><span class="msubsup" id="MathJax-Span-1033"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1034"><span class="mrow" id="MathJax-Span-1035"><span class="mi" id="MathJax-Span-1036" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1037"><span class="mrow" id="MathJax-Span-1038"><span class="mstyle" id="MathJax-Span-1039" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1040" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1041" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.524em, 1000.49em, 4.302em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1042" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">q</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.498em; border-left: 0px solid; width: 0px; height: 1.411em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-60">\W_q^\bc{r}</script>, <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-61-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1043" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.459em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1044"><span class="msubsup" id="MathJax-Span-1045"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1046"><span class="mrow" id="MathJax-Span-1047"><span class="mi" id="MathJax-Span-1048" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1049"><span class="mrow" id="MathJax-Span-1050"><span class="mstyle" id="MathJax-Span-1051" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1052" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1053" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.49em, 4.138em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1054" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.23em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-61">\W_k^\bc{r}</script>,<span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-62-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1055" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.459em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1056"><span class="msubsup" id="MathJax-Span-1057"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1058"><span class="mrow" id="MathJax-Span-1059"><span class="mi" id="MathJax-Span-1060" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1061"><span class="mrow" id="MathJax-Span-1062"><span class="mstyle" id="MathJax-Span-1063" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1064" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1065" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.41em, 4.138em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1066" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">v</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.23em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-62">\W_v^\bc{r}</script>. These are called <em>attention heads</em>.</p>

<p>For input <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-63-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1067" style="width: 0.985em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1000.86em, 2.377em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1068"><span class="msubsup" id="MathJax-Span-1069"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1070"><span class="mrow" id="MathJax-Span-1071"><span class="mi" id="MathJax-Span-1072" style="font-family: NeoEulerMathJax_Normal;">𝐱</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.847em; left: 0.534em;"><span class="texatom" id="MathJax-Span-1073"><span class="mrow" id="MathJax-Span-1074"><span class="mstyle" id="MathJax-Span-1075" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-1076" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-1077" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.225em; border-left: 0px solid; width: 0px; height: 0.82em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-63">\x_\rc{i}</script> each attention head produces a different output vector <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-64-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1078" style="width: 1.19em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.067em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1001.07em, 2.541em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1079"><span class="msubsup" id="MathJax-Span-1080"><span style="display: inline-block; position: relative; width: 1.067em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.384em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1081"><span class="mrow" id="MathJax-Span-1082"><span class="mi" id="MathJax-Span-1083" style="font-family: NeoEulerMathJax_Normal;">𝐲</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.339em; left: 0.657em;"><span class="texatom" id="MathJax-Span-1084"><span class="mrow" id="MathJax-Span-1085"><span class="mstyle" id="MathJax-Span-1086" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1087" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1088" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.33em, 4.138em, -999.998em); top: -3.683em; left: 0.657em;"><span class="texatom" id="MathJax-Span-1089"><span class="mrow" id="MathJax-Span-1090"><span class="mstyle" id="MathJax-Span-1091" style="color: rgb(177, 62, 38);"><span class="mrow" id="MathJax-Span-1092" style="color: rgb(177, 62, 38);"><span class="mi" id="MathJax-Span-1093" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(177, 62, 38);">i</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.407em; border-left: 0px solid; width: 0px; height: 1.23em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-64">\y_\rc{i}^\bc{r}</script>. We concatenate these, and pass them through a linear transformation to reduce the dimension back to <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-65-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1094" style="width: 0.657em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.58em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1095"><span class="mi" id="MathJax-Span-1096" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-65">k</script>.
</p>

<p><strong>Narrow and wide self-attention</strong> There are two ways to apply multi-head self-attention. The standard option is to cut the embedding vector into chunks: if the embedding vector has 256 dimensions, and we have 8 attention heads, we cut it into 8 chunks of 32 dimensions. For each chunk, we generate keys, values and queries of 32 dimensions each. This means that the matrices <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-66-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1097" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.623em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1098"><span class="msubsup" id="MathJax-Span-1099"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1100"><span class="mrow" id="MathJax-Span-1101"><span class="mi" id="MathJax-Span-1102" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1103"><span class="mrow" id="MathJax-Span-1104"><span class="mstyle" id="MathJax-Span-1105" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1106" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1107" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.524em, 1000.49em, 4.302em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1108" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">q</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.498em; border-left: 0px solid; width: 0px; height: 1.411em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-66">\W_q^\bc{r}</script>, <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-67-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1109" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.459em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1110"><span class="msubsup" id="MathJax-Span-1111"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1112"><span class="mrow" id="MathJax-Span-1113"><span class="mi" id="MathJax-Span-1114" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1115"><span class="mrow" id="MathJax-Span-1116"><span class="mstyle" id="MathJax-Span-1117" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1118" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1119" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.49em, 4.138em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1120" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.23em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-67">\W_k^\bc{r}</script>,<span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-68-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1121" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.459em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1122"><span class="msubsup" id="MathJax-Span-1123"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1124"><span class="mrow" id="MathJax-Span-1125"><span class="mi" id="MathJax-Span-1126" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1127"><span class="mrow" id="MathJax-Span-1128"><span class="mstyle" id="MathJax-Span-1129" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1130" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1131" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.41em, 4.138em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1132" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">v</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.23em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-68">\W_v^\bc{r}</script> are all <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-69-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1133" style="width: 3.524em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.155em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1003.11em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1134"><span class="mn" id="MathJax-Span-1135" style="font-family: NeoEulerMathJax_Main;">32</span><span class="mo" id="MathJax-Span-1136" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">×</span><span class="mn" id="MathJax-Span-1137" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">32</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.911em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-69">32 \times 32</script>.</p>

<p>We can also make the matrices <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-70-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1138" style="width: 4.629em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.179em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1004.14em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1139"><span class="mn" id="MathJax-Span-1140" style="font-family: NeoEulerMathJax_Main;">256</span><span class="mo" id="MathJax-Span-1141" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">×</span><span class="mn" id="MathJax-Span-1142" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">256</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.911em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-70">256 \times 256</script>, and apply each head to the whole size 256 vector. The first is faster, and more memory efficient but all else being equal, the second does give better results (at the cost of more memory and time).  The <a href="https://github.com/pbloem/former">code on github</a> contains both methods (called <em>narrow</em> and <em>wide</em> self-attention respectively).</p>

<p>For the sake of simplicity, we’ll describe the implementation of the second option here.</p>

<h3 id="in-pytorch-complete-self-attention">In Pytorch: complete self-attention</h3>

<p>Let’s now implement a self-attention module with all the bells and whistles. We’ll package it into a Pytorch module, so we can reuse it later.</p>

<figure class="right">
<img src="./Transformers from scratch _ peterbloem.nl_files/heads-matrix.svg">
<figcaption>
Combining three attention heads into one matrix multiplication (for the queries).
</figcaption>
</figure>

<pre><code class="python hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SelfAttention</span><span class="hljs-params">(nn.Module)</span>:</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, k, heads=<span class="hljs-number">8</span>)</span>:</span>
    super().__init__()
    self.k, self.heads = k, heads
</code></pre>

<p>We think of the <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-71-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1143" style="width: 0.698em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.616em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.62em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1144"><span class="mi" id="MathJax-Span-1145" style="font-family: NeoEulerMathJax_Main;">h<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-71">h</script> attention heads as <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-72-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1146" style="width: 0.698em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.616em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.62em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1147"><span class="mi" id="MathJax-Span-1148" style="font-family: NeoEulerMathJax_Main;">h<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-72">h</script> separate sets of three matrices <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-73-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1149" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.623em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1150"><span class="msubsup" id="MathJax-Span-1151"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1152"><span class="mrow" id="MathJax-Span-1153"><span class="mi" id="MathJax-Span-1154" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1155"><span class="mrow" id="MathJax-Span-1156"><span class="mstyle" id="MathJax-Span-1157" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1158" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1159" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.524em, 1000.49em, 4.302em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1160" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">q</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.498em; border-left: 0px solid; width: 0px; height: 1.411em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-73">\W^\bc{r}_q</script>, <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-74-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1161" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.459em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1162"><span class="msubsup" id="MathJax-Span-1163"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1164"><span class="mrow" id="MathJax-Span-1165"><span class="mi" id="MathJax-Span-1166" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1167"><span class="mrow" id="MathJax-Span-1168"><span class="mstyle" id="MathJax-Span-1169" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1170" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1171" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.401em, 1000.49em, 4.138em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1172" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.23em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-74">\W^\bc{r}_k</script>,<span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-75-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1173" style="width: 1.845em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.19em, 1001.64em, 2.459em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1174"><span class="msubsup" id="MathJax-Span-1175"><span style="display: inline-block; position: relative; width: 1.64em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1001.19em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1176"><span class="mrow" id="MathJax-Span-1177"><span class="mi" id="MathJax-Span-1178" style="font-family: NeoEulerMathJax_Normal;">𝐖<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.043em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.37em, 4.138em, -999.998em); top: -4.421em; left: 1.231em;"><span class="texatom" id="MathJax-Span-1179"><span class="mrow" id="MathJax-Span-1180"><span class="mstyle" id="MathJax-Span-1181" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1182" style="color: rgb(48, 102, 147);"><span class="mi" id="MathJax-Span-1183" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main; color: rgb(48, 102, 147);">r</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.565em, 1000.41em, 4.138em, -999.998em); top: -3.765em; left: 1.108em;"><span class="mi" id="MathJax-Span-1184" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">v</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.23em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-75">\W^\bc{r}_v</script>, but it's actually more efficient to combine these for all heads into three single <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-76-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1185" style="width: 3.237em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.91em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1002.91em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1186"><span class="mi" id="MathJax-Span-1187" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-1188" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">×</span><span class="mi" id="MathJax-Span-1189" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">h<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-1190" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-76">k \times hk</script> matrices, so that we can compute all the concatenated queries, keys and values in a single matrix multiplication.</p>

<pre><code class="python hljs">    <span class="hljs-comment"># These compute the queries, keys and values for all </span>
    <span class="hljs-comment"># heads (as a single concatenated vector)</span>
    self.tokeys    = nn.Linear(k, k * heads, bias=<span class="hljs-literal">False</span>)
    self.toqueries = nn.Linear(k, k * heads, bias=<span class="hljs-literal">False</span>)
	self.tovalues  = nn.Linear(k, k * heads, bias=<span class="hljs-literal">False</span>)

	<span class="hljs-comment"># This unifies the outputs of the different heads into </span>
	<span class="hljs-comment"># a single k-vector</span>
	self.unifyheads = nn.Linear(heads * k, k)
</code></pre>

<p>We can now implement the computation of the self-attention (the module’s <code class="language-plaintext highlighter-rouge">forward</code> function). First, we compute the queries, keys and values:</p>

<pre><code class="python hljs">  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
    b, t, k = x.size()
    h = self.heads

    queries = self.toqueries(x).view(b, t, h, k)
    keys    = self.tokeys(x)   .view(b, t, h, k)
    values  = self.tovalues(x) .view(b, t, h, k)
</code></pre>

<p>The output of each linear module has size <code class="language-plaintext highlighter-rouge">(b, t, h*k)</code>, which we simply reshape to <code class="language-plaintext highlighter-rouge">(b, t, h, k)</code> give each head its own dimension.</p>

<p>Next, we need to compute the dot products. This is the same operation for every head, so we fold the heads into the batch dimension. This ensures that we can use <code class="language-plaintext highlighter-rouge">torch.bmm()</code> as before, and the whole collection of keys, queries and values will just be seen as a slightly larger batch.</p>

<p>Since the head and batch dimension are not next to each other, we need to transpose before we reshape. (This is costly, but it seems to be unavoidable.)</p>

<pre><code class="python hljs">    <span class="hljs-comment"># - fold heads into the batch dimension</span>
    keys = keys.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(b * h, t, k)
    queries = queries.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(b * h, t, k)
    values = values.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(b * h, t, k)
</code></pre>

<p>As before, the dot products can be computed in a single matrix multiplication, but now between the queries and the keys.</p>

<p>Before that, however, we move the scaling of the dot product by <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-77-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1191" style="width: 1.599em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.108em, 1001.43em, 2.336em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1192"><span class="msqrt" id="MathJax-Span-1193"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1000.58em, 4.138em, -999.998em); top: -4.011em; left: 0.821em;"><span class="mrow" id="MathJax-Span-1194"><span class="mi" id="MathJax-Span-1195" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.606em, 1000.58em, 3.892em, -999.998em); top: -4.584em; left: 0.821em;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px;"><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.011em; left: -0.039em;">−<span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.011em; left: -0.121em;">−<span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(2.91em, 1000.86em, 4.138em, -999.998em); top: -3.888em; left: 0em;"><span style="font-family: NeoEulerMathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.18em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-77">\sqrt{k}</script> back and instead scale the keys and queries by <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-78-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1196" style="width: 1.599em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.108em, 1001.43em, 2.336em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1197"><span class="mroot" id="MathJax-Span-1198"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1000.58em, 4.138em, -999.998em); top: -4.011em; left: 0.821em;"><span class="mi" id="MathJax-Span-1199" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.606em, 1000.58em, 3.892em, -999.998em); top: -4.584em; left: 0.821em;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px;"><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.011em; left: -0.039em;">−<span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.011em; left: -0.121em;">−<span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(2.91em, 1000.86em, 4.138em, -999.998em); top: -3.888em; left: 0em;"><span style="font-family: NeoEulerMathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.524em, 1000.25em, 4.138em, -999.998em); top: -4.502em; left: 0.289em;"><span class="mn" id="MathJax-Span-1200" style="font-size: 50%; font-family: NeoEulerMathJax_Main;">4</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.18em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-78">\sqrt[4]{k}</script> before multiplying them together. This should save memory for longer sequences.</p>
<pre><code class="python hljs">    queries = queries / (k ** (<span class="hljs-number">1</span>/<span class="hljs-number">4</span>))
    keys    = keys / (k ** (<span class="hljs-number">1</span>/<span class="hljs-number">4</span>))

    <span class="hljs-comment"># - get dot product of queries and keys, and scale</span>
    dot = torch.bmm(queries, keys.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))
    <span class="hljs-comment"># - dot has size (b*h, t, t) containing raw weights</span>

    dot = F.softmax(dot, dim=<span class="hljs-number">2</span>) 
    <span class="hljs-comment"># - dot now contains row-wise normalized weights</span>
</code></pre>

<p>We apply the self attention to the values, giving us the output for each attention head</p>
<pre><code class="python hljs">    <span class="hljs-comment"># apply the self attention to the values</span>
    out = torch.bmm(dot, values).view(b, h, t, k)
</code></pre>

<p>To unify the attention heads, we transpose again, so that the head dimension and the embedding dimension are next to each other, and reshape to get concatenated vectors of dimension <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-79-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1201" style="width: 1.312em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.19em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1001.19em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1202"><span class="mi" id="MathJax-Span-1203" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-1204" style="font-family: NeoEulerMathJax_Main;">h<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-79">kh</script>. We then pass these through the <code class="language-plaintext highlighter-rouge">unifyheads</code> layer to project them back down to <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-80-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1205" style="width: 0.657em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.575em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.58em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1206"><span class="mi" id="MathJax-Span-1207" style="font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-80">k</script> dimensions.</p>

<pre><code class="python hljs">    <span class="hljs-comment"># swap h, t back, unify heads</span>
    out = out.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(b, t, h * k)
    <span class="hljs-keyword">return</span> self.unifyheads(out)
</code></pre>

<p>And there you have it: multi-head, scaled dot-product self attention. You can see <a href="https://github.com/pbloem/former/blob/b438731ceeaf6c468f8b961bb07c2adde3b54a9f/former/modules.py#L10">the complete implementation here</a>.</p>

<aside>
The implementation can be made more concise using <a href="https://rockt.github.io/2018/04/30/einsum">einsum notation</a> (see an example <a href="https://github.com/pbloem/former/issues/4">here</a>). 
</aside>

<h2 id="building-transformers">Building <em>transformers</em></h2>

<p>A transformer is not just a self-attention layer, it is an <em>architecture</em>. It’s not quite clear what does and doesn’t qualify as a transformer, but here we’ll use the following definition:</p>
<blockquote>
Any architecture designed to process a connected set of units—such as the tokens in a sequence or the pixels in an image—where the only interaction between units is through self-attention.
</blockquote>

<p>As with other mechanisms, like convolutions, a more or less standard approach has emerged for how to build self-attention layers up into a larger network. The first step is to wrap the self-attention into a <em>block</em> that we can repeat.</p>

<h3 id="the-transformer-block">The transformer block</h3>

<p>There are some variations on how to build a basic transformer block, but most of them are structured roughly like this:</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/transformer-block.svg">
</figure>

<p>That is, the block applies, in sequence: <span class="gc">a self attention layer,</span> <span class="rc">layer normalization</span>, <span class="gc">a feed forward layer</span> (a single <abbr title="multi-layer perceptron">MLP</abbr> applied independently to each vector), and <span class="rc">another layer normalization</span>. <span class="bc">Residual connections</span> are added around both, before the normalization. The order of the various components is not set in stone; the important thing is to combine self-attention with a local feedforward, and to add normalization and residual connections.</p>

<aside>
Normalization and residual connections are standard tricks used to help deep neural networks train faster and more accurately. The layer normalization is applied over the embedding dimension only.
</aside>

<p>Here’s what the transformer block looks like in pytorch.</p>
<pre><code class="hljs ruby"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TransformerBlock</span>(<span class="hljs-title">nn</span>.<span class="hljs-title">Module</span>):</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, k, heads)</span></span>:
    <span class="hljs-keyword">super</span>().__init_<span class="hljs-number">_</span>()

    <span class="hljs-keyword">self</span>.attention = SelfAttention(k, heads=heads)

    <span class="hljs-keyword">self</span>.norm1 = nn.LayerNorm(k)
    <span class="hljs-keyword">self</span>.norm2 = nn.LayerNorm(k)

    <span class="hljs-keyword">self</span>.ff = nn.Sequential(
      nn.Linear(k, <span class="hljs-number">4</span> * k),
      nn.ReLU(),
      nn.Linear(<span class="hljs-number">4</span> * k, k))

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, x)</span></span>:
    attended = <span class="hljs-keyword">self</span>.attention(x)
    x = <span class="hljs-keyword">self</span>.norm1(attended + x)
    
    fedforward = <span class="hljs-keyword">self</span>.ff(x)
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">self</span>.norm2(fedforward + x)</code></pre>

<p>We’ve made the relatively arbitrary choice of making the hidden layer of the feedforward 4 times as big as the input and output. Smaller values may work as well, and save memory, but it should be bigger than the input/output layers.</p>

<h3 id="classification-transformer">Classification transformer</h3>

<p>The simplest transformer we can build is a <em>sequence classifier</em>. We’ll use the <abbr title="Internet Movie Database">IMDb</abbr> sentiment classification dataset: the instances are movie reviews, tokenized into sequences of words, and the classification labels are <span class="bc"><code>positive</code></span> and <span class="rc"><code>negative</code></span> (indicating whether the review was positive or negative about the movie).</p>

<p>The heart of the architecture will simply be a large chain of transformer blocks. All we need to do is work out how to feed it the input sequences, and how to transform the final output sequence into a a single classification.</p>

<p>The whole experiment can be <a href="https://github.com/pbloem/former/blob/master/experiments/classify.py">found here</a>. We won’t deal with the data wrangling in this blog post. Follow the links in the code to see how the data is loaded and prepared.</p>

<h4 id="output-producing-a-classification">Output: producing a classification</h4>

<p>The most common way to build a sequence classifier out of sequence-to-sequence layers, is to apply global average pooling to the final output sequence, and to map the result to a softmaxed class vector.</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/classifier.svg">
<figcaption>
Overview of a simple sequence classification transformer. The output sequence is <span class="bc">averaged</span> to produce a single vector representing the whole sequence. This vector is projected down to a vector with one element per class and softmaxed to produce probabilities.
</figcaption>
</figure>

<h4 id="input-using-the-positions">Input: using the positions</h4>

<p>We’ve already discussed the principle of an embedding layer. This is what we’ll use to represent the words.</p>

<p>However, as we’ve also mentioned already, we’re stacking permutation equivariant layers, and the final global average pooling is permutation <em>in</em>variant, so the network as a whole is also permutation invariant. Put more simply: if we shuffle up the words in the sentence, we get the exact same classification, whatever weights we learn. Clearly, we want our state-of-the-art language model to have at least some sensitivity to word order, so this needs to be fixed.</p>

<p>The solution is simple: we create a second vector of equal length, that represents the position of the word in the current sentence, and add this to the word embedding. There are two options.</p>

<dl>
<dt>position embeddings</dt>
<dd>We simply <em>embed</em> the positions like we did the words. Just like we created embedding vectors <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-81-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1208" style="width: 1.599em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1001.43em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1209"><span class="msubsup" id="MathJax-Span-1210"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1211"><span class="mrow" id="MathJax-Span-1212"><span class="mi" id="MathJax-Span-1213" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-1214"><span class="mrow" id="MathJax-Span-1215"><span class="mstyle" id="MathJax-Span-1216" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1217" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-1218" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">cat</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-81">\v_\bc{\text{cat}}</script> and <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-82-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1219" style="width: 2.459em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.213em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1002.21em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1220"><span class="msubsup" id="MathJax-Span-1221"><span style="display: inline-block; position: relative; width: 2.213em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1222"><span class="mrow" id="MathJax-Span-1223"><span class="mi" id="MathJax-Span-1224" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-1225"><span class="mrow" id="MathJax-Span-1226"><span class="mstyle" id="MathJax-Span-1227" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1228" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-1229" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">susan</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-82">\v_\bc{\text{susan}}</script>, we create embedding vectors <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-83-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1230" style="width: 1.394em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.231em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1001.23em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1231"><span class="msubsup" id="MathJax-Span-1232"><span style="display: inline-block; position: relative; width: 1.231em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1233"><span class="mrow" id="MathJax-Span-1234"><span class="mi" id="MathJax-Span-1235" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-1236"><span class="mrow" id="MathJax-Span-1237"><span class="mstyle" id="MathJax-Span-1238" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1239" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-1240" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">12</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-83">\v_\bc{\text{12}}</script> and <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-84-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1241" style="width: 1.476em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.312em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.476em, 1001.31em, 2.705em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1242"><span class="msubsup" id="MathJax-Span-1243"><span style="display: inline-block; position: relative; width: 1.312em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.53em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="texatom" id="MathJax-Span-1244"><span class="mrow" id="MathJax-Span-1245"><span class="mi" id="MathJax-Span-1246" style="font-family: NeoEulerMathJax_Normal;">𝐯</span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -3.683em; left: 0.534em;"><span class="texatom" id="MathJax-Span-1247"><span class="mrow" id="MathJax-Span-1248"><span class="mstyle" id="MathJax-Span-1249" style="color: rgb(48, 102, 147);"><span class="mrow" id="MathJax-Span-1250" style="color: rgb(48, 102, 147);"><span class="mtext" id="MathJax-Span-1251" style="font-size: 70.7%; color: rgb(48, 102, 147);"><span style="font-size: 90%;">25</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.589em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-84">\v_\bc{\text{25}}</script>. Up to however long we expect sequences to get. The drawback is that we have to see sequences of every length during training, otherwise the relevant position embeddings don't get trained. The benefit is that it works pretty well, and it's easy to implement.</dd>
<dt>position encodings</dt>
<dd>Position encodings work in the same way as embeddings, except that we don't <em>learn</em> the position vectors, we just choose some function <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-85-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1252" style="width: 4.875em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.384em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.026em, 1004.38em, 2.5em, -999.998em); top: -2.168em; left: 0em;"><span class="mrow" id="MathJax-Span-1253"><span class="mi" id="MathJax-Span-1254" style="font-family: NeoEulerMathJax_Main;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-1255" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">:</span><span class="texatom" id="MathJax-Span-1256" style="padding-left: 0.248em;"><span class="mrow" id="MathJax-Span-1257"><span class="texatom" id="MathJax-Span-1258"><span class="mrow" id="MathJax-Span-1259"><span class="mi" id="MathJax-Span-1260"><span style="font-family: STIXGeneral, &quot;Arial Unicode MS&quot;, serif; font-size: 90%; font-style: normal; font-weight: normal;">ℕ</span></span></span></span></span></span><span class="mo" id="MathJax-Span-1261" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">→</span><span class="msubsup" id="MathJax-Span-1262" style="padding-left: 0.248em;"><span style="display: inline-block; position: relative; width: 1.108em; height: 0px;"><span style="position: absolute; clip: rect(1.231em, 1000.62em, 2.5em, -999.998em); top: -2.168em; left: 0em;"><span class="texatom" id="MathJax-Span-1263"><span class="mrow" id="MathJax-Span-1264"><span class="texatom" id="MathJax-Span-1265"><span class="mrow" id="MathJax-Span-1266"><span class="mi" id="MathJax-Span-1267"><span style="font-family: STIXGeneral, &quot;Arial Unicode MS&quot;, serif; font-size: 90%; font-style: normal; font-weight: normal;">ℝ</span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.172em;"></span></span><span style="position: absolute; top: -4.543em; left: 0.616em;"><span class="mi" id="MathJax-Span-1268" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.172em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.27em; border-left: 0px solid; width: 0px; height: 1.457em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-85">f: {\mathbb N} \to {\mathbb R}^k</script> to map the positions to real valued vectors, and let the network figure out how to interpret these encodings. The benefit is that for a well chosen function, the network should be able to deal with sequences that are longer than those it's seen during training (it's unlikely to perform well on them, but at least we can check). The drawbacks are that the choice of encoding function is a complicated hyperparameter, and it complicates the implementation a little.</dd>
</dl>

<p>For the sake of simplicity, we’ll use position embeddings in our implementation.</p>

<h4 id="pytorch">Pytorch</h4>

<p>Here is the complete text classification transformer in pytorch.</p>

<pre><code class="python hljs"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Transformer</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, k, heads, depth, seq_length, num_tokens, num_classes)</span>:</span>
        super().__init__()

        self.num_tokens = num_tokens
        self.token_emb = nn.Embedding(num_tokens, k)
        self.pos_emb = nn.Embedding(seq_length, k)

		<span class="hljs-comment"># The sequence of transformer blocks that does all the </span>
		<span class="hljs-comment"># heavy lifting</span>
        tblocks = []
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(depth):
            tblocks.append(TransformerBlock(k=k, heads=heads))
        self.tblocks = nn.Sequential(*tblocks)

		<span class="hljs-comment"># Maps the final output sequence to class logits</span>
        self.toprobs = nn.Linear(k, num_classes)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-string">"""
        :param x: A (b, t) tensor of integer values representing 
                  words (in some predetermined vocabulary).
        :return: A (b, c) tensor of log-probabilities over the 
                 classes (where c is the nr. of classes).
        """</span>
		<span class="hljs-comment"># generate token embeddings</span>
        tokens = self.token_emb(x)
        b, t, k = tokens.size()

		<span class="hljs-comment"># generate position embeddings</span>
		positions = torch.arange(t)
        positions = self.pos_emb(positions)[<span class="hljs-literal">None</span>, :, :].expand(b, t, k)
        
        x = tokens + positions
        x = self.tblocks(x)
        
        <span class="hljs-comment"># Average-pool over the t dimension and project to class </span>
        <span class="hljs-comment"># probabilities</span>
        x = self.toprobs(x.mean(dim=<span class="hljs-number">1</span>))
        <span class="hljs-keyword">return</span> F.log_softmax(x, dim=<span class="hljs-number">1</span>)
</code></pre>

<p>At depth 6, with a maximum sequence length of 512, this transformer achieves an accuracy of about 85%, competitive with results from RNN models, and much faster to train. To see the real near-human performance of transformers, we’d need to train a much deeper model on much more data. More about how to do that later.</p>

<h3 id="text-generation-transformer">Text generation transformer</h3>

<p>The next trick we’ll try is an <em>autoregressive</em> model. We’ll train a <em>character</em> level transformer to predict the next character in a sequence. The training regime is simple (and has been around <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">for far longer than transformers have</a>). We give the sequence-to-sequence model a sequence, and we ask it to predict the next character at each point in the sequence. In other words, the target output is the same sequence shifted one character to the left:</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/generator.svg">
</figure>

<p>With RNNs this is all we need to do, since they cannot look forward into the input sequence: output <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-86-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1269" style="width: 0.412em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.371em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.37em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1270"><span class="mi" id="MathJax-Span-1271" style="font-family: NeoEulerMathJax_Main;">i</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-86">i</script> depends only on inputs <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-87-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1272" style="width: 0.575em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.493em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.45em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1273"><span class="mn" id="MathJax-Span-1274" style="font-family: NeoEulerMathJax_Main;">0</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.911em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-87">0</script> to <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-88-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1275" style="width: 0.412em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.371em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.37em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1276"><span class="mi" id="MathJax-Span-1277" style="font-family: NeoEulerMathJax_Main;">i</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-88">i</script>. With a transformer, the output depends on the entire input sequence, so prediction of the next character becomes vacuously easy, just retrieve it from the input.</p>

<p>To use self-attention as an autoregressive model, we’ll need to ensure that it cannot look forward into the sequence. We do this by applying a mask to the matrix of dot products, before the softmax is applied. This mask disables all elements above the diagonal of the matrix.</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/masked-attention.svg">
<figcaption>
Masking the self attention, to ensure that elements can only attend to input elements that precede them in the sequence. Note that the multiplication symbol is slightly misleading: we actually set the masked out elements (the white squares) to <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-89-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1278" style="width: 1.961em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.739em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.427em, 1001.69em, 2.362em, -999.998em); top: -2.135em; left: 0em;"><span class="mrow" id="MathJax-Span-1279"><span class="mo" id="MathJax-Span-1280" style="font-family: NeoEulerMathJax_Main;">−</span><span class="mi" id="MathJax-Span-1281" style="font-family: NeoEulerMathJax_Main;">∞</span></span><span style="display: inline-block; width: 0px; height: 2.139em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.146em; border-left: 0px solid; width: 0px; height: 0.843em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-89">-\infty</script>
</figcaption>
</figure>

<p>Since we want these elements to be zero after the softmax, we set them to <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-90-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1282" style="width: 1.968em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.763em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.435em, 1001.72em, 2.336em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1283"><span class="mo" id="MathJax-Span-1284" style="font-family: NeoEulerMathJax_Main;">−</span><span class="mi" id="MathJax-Span-1285" style="font-family: NeoEulerMathJax_Main;">∞</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.134em; border-left: 0px solid; width: 0px; height: 0.82em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-90">-\infty</script>. Here’s how that looks in pytorch:</p>

<pre><code class="python hljs">dot = torch.bmm(queries, keys.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))

indices = torch.triu_indices(t, t, offset=<span class="hljs-number">1</span>)
dot[:, indices[<span class="hljs-number">0</span>], indices[<span class="hljs-number">1</span>]] = float(<span class="hljs-string">'-inf'</span>)

dot = F.softmax(dot, dim=<span class="hljs-number">2</span>) 
</code></pre>

<p>After we’ve handicapped the self-attention module like this, the model can no longer look forward in the sequence.</p>

<p>We train on the standard <code class="language-plaintext highlighter-rouge">enwik8</code> dataset (taken from the <a href="http://prize.hutter1.net/">Hutter prize</a>), which contains <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-91-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1286" style="width: 1.599em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.026em, 1001.43em, 2.213em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1287"><span class="msubsup" id="MathJax-Span-1288"><span style="display: inline-block; position: relative; width: 1.435em; height: 0px;"><span style="position: absolute; clip: rect(3.196em, 1000.94em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mn" id="MathJax-Span-1289" style="font-family: NeoEulerMathJax_Main;">10</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -4.462em; left: 0.985em;"><span class="mn" id="MathJax-Span-1290" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">8</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 1.139em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-91">10^8</script> characters of Wikipedia text (including markup). During training, we generate batches by randomly sampling subsequences from the data.</p>

<p>We train on sequences of length 256, using a model of 12 transformer blocks and 256 embedding dimension. After about 24 hours training on an RTX 2080Ti (some 170K batches of size 32), we let the model generate from <span class="lbc">a 256-character seed</span>: for each character, we feed it the preceding 256 characters, and look what it predicts for the next character (the last output vector). We sample from that with a <a href="https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277">temperature</a> of 0.5, and move to the next character.</p>

<p>The output looks like this:</p>

<div class="sample">
<span class="lbc">1228X Human &amp; Rousseau.

Because many of his stories were originally published in long-forgotten magazines and
 journals, there are a number of [[anthology|anthologies]] by different collators each containing a different selection. His original books ha</span>ve been considered an 
 anthologie in the [[Middle Ages]], and were likely to be one of the most common in the 
 [[Indian Ocean]] in the [[1st century]]. As a result of his death, the Bible was 
 recognised as a counter-attack by the [[Gospel of Matthew]] (1177-1133), and the 
 [[Saxony|Saxons]] of the [[Isle of Matthew]] (1100-1138), the third was a topic of the 
 [[Saxony|Saxon]] throne, and the [[Roman Empire|Roman]] troops of [[Antiochia]] 
 (1145-1148). The [[Roman Empire|Romans]] resigned in [[1148]] and [[1148]] began to 
 collapse. The [[Saxony|Saxons]] of the [[Battle of Valasander]] reported the y
</div>

<p>Note that the Wikipedia link tag syntax is correctly used, that the text inside the links represents reasonable subjects for links. Most importantly, note that there is a rough thematic consistency; the generated text keeps on the subject of the bible, and the Roman empire, using different related terms at different points. While this is far from the performance of a model like <a href="https://openai.com/blog/better-language-models/">GPT-2</a>, the benefits over a similar RNN model are clear already: faster training (a similar RNN model would take many days to train) and better long-term coherence.</p>

<aside>
In case you're curious, the Battle of Valasander seems to be an invention of the network.
</aside>

<p>At this point, the model achieves a compression of 1.343 bits per byte on the validation set, which is not too far off the state of the art of 0.93 bits per byte, achieved by the GPT-2 model (described below).</p>

<h2 id="design-considerations">Design considerations</h2>

<p>To understand why transformers are set up this way, it helps to understand the basic design considerations that went into them. The main point of the transformer was to overcome the problems of the previous state-of-the-art architecture, the RNN (usually an LSTM or a GRU). <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Unrolled</a>, an RNN looks like this:</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/recurrent-connection.svg">
</figure>

<p>The big weakness here is the <span class="bc">recurrent connection</span>. while this allows information to propagate along the sequence, it also means that we cannot compute the cell at time step <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-92-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1291" style="width: 0.412em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.371em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1000.37em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1292"><span class="mi" id="MathJax-Span-1293" style="font-family: NeoEulerMathJax_Main;">i</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.866em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-92">i</script> until we’ve computed the cell at timestep <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-93-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1294" style="width: 2.295em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.05em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1001.85em, 2.336em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1295"><span class="mi" id="MathJax-Span-1296" style="font-family: NeoEulerMathJax_Main;">i</span><span class="mo" id="MathJax-Span-1297" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">−</span><span class="mn" id="MathJax-Span-1298" style="font-family: NeoEulerMathJax_Main; padding-left: 0.207em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.134em; border-left: 0px solid; width: 0px; height: 0.957em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-93">i - 1</script>. Contrast this with a 1D convolution:</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/convolutional-connection.svg">
</figure>

<p>In this model, every output vector can be computed in parallel with every other output vector. This makes convolutions much faster. The drawback with convolutions, however, is that they’re severely limited in modeling <em>long range dependencies</em>. In one convolution layer, only words that are closer together than the kernel size can interact with each other. For longer dependence we need to stack many convolutions.</p>

<p>The transformer is an attempt to capture the best of both worlds. They can model dependencies over the whole range of the input sequence just as easily as they can for words that are next to each other (in fact, without the position vectors, they can’t even tell the difference). And yet, there are no recurrent connections, so the whole model can be computed in a very efficient feedforward fashion.</p>

<p>The rest of the design of the transformer is based primarily on one consideration: depth. Most choices follow from the desire to train big stacks of transformer blocks. Note for instance that there are only two places in the transformer where non-linearities occur: the softmax in the self-attention and the <abbr title="rectified linear unit">ReLU</abbr> in the feedforward layer. The rest of the model is entirely composed of linear transformations, which perfectly preserve the gradient.</p>
<aside>
I suppose the layer normalization is also nonlinear, but that is one nonlinearity that actually helps to keep the gradient stable as it propagates back down the network.
</aside>

<h2 id="historical-baggage">Historical baggage</h2>

<p>If you’ve read other introductions to transformers, you may have noticed that they contain some bits I’ve skipped. I think these are not necessary to understand modern transformers. They are, however, helpful to understand some of the terminology and some of the writing <em>about</em> modern transformers. Here are the most important ones.</p>

<h3 id="why-is-it-called-self-attention">Why is it called self-<em>attention</em>?</h3>

<p>Before self-attention was first presented, sequence models consisted mostly of recurrent networks or convolutions stacked together. At some point, it was discovered that these models could be helped by adding <em>attention mechanisms</em>: instead of feeding the output sequence of the previous layer directly to the input of the next, an intermediate mechanism was introduced, that decided which elements of the input were relevant for a particular word of the output.</p>

<p>The general mechanism was as follows. We call the input the <strong>values</strong>. Some (trainable) mechanism assigns a <strong>key</strong> to each value. Then to each output, some other mechanism assigns a <strong>query</strong>.</p>

<p>These names derive from the datastructure of a key-value store. In that case we expect only one item in our store to have a key that matches the query, which is returned when the query is executed. Attention is a softened version of this: <em>every</em> key in the store matches the query to some extent. All are returned, and we take a sum, weighted by the extent to which each key matches the query.</p>

<p>The great breakthrough of self-attention was that attention by itself is a strong enough mechanism to do all the learning. <a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a>, as the authors put it. The key, query and value are all the same vectors (with minor linear transformations). They <em>attend to themselves</em> and stacking such self-attention provides sufficient nonlinearity and representational power to learn very complicated functions.</p>

<h3 id="the-original-transformer-encoders-and-decoders">The original transformer: encoders and decoders</h3>

<p>But the authors did not dispense with all the complexity of contemporary sequence modeling. The standard structure of sequence-to-sequence models in those days was an encoder-decoder architecture, with <a href="https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html">teacher forcing</a>.</p>

<figure class="narrow">
<img src="./Transformers from scratch _ peterbloem.nl_files/encoder-decoder.svg">
</figure>

<p>The <em>encoder</em> takes the input sequence and maps it to a single <em>latent</em> vector representing the whole sequence. This vector is then passed to a <em>decoder</em> which unpacks it to the desired target sequence (for instance, the same sentence in another language).</p>

<p><em>Teacher forcing</em> refers to the technique of also allowing the decoder access to the input sentence, but in an autoregressive fashion. That is, the decoder generates the output sentence word for word based both on the latent vector and the words it has already generated. This takes some of the pressure off the latent representation: the decoder can use word-for-word sampling to take care of the low-level structure like syntax and grammar and use the latent vector to capture more high-level semantic structure. Decoding twice with the same latent vector would, ideally, give you two different sentences with the same meaning.</p>

<p>In later transformers, like BERT and GPT-2, the encoder/decoder configuration was entirely dispensed with. A simple stack of transformer blocks was found to be sufficient to achieve state of the art in many sequence based tasks.</p>

<aside>This is sometimes called a decoder-only transformer (for an autoregressive model) or an encoder-only transformer (for a model without masking). </aside>

<h2 id="modern-transformers">Modern transformers</h2>

<p>Here’s a small selection of some modern transformers and their most characteristic details.</p>

<h3 id="bert"><a href="https://arxiv.org/abs/1810.04805">BERT</a></h3>

<p><abbr title="Bidirectional Encoder Representations from Transformers">BERT</abbr> was one of the first models to show that transformers could reach human-level performance on a variety of language based tasks: question answering, sentiment classification or classifying whether two sentences naturally follow one another.</p>

<p>BERT consists of a simple stack of transformer blocks, of the type we’ve described above. This stack is <em>pre-trained</em> on a large general-domain corpus consisting of 800M words from English books (modern work, from unpublished authors), and 2.5B words of text from English Wikipedia articles (without markup).</p>

<p>Pretraining is done through two tasks:</p>
<dl>
<dt>Masking</dt><dd>A certain number of words in the input sequence are: masked out, replaced with a random word or kept as is. The model is then asked to predict, for these words, what the original words were. Note that the model doesn't need to predict the entire denoised sentence, just the modified words. Since the model doesn't know which words it will be asked about, it learns a representation for every word in the sequence.</dd>
<dt>Next sequence classification</dt><dd>Two sequences of about 256 words are sampled that either (a) follow each other directly in the corpus, or (b) are both taken from random places. The model must then predict whether a or b is the case.</dd>
</dl>

<p>BERT uses WordPiece tokenization, which is somewhere in between word-level and character level sequences. It breaks words like <span class="bc">walking</span> up into the tokens <span class="bc">walk</span> and <span class="bc">##ing</span>. This allows the model to make some inferences based on word structure: two verbs ending in -ing have similar grammatical functions, and two verbs starting with walk- have similar semantic function.</p>

<p>The input is prepended with a special <span class="bc">&lt;cls&gt;</span> token. The output vector corresponding to this token is used as a sentence representation in sequence classification tasks like the next sentence classification (as opposed to the global average pooling over all vectors that we used in our classification model above).</p>

<p>After pretraining, a single task-specific layer is placed after the body of transformer blocks, which maps the general purpose representation to a task specific output. For classification tasks, this simply maps the first output token to softmax probabilities over the classes. For more complex tasks, a final sequence-to-sequence layer is designed specifically for the task.</p>

<p>The whole model is then re-trained to finetune the model for the specific task at hand.</p>

<p>In an ablation experiment, the authors show that the largest improvement as compared to previous models comes from the bidirectional nature of BERT. That is, previous models like GPT used an autoregressive mask, which allowed attention only over previous tokens. The fact that in BERT all attention is over the whole sequence is the main cause of the improved performance.</p>
<aside>
This is why the B in BERT stands for "bidirectional".
</aside>

<p>The largest BERT model uses 24 transformer blocks, an embedding dimension of 1024 and 16 attention heads, resulting in 340M parameters.</p>

<h3 id="gpt-2"><a href="https://openai.com/blog/better-language-models/">GPT-2</a></h3>

<p><abbr title="generative pre-trained transformer">GPT</abbr>-2 is the first transformer model that actually made it into <a href="https://www.bbc.com/news/technology-47249163">the mainstream news</a>, after the controversial decision by OpenAI not to release the full model.</p>

<aside>The reason was that GPT-2 could generate sufficiently believable text that large-scale fake news campaigns of the kind seen in the 2016 US presidential election would become effectively a one-person job.</aside>

<p>The first trick that the authors of GPT-2 employed was to create a new high-quality dataset. While BERT used high-quality data, their sources (lovingly crafted books and well-edited wikipedia articles) had a certain lack of diversity in the writing style. To collect more diverse data without sacrificing quality the authors used links posted on the social media site <em>Reddit</em> to gather a large collection of writing with a certain minimum level of social support (expressed on Reddit as <em>karma</em>).</p>

<p>GPT2 is fundamentally a language <em>generation</em> model, so it uses masked self-attention like we did in our model above. It uses byte-pair encoding to tokenize the language, which , like the WordPiece encoding breaks words up into tokens that are slightly larger than single characters but less than entire words.</p>

<p>GPT2 is built very much like our text generation model above, with only small differences in layer order and added tricks to train at greater depths. The largest model uses 48 transformer blocks, a sequence length of 1024 and an embedding dimension of 1600, resulting in 1.5B parameters.</p>

<p>They show state-of-the art performance on many tasks. On the wikipedia compression task that we tried above, they achieve 0.93 bits per byte.</p>

<h3 id="transformer-xl"><a href="https://arxiv.org/abs/1901.02860">Transformer-XL</a></h3>

<p>While the transformer represents a massive leap forward in modeling long-range dependency, the models we have seen so far are still fundamentally limited by the size of the input. Since the size of the dot-product matrix grows quadratically in the sequence length, this quickly becomes the bottleneck as we try to extend the length of the input sequence. Transformer-XL is one of the first succesful transformer models to tackle this problem.</p>

<p>During training, a long sequence of text (longer than the model could deal with) is broken up into shorter segments. Each segment is processed in sequence, with self-attention computed over the tokens in the curent segment <em>and the previous segment</em>. Gradients are only computed over the current segment, but information still propagates as the segment window moves through the text. In theory at layer <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-94-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1299" style="width: 0.739em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.657em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.517em, 1000.66em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1300"><span class="mi" id="MathJax-Span-1301" style="font-family: NeoEulerMathJax_Main;">n</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.639em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-94">n</script>, information may be used from <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-95-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1302" style="width: 0.739em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.657em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.517em, 1000.66em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1303"><span class="mi" id="MathJax-Span-1304" style="font-family: NeoEulerMathJax_Main;">n</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.639em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-95">n</script> segments ago.</p>

<aside>
A similar trick in RNN training is called truncated backpropagation through time. We feed the model a very long sequence, but backpropagate only over part of it. The first part of the sequence, for which no gradients are computed, still influences the values of the hidden states in the part for which they are.
</aside>

<p>To make this work, the authors had to let go of the standard position encoding/embedding scheme. Since the position encoding is <em>absolute</em>, it would change for each segment and not lead to a consistent embedding over the whole sequence. Instead they use a <em>relative</em> encoding. For each output vector, a different sequence of position vectors is used that denotes not the absolute position, but the distance to the current output.</p>

<p>This requires moving the position encoding into the attention mechanism (which is detailed in the paper). One benefit is that the resulting transformer will likely generalize much better to sequences of unseen length.</p>

<h3 id="sparse-transformers"><a href="https://openai.com/blog/sparse-transformer/">Sparse transformers</a></h3>

<p>Sparse transformers tackle the problem of quadratic memory use head-on. Instead of computing a dense matrix of attention weights (which grows quadratically), they compute the self-attention only for particular pairs of input tokens, resulting in a <em>sparse</em> attention matrix, with only <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-96-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1305" style="width: 2.418em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.172em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.271em, 1002.17em, 2.5em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1306"><span class="mi" id="MathJax-Span-1307" style="font-family: NeoEulerMathJax_Main;">n</span><span class="msqrt" id="MathJax-Span-1308"><span style="display: inline-block; position: relative; width: 1.517em; height: 0px;"><span style="position: absolute; clip: rect(3.401em, 1000.66em, 4.138em, -999.998em); top: -4.011em; left: 0.821em;"><span class="mrow" id="MathJax-Span-1309"><span class="mi" id="MathJax-Span-1310" style="font-family: NeoEulerMathJax_Main;">n</span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(3.606em, 1000.7em, 3.892em, -999.998em); top: -4.462em; left: 0.821em;"><span style="display: inline-block; position: relative; width: 0.698em; height: 0px;"><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.011em; left: -0.039em;">−<span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; font-family: NeoEulerMathJax_Main; top: -4.011em; left: -0.039em;">−<span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; clip: rect(2.91em, 1000.86em, 4.138em, -999.998em); top: -3.765em; left: 0em;"><span style="font-family: NeoEulerMathJax_Main;">√</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.316em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-96">n\sqrt{n}</script> explicit elements.</p>

<p>This allows models with very large context sizes, for instance for generative modeling over images, with large dependencies between pixels. The tradeoff is that the sparsity structure is not learned, so by the choice of sparse matrix, we are disabling some interactions between input tokens that might otherwise have been useful. However, two units that are not directly related may still interact in higher layers of the transformer (similar to the way a convolutional net builds up a larger receptive field with more convolutional layers).</p>

<p>Beyond the simple benefit of training transformers with very large sequence lengths, the sparse transformer also allows a very elegant way of designing an inductive bias. We take our input as a collection of units (words, characters, pixels in an image, nodes in a graph) and we specify, through the sparsity of the attention matrix, which units we believe to be related. The rest is just a matter of building the transformer up as deep as it will go and seeing if it trains.</p>

<h2 id="going-big">Going big</h2>

<p>The big bottleneck in training transformers is the matrix of dot products in the self attention. For a sequence length <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-97-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1311" style="width: 0.452em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.412em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.394em, 1000.41em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1312"><span class="mi" id="MathJax-Span-1313" style="font-family: NeoEulerMathJax_Main;">t</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.775em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-97">t</script>, this is a dense matrix containing <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-98-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1314" style="width: 0.985em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.108em, 1000.86em, 2.213em, -999.998em); top: -2.086em; left: 0em;"><span class="mrow" id="MathJax-Span-1315"><span class="msubsup" id="MathJax-Span-1316"><span style="display: inline-block; position: relative; width: 0.862em; height: 0px;"><span style="position: absolute; clip: rect(3.278em, 1000.41em, 4.138em, -999.998em); top: -4.011em; left: 0em;"><span class="mi" id="MathJax-Span-1317" style="font-family: NeoEulerMathJax_Main;">t</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span><span style="position: absolute; top: -4.38em; left: 0.412em;"><span class="mn" id="MathJax-Span-1318" style="font-size: 70.7%; font-family: NeoEulerMathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.015em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.09em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 1.048em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-98">t^2</script> elements. At standard 32-bit precision, and with <span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-99-Frame" tabindex="0" style=""><nobr><span class="math" id="MathJax-Span-1319" style="width: 4.056em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.647em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.312em, 1003.61em, 2.254em, -999.998em); top: -2.127em; left: 0em;"><span class="mrow" id="MathJax-Span-1320"><span class="mi" id="MathJax-Span-1321" style="font-family: NeoEulerMathJax_Main;">t</span><span class="mo" id="MathJax-Span-1322" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">=</span><span class="mn" id="MathJax-Span-1323" style="font-family: NeoEulerMathJax_Main; padding-left: 0.248em;">1000</span></span><span style="display: inline-block; width: 0px; height: 2.131em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.043em; border-left: 0px solid; width: 0px; height: 0.911em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-99">t=1000</script> a batch of 16 such matrices takes up about 250Mb of memory. Since we need at least four of them per self attention operation (before and after softmax, plus their gradients), that limits us to at most twelve layers in a standard 12Gb GPU. In practice, we get even less, since the inputs and outputs also take up a lot of memory (although the dot product dominates).</p>

<p>And yet models reported in the literature contain <a href="https://openai.com/blog/sparse-transformer/">sequence lengths of over 12000, with 48 layers</a>, using dense dot product matrices. These models are trained on clusters, of course, but a single GPU is still required to do a single forward/backward pass. How do we fit such humongous transformers into 12Gb of memory? There are three main tricks:</p>

<dl>
<dt>Half precision</dt><dd>On modern GPUs and on TPUs, tensor computations can be done efficiently on 16-bit float tensors. This isn't quite as simple as just setting the dtype of the tensor to <code>torch.float16</code>. For some parts of the network, like the loss, 32 bit precision is required. But most of this can be handled with relative ease by <a href="https://github.com/NVIDIA/apex">existing libraries</a>. Practically, this doubles your effective memory.</dd>
<dt>Gradient accumulation</dt><dd>For a large model, we may only be able to perform a forward/backward pass on a single instance. Batch size 1 is not likely to lead to stable learning. Luckily, we can perform a single forward/backward for each instance in a larger batch, and simply sum the gradients we find (this is a consequence of the <a href="https://youtu.be/VZwrbIBNzzA?t=1562">multivariate chain rule</a>). When we hit the end of the batch, we do a single step of gradient descent, and zero out the gradient. In Pytorch this is particulary easy: you know that <code>optimizer.zero_grad()</code> call in your training loop that seems so superfluous? If you don't make that call, the new gradients are simply added to the old ones. </dd>
<dt>Gradient checkpointing</dt><dd>If your model is so big that even a single forward/backward won't fit in memory, you can trade off even more computation for memory efficiency. In gradient checkpointing, you separate your model into sections. For each section, you do a separate forward/backward to compute the gradients, without retaining the intermediate values for the rest. Pytorch has <a href="https://pytorch.org/docs/stable/checkpoint.html">special utilities</a> for gradient checkpointng.
</dd>
</dl>

<p>For more information on how to do this, see <a href="https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255">this blogpost</a>.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The transformer may well be the simplest machine learning architecture to dominate the field in decades. There are good reasons to start paying attention to them if you haven’t been already.</p>

<p>Firstly, <strong>the current performance limit is purely in the hardware</strong>. Unlike convolutions or LSTMs the current limitations to what they can do are entirely determined by how big a model we can fit in GPU memory and how much data we can push through it in a reasonable amount of time. I have no doubt, we will eventually hit the point where more layers and and more data won’t help anymore, but we don’t seem to have reached that point yet.</p>

<p>Second, <strong>transformers are extremely generic</strong>. So far, the big successes have been in language modelling, with some more modest achievements in image and music analysis, but the transformer has a level of generality that is waiting to be exploited. The basic transformer is a <em>set-to-set</em> model. So long as your data is a set of units, you can apply a transformer. Anything else you know about your data (like local structure) you can add by means of position embeddings, or by manipulating the structure of the attention matrix (making it sparse, or masking out parts).</p>

<p>This is particularly useful in multi-modal learning. We could easily combine a captioned image into a set of pixels and characters and design some clever embeddings and sparsity structure to help the model figure out how to combine and align the two. If we combine the entirety of our knowledge about our domain into a relational structure like a multi-modal knowledge graph (as discussed in [3]), simple transformer blocks could be employed to propagate information between multimodal units, and to align them with the sparsity structure providing control over which units directly interact.</p>

<p>So far, transformers are still primarily seen as a language model. I expect that in time, we’ll see them adopted much more in other domains, not just to increase performance, but to simplify existing models, and to allow practitioners more intuitive control over their models’ inductive biases.</p>

<h2 id="references">References</h2>

<p>[1] <a href="http://jalammar.github.io/illustrated-transformer/">The illustrated transformer</a>, Jay Allamar.</p>

<p>[2] <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The annotated transformer</a>, Alexander Rush.</p>

<p>[3] <a href="https://content.iospress.com/articles/data-science/ds007"> The knowledge graph as the default data model for learning on heterogeneous knowledge</a> Xander Wilcke, Peter Bloem, Victor de Boer</p>

<p>[4] <a href="https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf">Matrix factorization techniques for recommender systems</a> Yehuda Koren et al.</p>

<h2 id="updates">Updates</h2>

<dl>
<dt>19 October 2019</dt>
<dd>Added a section on the difference between wide and narrow self-attention. Thanks to <a href="https://github.com/sidneyaraujomelo">Sidney Melo</a> for <a href="https://github.com/pbloem/former/issues/8">spotting the mistake</a> in the original implementation.</dd>
</dl>

<!--  -->

	   </article>
	

	
		
		  <nav class="title">
			<a href="http://peterbloem.nl/blog/">back</a>
			<h1> Transformers from scratch </h1>	
		  </nav>
		
	

	
<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; min-width: 0px; max-width: none; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: NeoEulerMathJax_Operators, sans-serif;"></div></div></body></html>