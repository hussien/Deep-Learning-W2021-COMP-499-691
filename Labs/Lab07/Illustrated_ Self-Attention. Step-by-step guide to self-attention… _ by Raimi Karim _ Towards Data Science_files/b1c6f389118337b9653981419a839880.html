<!DOCTYPE html>
<!-- saved from url=(0085)https://towardsdatascience.com/media/b1c6f389118337b9653981419a839880?gi=d91ec287afcd -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>Calculate softmax of attention scores – Medium</title><meta name="description" content="You can&#39;t perform that action at this time. You signed in with another tab or window. You signed out in another tab or window. Reload to refresh your session. Reload to refresh your session."><meta name="twitter:widgets:csp" content="on"><meta name="robots" content="noindex"><!--<base target="_blank">--><base href="." target="_blank"><style>body {text-rendering: optimizeLegibility; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; font-family: "ff-tisa-web-pro", Georgia, Cambria, "Times New Roman", Times, serif; font-weight: 400; color: #333332; font-size: 18px; line-height: 1.4; margin: 0; background-color: white; overflow: hidden;}iframe {max-width: 100%;}</style></head><body data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed=""><style>.gist .gist-file { margin-bottom: 0 !important; }.gist { text-rendering: auto; }</style><script src="./ab5eaf2075eb5bed207f35b68aff0.download" charset="utf-8"></script><link rel="stylesheet" href="./gist-embed-aa085cbd1d0cec4a6d8d8d3.css"><div id="gist99452464" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-selfattn_calculate_softmax-py" class="file my-2">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python  ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8" data-paste-markdown-skip="">
      <tbody><tr>
        <td id="file-selfattn_calculate_softmax-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-selfattn_calculate_softmax-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">torch</span>.<span class="pl-s1">nn</span>.<span class="pl-s1">functional</span> <span class="pl-k">import</span> <span class="pl-s1">softmax</span></td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-selfattn_calculate_softmax-py-LC2" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-selfattn_calculate_softmax-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">attn_scores_softmax</span> <span class="pl-c1">=</span> <span class="pl-en">softmax</span>(<span class="pl-s1">attn_scores</span>, <span class="pl-s1">dim</span><span class="pl-c1">=</span><span class="pl-c1">-</span><span class="pl-c1">1</span>)</td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-selfattn_calculate_softmax-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],</span></td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-selfattn_calculate_softmax-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-c">#         [6.0337e-06, 9.8201e-01, 1.7986e-02],</span></td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-selfattn_calculate_softmax-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-c">#         [2.9539e-04, 8.8054e-01, 1.1917e-01]])</span></td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-selfattn_calculate_softmax-py-LC7" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-selfattn_calculate_softmax-py-LC8" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># For readability, approximate the above as follows</span></td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-selfattn_calculate_softmax-py-LC9" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">attn_scores_softmax</span> <span class="pl-c1">=</span> [</td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-selfattn_calculate_softmax-py-LC10" class="blob-code blob-code-inner js-file-line">  [<span class="pl-c1">0.0</span>, <span class="pl-c1">0.5</span>, <span class="pl-c1">0.5</span>],</td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-selfattn_calculate_softmax-py-LC11" class="blob-code blob-code-inner js-file-line">  [<span class="pl-c1">0.0</span>, <span class="pl-c1">1.0</span>, <span class="pl-c1">0.0</span>],</td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-selfattn_calculate_softmax-py-LC12" class="blob-code blob-code-inner js-file-line">  [<span class="pl-c1">0.0</span>, <span class="pl-c1">0.9</span>, <span class="pl-c1">0.1</span>]</td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-selfattn_calculate_softmax-py-LC13" class="blob-code blob-code-inner js-file-line">]</td>
      </tr>
      <tr>
        <td id="file-selfattn_calculate_softmax-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-selfattn_calculate_softmax-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">attn_scores_softmax</span> <span class="pl-c1">=</span> <span class="pl-s1">torch</span>.<span class="pl-en">tensor</span>(<span class="pl-s1">attn_scores_softmax</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="https://gist.github.com/remykarem/ab5eaf2075eb5bed207f35b68aff05de/raw/edae67afe9eb17efe9a4cec50e3c6282c056934e/selfattn_calculate_softmax.py" style="float:right">view raw</a>
        <a href="https://gist.github.com/remykarem/ab5eaf2075eb5bed207f35b68aff05de#file-selfattn_calculate_softmax-py">selfattn_calculate_softmax.py</a>
        hosted with ❤ by <a href="https://github.com/">GitHub</a>
      </div>
    </div>
</div>
<script>var height = -1; var delayMs = 200; if (document) {document.domain = document.domain;}function notifyResize(height) {height = height ? height : document.documentElement.offsetHeight; var resized = false; if (window.donkey && donkey.resize) {donkey.resize(height);var elements = document.getElementsByClassName("gist-data"); for (var i = 0; i < elements.length; i++) {elements[i].style.overflow = "visible"}resized = true;}if (parent && parent._resizeIframe) {var obj = {iframe: window.frameElement, height: height}; parent._resizeIframe(obj); resized = true;}if (window.location && window.location.hash === "#amp=1" && window.parent && window.parent.postMessage) {window.parent.postMessage({sentinel: "amp", type: "embed-size", height: height}, "*");}if (window.webkit && window.webkit.messageHandlers && window.webkit.messageHandlers.resize) {window.webkit.messageHandlers.resize.postMessage(height); resized = true;}return resized;}function maybeResize() {try {if (document.documentElement.offsetHeight != height && notifyResize()) {height = document.documentElement.offsetHeight;}delayMs = Math.min(delayMs * 2, 1000000); setTimeout(maybeResize, delayMs);} catch(error) {console.log('maybeResize error: ', error)}}maybeResize();</script></body></html>